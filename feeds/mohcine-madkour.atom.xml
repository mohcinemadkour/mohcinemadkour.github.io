<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Mohcine Madkour - Mohcine Madkour</title><link href="https://mmadkour.xyz/" rel="alternate"></link><link href="https://mmadkour.xyz%5Cfeeds/mohcine-madkour.atom.xml" rel="self"></link><id>https://mmadkour.xyz/</id><updated>2020-02-01T13:01:00-05:00</updated><entry><title>Assets Management and energy demand forecasting using Matrix Profile</title><link href="https://mmadkour.xyz%5Cposts/2020/02/Matrix%20Profile/" rel="alternate"></link><published>2020-02-01T13:01:00-05:00</published><updated>2020-02-01T13:01:00-05:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2020-02-01:/2020/02/Matrix Profile/</id><summary type="html">&lt;p&gt;The code of this article is available at: https://github.com/mohcinemadkour/Matrix-Profile-for-Regime-Detection-in-Time-Series-Data/tree/master&lt;/p&gt;
&lt;p&gt;Today’s companies hold enormous value in the form of equipment and plants. Research suggests that on average, 5 to 15 % of a manufacturing company’s global asset base is idle, with most not having …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The code of this article is available at: https://github.com/mohcinemadkour/Matrix-Profile-for-Regime-Detection-in-Time-Series-Data/tree/master&lt;/p&gt;
&lt;p&gt;Today’s companies hold enormous value in the form of equipment and plants. Research suggests that on average, 5 to 15 % of a manufacturing company’s global asset base is idle, with most not having good visibility of these underutilized assets. In pharmaceutical industry for example, finding and repurposing under-utilized assets is seen to deliver the highest value and proven to avoid $ Millions of capital expenditures.&lt;/p&gt;
&lt;p&gt;Recent advances in time series classification and forecasting such as Prophet, Matrix Profile, RNN brought sophisticated tools to the support of the visibility and control of energy consumption at the device level. For example, identifying pattern of usage episodes overlaid on asset energy consumption can help to compare usage periods by location, type of equipment, and even individual device. However in real-life problem domain every situation is different and therefore using frequency domain or statistically modeling techniques, for example, to find patterns of energy consumption will require domain specific knowledge and to have labels on data which sometimes can bottleneck the motif search process. In this article I show a new technique that’s based on matrix profile to detect episodes of electricity usage and return the timestamps at which each episode stars and stops.&lt;/p&gt;
&lt;h2&gt;Data set and problem description&lt;/h2&gt;
&lt;p&gt;In this example we show energy consumption data from a pharmaceutical equipment over the course of a typical 24-hour day. Power consumption is measured in watts. The behavior of the device being measured is fairly typical: during episodes of active usage, power consumption quickly increases from an “idle” or background level of consumption, and then returns to idle power draw after usage ceases. Power consumption is noisy and variable in general. It is also fairly common for the “background” consumption of equipment to be variable over time, noisy, and to change such that you cannot rely on a single measurement or value. &lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/plot_image.svg"&gt;&lt;/p&gt;
&lt;h2&gt;Calculation of Matrix Profile&lt;/h2&gt;
&lt;p&gt;The Matrix Profile is a relatively new data structure for time series analysis developed by Eamonn Keogh at the University of California Riverside and Abdullah Mueen at the University of New Mexico []. Some of the advantages of using the Matrix Profile is that it is domain agnostic, fast, provides an exact solution (approximate when desired) and only requires a single parameter.
The algorithms that compute the Matrix Profile use a sliding window approach. With a window size of m, the algorithm:
- Computes the distances for the windowed sub-sequence against the entire time series
- Sets an exclusion zone to ignore trivial matches
- Updates the distance profile with the minimal values
- Sets the first nearest-neighbor index
The distance calculations outlined above occur n-m + 1 times; where n is the length of the time series and m is the window size. Since the sub-sequences are pulled from the time series itself, an exclusion zone is required to prevent trivial matches. For example, a snippet matching itself or a snippet very close to itself is considered a trivial match. The exclusion zone is simply half of the window size (m) both before and after the current window index. The values at these indices are ignored when computing the minimum distance and the nearest-neighbor index. A visualization showing the computation of a distance profile starting at the second window is shown below. &lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/E1jkPS6DbqgoR-1tpr3lyA.gif"&gt;&lt;/p&gt;
&lt;p&gt;The second window of values, X2 through X5, slides across the time series computing the dot product for each sub-sequence. Once all of the dot products are computed, the exclusion zone is applied to the distances and the minimum distance is stored in the Matrix Profile. Throwing away the extra distances and only keeping the minimum distance reduces the space complexity to 0(n).&lt;/p&gt;
&lt;h3&gt;Motif (and Anomaly) Definitions&lt;/h3&gt;
&lt;p&gt;A motif is a repeated pattern in a time series and a discord is an anomaly. With the Matrix Profile computed, it is simple to find the top-K number of motifs or discords. The Matrix Profile stores the distances in Euclidean space meaning that a distance close to 0 is most similar to another sub-sequence in the time series and a distance far away from 0, say 100, is unlike any other sub-sequence. Extracting the lowest distances gives the motifs and the largest distances gives the discords.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;calc_mp_cac&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;,&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;warnings&lt;/span&gt;.&lt;span class="nv"&gt;filterwarnings&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;ignore&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;df&lt;/span&gt;.&lt;span class="nv"&gt;power&lt;/span&gt;.&lt;span class="nv"&gt;values&lt;/span&gt;
    &lt;span class="nv"&gt;mp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;matrixProfile&lt;/span&gt;.&lt;span class="nv"&gt;stomp&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;,&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    # &lt;span class="nv"&gt;Bonus&lt;/span&gt;: &lt;span class="nv"&gt;calculate&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;corrected&lt;/span&gt; &lt;span class="nv"&gt;arc&lt;/span&gt; &lt;span class="nv"&gt;curve&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;CAC&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="nv"&gt;semantic&lt;/span&gt; &lt;span class="nv"&gt;segmantation&lt;/span&gt;.
    &lt;span class="nv"&gt;cac&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;fluss&lt;/span&gt;.&lt;span class="nv"&gt;fluss&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;], &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    #&lt;span class="nv"&gt;Append&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;nan&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;Matrix&lt;/span&gt; &lt;span class="nv"&gt;profile&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;enable&lt;/span&gt; &lt;span class="nv"&gt;plotting&lt;/span&gt; &lt;span class="nv"&gt;against&lt;/span&gt; &lt;span class="nv"&gt;raw&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;
    &lt;span class="nv"&gt;mp_adj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;],&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;nan&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;signal&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;
    &lt;span class="nv"&gt;fig&lt;/span&gt;, &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ax1&lt;/span&gt;, &lt;span class="nv"&gt;ax2&lt;/span&gt;, &lt;span class="nv"&gt;ax3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="nv"&gt;subplots&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;,&lt;span class="mi"&gt;1&lt;/span&gt;,&lt;span class="nv"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;True&lt;/span&gt;,&lt;span class="nv"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;,&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;ax1&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Power Consumption Data&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax1&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Signal&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;Matrix&lt;/span&gt; &lt;span class="nv"&gt;Profile&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp_adj&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;mp_adj&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Matrix Profile&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;, &lt;span class="nv"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;red&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Matrix Profile&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;set_xlabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Sequence window={}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="nv"&gt;format&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;CAC&lt;/span&gt;
    &lt;span class="nv"&gt;ax3&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;cac&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;cac&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;CAC&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;, &lt;span class="nv"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;green&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax3&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;CAC&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax3&lt;/span&gt;.&lt;span class="nv"&gt;set_xlabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Sequence window={}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="nv"&gt;format&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;mp&lt;/span&gt;

&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;plot_mp_cac&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;,&lt;span class="nv"&gt;m&lt;/span&gt;, &lt;span class="nv"&gt;feature&lt;/span&gt;,&lt;span class="nv"&gt;mp&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;warnings&lt;/span&gt;.&lt;span class="nv"&gt;filterwarnings&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;ignore&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;df&lt;/span&gt;[&lt;span class="nv"&gt;feature&lt;/span&gt;].&lt;span class="nv"&gt;values&lt;/span&gt;
    # &lt;span class="nv"&gt;Bonus&lt;/span&gt;: &lt;span class="nv"&gt;calculate&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;corrected&lt;/span&gt; &lt;span class="nv"&gt;arc&lt;/span&gt; &lt;span class="nv"&gt;curve&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;CAC&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="nv"&gt;semantic&lt;/span&gt; &lt;span class="nv"&gt;segmantation&lt;/span&gt;.
    &lt;span class="nv"&gt;cac&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;fluss&lt;/span&gt;.&lt;span class="nv"&gt;fluss&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;], &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    #&lt;span class="nv"&gt;Append&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;nan&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;Matrix&lt;/span&gt; &lt;span class="nv"&gt;profile&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;enable&lt;/span&gt; &lt;span class="nv"&gt;plotting&lt;/span&gt; &lt;span class="nv"&gt;against&lt;/span&gt; &lt;span class="nv"&gt;raw&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;
    &lt;span class="nv"&gt;mp_adj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;],&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;nan&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;signal&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;
    &lt;span class="nv"&gt;fig&lt;/span&gt;, &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ax1&lt;/span&gt;, &lt;span class="nv"&gt;ax2&lt;/span&gt;, &lt;span class="nv"&gt;ax3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="nv"&gt;subplots&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;,&lt;span class="mi"&gt;1&lt;/span&gt;,&lt;span class="nv"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;True&lt;/span&gt;,&lt;span class="nv"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;,&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;ax1&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Power Consumption Data&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax1&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Signal&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;Matrix&lt;/span&gt; &lt;span class="nv"&gt;Profile&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp_adj&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;mp_adj&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Matrix Profile&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;, &lt;span class="nv"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;red&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Matrix Profile&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;set_xlabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Sequence window={}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="nv"&gt;format&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;CAC&lt;/span&gt;
    &lt;span class="nv"&gt;ax3&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;cac&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;cac&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;CAC&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;, &lt;span class="nv"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;green&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax3&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;CAC&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax3&lt;/span&gt;.&lt;span class="nv"&gt;set_xlabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Sequence window={}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="nv"&gt;format&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;mp&lt;/span&gt;

&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;plot_signal_mp&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;,&lt;span class="nv"&gt;m&lt;/span&gt;, &lt;span class="nv"&gt;feature&lt;/span&gt;,&lt;span class="nv"&gt;mp&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;warnings&lt;/span&gt;.&lt;span class="nv"&gt;filterwarnings&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;ignore&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;df&lt;/span&gt;[&lt;span class="nv"&gt;feature&lt;/span&gt;].&lt;span class="nv"&gt;values&lt;/span&gt;

    #&lt;span class="nv"&gt;Append&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;nan&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;Matrix&lt;/span&gt; &lt;span class="nv"&gt;profile&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;enable&lt;/span&gt; &lt;span class="nv"&gt;plotting&lt;/span&gt; &lt;span class="nv"&gt;against&lt;/span&gt; &lt;span class="nv"&gt;raw&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;
    &lt;span class="nv"&gt;mp_adj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;],&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;nan&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;signal&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;
    &lt;span class="nv"&gt;fig&lt;/span&gt;, &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ax1&lt;/span&gt;, &lt;span class="nv"&gt;ax2&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="nv"&gt;subplots&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;,&lt;span class="mi"&gt;1&lt;/span&gt;,&lt;span class="nv"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;True&lt;/span&gt;,&lt;span class="nv"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;,&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;ax1&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Power Consumption Data&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax1&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Signal&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;Matrix&lt;/span&gt; &lt;span class="nv"&gt;Profile&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp_adj&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;mp_adj&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Matrix Profile&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;, &lt;span class="nv"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;red&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Matrix Profile&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;set_xlabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Sequence window={}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="nv"&gt;format&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

&lt;span class="nv"&gt;mp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;calc_mp_cac&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;,&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/download.png"&gt;&lt;/p&gt;
&lt;h4&gt;Summary:&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Interpretation of the matrix profile (mp) plot&lt;/strong&gt;
form the mp plot, there are many items of note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The choice of the subsequence lengh can be made visually, from the pattern examples, we are only interested in small local subsequences, of length ~ 11 min&lt;/li&gt;
&lt;li&gt;The relatively low values implies that the subsequence in the original time series must have (at least one) relatively similar subsequence elsewhere in the time series data (such regions are “motifs” or reoccurring patterns)&lt;/li&gt;
&lt;li&gt;Repeated patterns in the data (or "motifs") lead to low Matrix Profile values: From the data it looks that we dont have reapeted motifts throughout the time
Where we see relatively high values , we know that the subsequence in the original time series must be unique in its shape (such areas are “discords” )&lt;/li&gt;
&lt;li&gt;The Matrix Profile value jumps at each phase change. High Matrix Profile values are associated with "discords": time series behavior that hasn't been observed before: From the mp it looks we have many jumps because the time series data keeps fluctuating but there is no standalone top or local tops which means there it is no Discord or Anomay&lt;/li&gt;
&lt;li&gt;The conclusion is that the data is noisy and domain knowledge informtion is missing&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Matrix Profile Segmentation&lt;/h3&gt;
&lt;p&gt;The Matrix Profile allows a simple algorithm, FLUSS/FLOSS, for time series segmentation.The ideas of segmentation comes form the Matrix Profile Index which has pointers ( arrows , arcs ) that point to the nearest neighbor of each subsequence. If we have a change of behavior, for exampe active to idle , we should expect very few arrows to span that change of behavior (See the arrows in the bellow picture). In the matrixprofile-ts python library, the fluss function is implemented in the fluss sub-module, and it outputs the corrected arc curve&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/cac.png"&gt;&lt;/p&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Most active subsequences will point to another active subsequence&lt;/li&gt;
&lt;li&gt;Most "idle" subsequences will point to another "idle" subsequence&lt;/li&gt;
&lt;li&gt;Rarely, if ever, will an "idle" point to an "active"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, if we slide across the Matrix Profile Index , and count how many arrows cross each particular point, we expect to find few that span the change of behavior. As we can see in the example used in the corrected arc curve (CAC) bellow, The CAC minimizes in the right place. The CAC has a single parameter, the subsequence length m .Lets change it by an order of magnitude, and see how the results will change.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; [&lt;span class="mi"&gt;11&lt;/span&gt;,&lt;span class="mi"&gt;14&lt;/span&gt;,&lt;span class="mi"&gt;17&lt;/span&gt;]:
    &lt;span class="nv"&gt;calc_mp_cac&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;,&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/download121.png"&gt;
&lt;img alt="png" src="/images/download222.png"&gt;
&lt;img alt="png" src="/images/download211.png"&gt;&lt;/p&gt;
&lt;h4&gt;Summury&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The segmentation result sounds mathematically correct, but not what we expect for the active power domain.&lt;/li&gt;
&lt;li&gt;The true motifs are still “swamped” by more frequent, but meaningless patterns, like idle patterns.&lt;/li&gt;
&lt;li&gt;The solutions is to correctly incorporates the contextual weights of noise and active consumption in our use case.&lt;/li&gt;
&lt;li&gt;By correcting the MP to bias away from idle motifs, we can discover meaningful power active usage motifs.&lt;/li&gt;
&lt;li&gt;In the next step we will supress the 'motifs' that we know are representing idle or noise.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Domain specific annotation vector : Corrected Matrix Profile&lt;/h3&gt;
&lt;p&gt;The annotation vector( AV ) is a time series consisting of real valued numbers between [0 1]. A lower value indicates the subsequence starting at that index is less desirable, and therefore should be biased against . Conversely, higher values mean the corresponding subsequences should be favored for the potential motif pool.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matrixprofile.utils&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;apply_av&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;av_power_consumption&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;disp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
    &lt;span class="n"&gt;mp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;matrixProfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stomp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mp&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;ind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ind&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;ind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ind&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;mp_corrected&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;apply_av&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;disp&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;plot_signal_mp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mp_corrected&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mp_corrected&lt;/span&gt;
&lt;span class="n"&gt;mp_corrected&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;av_power_consumption&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/download322.png"&gt;&lt;/p&gt;
&lt;h4&gt;Summury&lt;/h4&gt;
&lt;p&gt;After adding the domain knowledge information( represented by the AV), the Corrected matrix profile is capable of detecting the consumption motifs by showing them as the low values&lt;/p&gt;
&lt;h3&gt;Motif Search&lt;/h3&gt;
&lt;p&gt;After finding some relatively low values (almost 0) in the mp, lets find out the different motifs existing in our data&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;plot_motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mtfs&lt;/span&gt;, &lt;span class="nv"&gt;labels&lt;/span&gt;, &lt;span class="nv"&gt;ax&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;colori&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="nv"&gt;colors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;rgbcm&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;ms&lt;/span&gt;,&lt;span class="nv"&gt;l&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;zip&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mtfs&lt;/span&gt;,&lt;span class="nv"&gt;labels&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
        &lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;colors&lt;/span&gt;[&lt;span class="nv"&gt;colori&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;colors&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;]
        &lt;span class="nv"&gt;starts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;list&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ms&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;ends&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; [&lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nv"&gt;m&lt;/span&gt;,&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;s&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;starts&lt;/span&gt;]
        &lt;span class="nv"&gt;ax&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;starts&lt;/span&gt;, &lt;span class="nv"&gt;pattern&lt;/span&gt;[&lt;span class="nv"&gt;starts&lt;/span&gt;],  &lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;o&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;,  &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;l&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;ax&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ends&lt;/span&gt;, &lt;span class="nv"&gt;pattern&lt;/span&gt;[&lt;span class="nv"&gt;ends&lt;/span&gt;],  &lt;span class="nv"&gt;c&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;o&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;markerfacecolor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;none&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;nn&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;ms&lt;/span&gt;:
            &lt;span class="nv"&gt;ax&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;range&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;nn&lt;/span&gt;,&lt;span class="nv"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;,&lt;span class="nv"&gt;pattern&lt;/span&gt;[&lt;span class="nv"&gt;nn&lt;/span&gt;:&lt;span class="nv"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;], &lt;span class="nv"&gt;c&lt;/span&gt; , &lt;span class="nv"&gt;linewidth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;colori&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="nv"&gt;ax&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;k&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;linewidth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;data&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax&lt;/span&gt;.&lt;span class="nv"&gt;legend&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;
&lt;span class="nv"&gt;mp_corrected&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;av_power_consumption&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;, &lt;span class="mi"&gt;12&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;power&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;, &lt;span class="mi"&gt;5&lt;/span&gt;, &lt;span class="nv"&gt;disp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;False&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;mtfs&lt;/span&gt; ,&lt;span class="nv"&gt;motif_d&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;motifs&lt;/span&gt;.&lt;span class="nv"&gt;motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;mp_corrected&lt;/span&gt;, &lt;span class="nv"&gt;max_motifs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;plot_signal_cmp_motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;, &lt;span class="nv"&gt;feature&lt;/span&gt;,&lt;span class="nv"&gt;m&lt;/span&gt;,&lt;span class="nv"&gt;mp_corrected&lt;/span&gt; &lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;warnings&lt;/span&gt;.&lt;span class="nv"&gt;filterwarnings&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;ignore&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;df&lt;/span&gt;[&lt;span class="nv"&gt;feature&lt;/span&gt;].&lt;span class="nv"&gt;values&lt;/span&gt;
    #&lt;span class="nv"&gt;Append&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;nan&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;Matrix&lt;/span&gt; &lt;span class="nv"&gt;profile&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;enable&lt;/span&gt; &lt;span class="nv"&gt;plotting&lt;/span&gt; &lt;span class="nv"&gt;against&lt;/span&gt; &lt;span class="nv"&gt;raw&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;
    &lt;span class="nv"&gt;mp_adj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp_corrected&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;],&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;nan&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;signal&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;
    &lt;span class="nv"&gt;fig&lt;/span&gt;, &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ax1&lt;/span&gt;, &lt;span class="nv"&gt;ax2&lt;/span&gt;, &lt;span class="nv"&gt;ax3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="nv"&gt;subplots&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;,&lt;span class="mi"&gt;1&lt;/span&gt;,&lt;span class="nv"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;True&lt;/span&gt;,&lt;span class="nv"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;,&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;ax1&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;power Data&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax1&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Signal&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;corrected&lt;/span&gt; &lt;span class="nv"&gt;Matrix&lt;/span&gt; &lt;span class="nv"&gt;Profile&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;plot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mp_adj&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;,&lt;span class="nv"&gt;mp_adj&lt;/span&gt;, &lt;span class="nv"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Corrected Matrix Profile&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;, &lt;span class="nv"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;red&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Corrected Matrix Profile&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

    #&lt;span class="nv"&gt;Plot&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;Motifs&lt;/span&gt;
    &lt;span class="nv"&gt;plot_motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mtfs&lt;/span&gt;, [&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;{md:.3f}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;md&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;motif_d&lt;/span&gt;], &lt;span class="nv"&gt;ax3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ax3&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Motifs&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    #&lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="nv"&gt;xlim&lt;/span&gt;&lt;span class="ss"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;,&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="k"&gt;show&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;
&lt;span class="nv"&gt;plot_signal_cmp_motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;, &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;power&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="mi"&gt;11&lt;/span&gt;,&lt;span class="nv"&gt;mp_corrected&lt;/span&gt; &lt;span class="ss"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/download3133.png"&gt;&lt;/p&gt;
&lt;h4&gt;Summury&lt;/h4&gt;
&lt;p&gt;The motifs.motifs function founds some consumption patterns in the data as well as some noise motifs, we will try to tune the motif search in order to discover consumption motifs only&lt;/p&gt;
&lt;h3&gt;Motifs Discovery&lt;/h3&gt;
&lt;p&gt;The motifs.motifs function admits the following parametres and return&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;max_motifs: stop finding new motifs once we have max_motifs&lt;/li&gt;
&lt;li&gt;radius: For each motif found, find neighbors that are within radius*motif_mp of the first.&lt;/li&gt;
&lt;li&gt;n_neighbors: number of neighbors from the first to find. If it is None, find all.&lt;/li&gt;
&lt;li&gt;ex_zone: minimum distance between indices for after each subsequence is identified. Defaults to m/2 where m is the subsequence length. If ex_zone = 0, only the found index is exclude, if ex_zone = 1 then if idx is found as a motif idx-1, idx, idx+1 are excluded.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Returns&lt;/strong&gt;
The function returns a tuple (top_motifs, distances) which are lists of the same length.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;top_motifs: This is a list of the indices found for each motif. The first index is the nth motif followed by all nearest neighbors found sorted by distances.&lt;/li&gt;
&lt;li&gt;distances: Minimum Matrix profile value for each motif set.
More detail about the algortihm implemented by this function can be found here: https://www.cs.ucr.edu/~eamonn/guided-motif-KDD17-new-format-10-pages-v005.pdf&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Experimenetation&lt;/h2&gt;
&lt;p&gt;In this step we experimente different values of max_motifs, radius, n_neighbors, and ex_zone, and use motifs plots visualization to find the best parametres set that distiguish the consumption motifs&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;fig&lt;/span&gt;, &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ax1&lt;/span&gt;, &lt;span class="nv"&gt;ax2&lt;/span&gt;, &lt;span class="nv"&gt;ax3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="nv"&gt;subplots&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;,&lt;span class="mi"&gt;1&lt;/span&gt;,&lt;span class="nv"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;True&lt;/span&gt;,&lt;span class="nv"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;,&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;


&lt;span class="nv"&gt;mtfs&lt;/span&gt; ,&lt;span class="nv"&gt;motif_d&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;motifs&lt;/span&gt;.&lt;span class="nv"&gt;motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;mp_corrected&lt;/span&gt;, &lt;span class="nv"&gt;max_motifs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;, &lt;span class="nv"&gt;n_neighbors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;None&lt;/span&gt;, &lt;span class="nv"&gt;radius&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;plot_motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mtfs&lt;/span&gt;, [&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;{md:.3f}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;md&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;motif_d&lt;/span&gt;], &lt;span class="nv"&gt;ax1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;ax1&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;4 Neigbhors&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mtfs&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

#&lt;span class="nv"&gt;mtfs&lt;/span&gt; ,&lt;span class="nv"&gt;motif_d&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;motifs&lt;/span&gt;.&lt;span class="nv"&gt;motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;mp&lt;/span&gt;, &lt;span class="nv"&gt;max_motifs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;, &lt;span class="nv"&gt;radius&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;mtfs&lt;/span&gt; ,&lt;span class="nv"&gt;motif_d&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;motifs&lt;/span&gt;.&lt;span class="nv"&gt;motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;mp_corrected&lt;/span&gt;, &lt;span class="nv"&gt;max_motifs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;, &lt;span class="nv"&gt;n_neighbors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;radius&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;plot_motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mtfs&lt;/span&gt;, [&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;{md:.3f}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;md&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;motif_d&lt;/span&gt;], &lt;span class="nv"&gt;ax2&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;ax2&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Radius = 10&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mtfs&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

#&lt;span class="nv"&gt;mtfs&lt;/span&gt; ,&lt;span class="nv"&gt;motif_d&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;motifs&lt;/span&gt;.&lt;span class="nv"&gt;motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;mp&lt;/span&gt;, &lt;span class="nv"&gt;max_motifs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;, &lt;span class="nv"&gt;ex_zone&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;mtfs&lt;/span&gt; ,&lt;span class="nv"&gt;motif_d&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;motifs&lt;/span&gt;.&lt;span class="nv"&gt;motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pattern&lt;/span&gt;, &lt;span class="nv"&gt;mp_corrected&lt;/span&gt;, &lt;span class="nv"&gt;max_motifs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;, &lt;span class="nv"&gt;n_neighbors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;None&lt;/span&gt;, &lt;span class="nv"&gt;radius&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;,  &lt;span class="nv"&gt;ex_zone&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;plot_motifs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mtfs&lt;/span&gt;, [&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;{md:.3f}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;md&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;motif_d&lt;/span&gt;], &lt;span class="nv"&gt;ax3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;ax3&lt;/span&gt;.&lt;span class="nv"&gt;set_ylabel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;Exclude 2*m&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;plt&lt;/span&gt;.&lt;span class="k"&gt;show&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;
&lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mtfs&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
#### &lt;span class="nv"&gt;Results&lt;/span&gt;:
[[&lt;span class="mi"&gt;839&lt;/span&gt;, &lt;span class="mi"&gt;1186&lt;/span&gt;], [&lt;span class="mi"&gt;612&lt;/span&gt;, &lt;span class="mi"&gt;989&lt;/span&gt;], [&lt;span class="mi"&gt;577&lt;/span&gt;, &lt;span class="mi"&gt;898&lt;/span&gt;], [&lt;span class="mi"&gt;825&lt;/span&gt;, &lt;span class="mi"&gt;1394&lt;/span&gt;]]
[[&lt;span class="mi"&gt;839&lt;/span&gt;, &lt;span class="mi"&gt;1186&lt;/span&gt;], [&lt;span class="mi"&gt;612&lt;/span&gt;, &lt;span class="mi"&gt;989&lt;/span&gt;], [&lt;span class="mi"&gt;577&lt;/span&gt;, &lt;span class="mi"&gt;898&lt;/span&gt;], [&lt;span class="mi"&gt;825&lt;/span&gt;, &lt;span class="mi"&gt;1394&lt;/span&gt;]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/download223.png"&gt;&lt;/p&gt;
&lt;h3&gt;Periods of active power consumptions&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;839&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;839&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;1186&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;1186&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;612&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;612&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;989&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;989&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;577&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;577&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;    
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;898&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;898&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;583&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;583&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;827&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;index&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;827&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;General Conclusion&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;By correcting the matrix profile with an AV based on the active power consumptions peaks measure, we were able to discover the true motifs&lt;/li&gt;
&lt;li&gt;After fine tuning the parametres of motifs.motifs, we were able to differtiate different motifs existing in the data.&lt;/li&gt;
&lt;li&gt;Visually we have one false positive : the red motif in the right, which we refere to noise. We can improve the result by adding a noise fiter on the found motifs.&lt;/li&gt;
&lt;/ul&gt;</content><category term="Motif search"></category><category term="Matrix Profile"></category></entry><entry><title>Practical Deep Learning for Time Series using fastai/ Pytorch: Part 1</title><link href="https://mmadkour.xyz%5Cposts/2019/10/Machine%20Learning,%20timeseriesAI,%20Time%20Series%20Classification,%20fastai_timeseries/" rel="alternate"></link><published>2019-10-12T13:01:00-04:00</published><updated>2019-10-12T13:01:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2019-10-12:/2019/10/Machine Learning, timeseriesAI, Time Series Classification, fastai_timeseries/</id><summary type="html">&lt;p&gt;timeseriesAI is a library built on top of fastai/ Pytorch to help you apply Deep Learning to your time series/ sequential datasets, in particular Time Series Classification (TSC) and Time Series Regression (TSR) problems.
The library contains 3 major components: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Notebooks&lt;/strong&gt;: they are very practical, and show you how certain …&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;timeseriesAI is a library built on top of fastai/ Pytorch to help you apply Deep Learning to your time series/ sequential datasets, in particular Time Series Classification (TSC) and Time Series Regression (TSR) problems.
The library contains 3 major components: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Notebooks&lt;/strong&gt;: they are very practical, and show you how certain techniques can be easily applied. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;fastai_timeseries&lt;/strong&gt;: it's an extension of fastai's library that focuses on time series/ sequential problems. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;torchtimeseries.models&lt;/strong&gt; : it's a collection of some state-of-the-art time series/ sequential models.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Notebooks&lt;/h2&gt;
&lt;h4&gt;1. Introduction to Time Series Classification (TSC):&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;This is an intro that nb that shows you how you can achieve high performance in 4 simple steps.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. UCR_TCS:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The UCR datasets are broadly used in TSC problems as s bechmark to measure performance. This notebook will allow you to test any of the available datasets, with the model of your choice and any training scheme. You can easily tweak any of them to try to beat a SOTA.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. New TS data augmentations:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;You will see how you can apply successful data augmentation techniques (like mixup, cutout, and cutmix) to time series problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="nx"&gt;javascript&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;collapsible_headings/main&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hide_input/main&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;autosavetime/main&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;execute_time/ExecuteTime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;code_prettify/code_prettify&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;scroll_down/main&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;jupyter-js-widgets/extension&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;IPython&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Javascript&lt;/span&gt; &lt;span class="k"&gt;object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;00. Purpose 😇&lt;/h2&gt;
&lt;p&gt;The purpose of this notebook is to show you how you can create a simple, state-of-the-art time series classification model using the great &lt;strong&gt;fastai-v1&lt;/strong&gt; library in 4 steps:
1. Import libraries
2. Prepare data
3. Build learner
4. Train model&lt;/p&gt;
&lt;p&gt;In general, there are 3 main ways to classify time series, based on the input to the neural network:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;raw data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;image data (encoded from raw data)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;feature data (extracted from raw data)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this notebook, we will use the first approach. We will cover other approaches in future notebooks.&lt;/p&gt;
&lt;p&gt;Throughout the notebook you will see this ✳️. It means there's some value you need to select.&lt;/p&gt;
&lt;h2&gt;01. Import libraries 📚&lt;/h2&gt;
&lt;p&gt;There are some dependencies you need to have installed to be able to run this repo. If you don't have these packages you will need to install them: 
- pip install Cython
- pip install tslearn
- pip install PyWavelets
- pip install pyts
- pip install fire
- pip install nvidia-ml-py3&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;reload_ext&lt;/span&gt; &lt;span class="n"&gt;autoreload&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;autoreload&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;fastai&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;fastai_timeseries&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;torchtimeseries.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcwd&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fastai :&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fastai&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;torch  :&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;device :&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;C&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;Users&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;qq834&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;Google&lt;/span&gt; &lt;span class="n"&gt;Drive&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;mohcineblog&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;Draft&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;timeseriesAI&lt;/span&gt;
&lt;span class="n"&gt;fastai&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;58&lt;/span&gt;
&lt;span class="n"&gt;torch&lt;/span&gt;  &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;device&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;cuda&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;02. Prepare data 🔢&lt;/h2&gt;
&lt;h3&gt;Download data ⬇️&lt;/h3&gt;
&lt;p&gt;In this notebook, we'll use one of the most widely used time series classification databases: UEA &amp;amp; UCR Time Series Classification Repository. As of Sep 2019 it contains 128 univariate datasets and 30 multivariate datasets.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;get_UCR_univariate_list&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ACSF1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Adiac&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;AllGestureWiimoteX&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;AllGestureWiimoteY&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;AllGestureWiimoteZ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ArrowHead&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Beef&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;BeetleFly&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;BirdChicken&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;BME&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Car&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;CBF&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Chinatown&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ChlorineConcentration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;CinCECGtorso&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Coffee&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Computers&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;CricketX&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;CricketY&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;CricketZ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Crop&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;DiatomSizeReduction&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;DistalPhalanxOutlineAgeGroup&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;DistalPhalanxOutlineCorrect&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;DistalPhalanxTW&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;DodgerLoopDay&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;DodgerLoopGame&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;DodgerLoopWeekend&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Earthquakes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ECG200&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ECG5000&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ECGFiveDays&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ElectricDevices&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;EOGHorizontalSignal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;EOGVerticalSignal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;EthanolLevel&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;FaceAll&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;FaceFour&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;FacesUCR&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;FiftyWords&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Fish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;FordA&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;FordB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;FreezerRegularTrain&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;FreezerSmallTrain&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Fungi&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;GestureMidAirD1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;GestureMidAirD2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;GestureMidAirD3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;GesturePebbleZ1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;GesturePebbleZ2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;GunPoint&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;GunPointAgeSpan&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;GunPointMaleVersusFemale&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;GunPointOldVersusYoung&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Ham&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;HandOutlines&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Haptics&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Herring&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;HouseTwenty&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;InlineSkate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;InsectEPGRegularTrain&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;InsectEPGSmallTrain&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;InsectWingbeatSound&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ItalyPowerDemand&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;LargeKitchenAppliances&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Lightning2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Lightning7&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Mallat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Meat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;MedicalImages&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;MelbournePedestrian&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;MiddlePhalanxOutlineAgeGroup&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;MiddlePhalanxOutlineCorrect&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;MiddlePhalanxTW&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;MixedShapes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;MixedShapesSmallTrain&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;MoteStrain&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;NonInvasiveFetalECGThorax1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;NonInvasiveFetalECGThorax2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;OliveOil&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;OSULeaf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;PhalangesOutlinesCorrect&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Phoneme&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;PickupGestureWiimoteZ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;PigAirwayPressure&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;PigArtPressure&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;PigCVP&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;PLAID&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Plane&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;PowerCons&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ProximalPhalanxOutlineAgeGroup&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ProximalPhalanxOutlineCorrect&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ProximalPhalanxTW&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;RefrigerationDevices&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Rock&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ScreenType&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;SemgHandGenderCh2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;SemgHandMovementCh2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;SemgHandSubjectCh2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ShakeGestureWiimoteZ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ShapeletSim&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ShapesAll&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;SmallKitchenAppliances&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;SmoothSubspace&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;SonyAIBORobotSurface1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;SonyAIBORobotSurface2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;StarlightCurves&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Strawberry&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;SwedishLeaf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Symbols&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;SyntheticControl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ToeSegmentation1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;ToeSegmentation2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Trace&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;TwoLeadECG&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;TwoPatterns&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;UMD&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;UWaveGestureLibraryAll&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;UWaveGestureLibraryX&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;UWaveGestureLibraryY&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;UWaveGestureLibraryZ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Wafer&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Wine&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;WordSynonyms&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Worms&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;WormsTwoClass&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;Yoga&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#pprint.pprint(get_UCR_multivariate_list())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the case of UCR data it's very easy to get data loaded. Let's select a dataset. You can modify this and select any one from the previous lists (univariate of multivariate).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# dataset id&lt;/span&gt;
&lt;span class="n"&gt;dsid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ChlorineConcentration&amp;#39;&lt;/span&gt;   &lt;span class="c1"&gt;# ✳️&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_UCR_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dsid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;☣️ &lt;strong&gt;Something very important when you prepare your own data is that data needs to be in a 3-d array with the following format:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Samples&lt;/li&gt;
&lt;li&gt;Features&lt;/li&gt;
&lt;li&gt;Sequence length (aka time steps)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All UEA &amp;amp; UCR Time Series Classification data have already been split between train and valid. When you use your own data, you'll have to split it yourself. We'll see examples of this in future notebooks.&lt;/p&gt;
&lt;h3&gt;Prepare databunch 💿&lt;/h3&gt;
&lt;p&gt;You always need to define the bs at the time of creating the databunch, the object that contains all data required.&lt;/p&gt;
&lt;p&gt;It's also best practice to scale the data using the train stats. There are several options available: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;standardization or normalization.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;calculate them based on all samples, per channel or per sample. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;scale range (for normalization only).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The most common practice is to standardize data per channel.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;                            &lt;span class="c1"&gt;# ✳️&lt;/span&gt;
&lt;span class="n"&gt;seed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1234&lt;/span&gt;                        &lt;span class="c1"&gt;# ✳️&lt;/span&gt;
&lt;span class="n"&gt;scale_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;standardize&amp;#39;&lt;/span&gt;         &lt;span class="c1"&gt;# ✳️ &amp;#39;standardize&amp;#39;, &amp;#39;normalize&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;scale_subtype&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;per_channel&amp;#39;&lt;/span&gt;      &lt;span class="c1"&gt;# ✳️ &amp;#39;all_samples&amp;#39;, &amp;#39;per_channel&amp;#39;, &amp;#39;per_sample&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;scale_range&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;              &lt;span class="c1"&gt;# ✳️ for normalization only: usually left to (-1, 1)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, the last step in data preparation is to prepare a databunch.
Time series data may come as numpy arrays, pandas dataframes, etc.
The 2 most common ways to load data into a databunch will be from a numpy array/ torch tensors or a pandas dataframe. Let's see how we'd work in either case. &lt;/p&gt;
&lt;h4&gt;From 3D numpy arrays/ torch tensors&lt;/h4&gt;
&lt;p&gt;1) You need to first create ItemLists from TimeSeriesList (custom type of ItemList built for Time Series)&lt;/p&gt;
&lt;p&gt;2) You need to label the ItemLists. You'll find a lot of information &lt;a href="https://docs.fast.ai/data_block.html"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3) You enter the train bs and val_bs and crate the databunch object. &lt;/p&gt;
&lt;p&gt;4) You add features and seq_len.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ItemLists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TimeSeriesList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;TimeSeriesList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label_from_lists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_valid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;databunch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;val_bs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;bs&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;num_workers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cpus&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scale_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scale_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale_subtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scale_subtype&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale_range&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scale_range&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
     &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;db&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;TSDataBunch&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="nt"&gt;Train&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;LabelList&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;467&lt;/span&gt; &lt;span class="nt"&gt;items&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;x&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;TimeSeriesList&lt;/span&gt;
&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;y&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;CategoryList&lt;/span&gt;
&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;3&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;3&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;
&lt;span class="nt"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;.;&lt;/span&gt;

&lt;span class="nt"&gt;Valid&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;LabelList&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;3840&lt;/span&gt; &lt;span class="nt"&gt;items&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;x&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;TimeSeriesList&lt;/span&gt;
&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;166&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;y&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;CategoryList&lt;/span&gt;
&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;3&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;
&lt;span class="nt"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;.;&lt;/span&gt;

&lt;span class="nt"&gt;Test&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;None&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;From pandas dataframe&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dsid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;NATOPS&amp;#39;&lt;/span&gt; 
&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_UCR_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dsid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ch&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="n"&gt;data_ch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;full&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;ch&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                              &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;))[:,&lt;/span&gt; &lt;span class="n"&gt;ch&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                              &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_valid&lt;/span&gt;&lt;span class="p"&gt;))[:,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;ch&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data_ch&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data_ch&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;feat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;str&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;target&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data/UCR/{dsid}/{dsid}.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data/UCR/{dsid}/{dsid}.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8640&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;53&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;feat&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;42&lt;/th&gt;
      &lt;th&gt;43&lt;/th&gt;
      &lt;th&gt;44&lt;/th&gt;
      &lt;th&gt;45&lt;/th&gt;
      &lt;th&gt;46&lt;/th&gt;
      &lt;th&gt;47&lt;/th&gt;
      &lt;th&gt;48&lt;/th&gt;
      &lt;th&gt;49&lt;/th&gt;
      &lt;th&gt;50&lt;/th&gt;
      &lt;th&gt;target&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.372758&lt;/td&gt;
      &lt;td&gt;-0.367844&lt;/td&gt;
      &lt;td&gt;-0.378445&lt;/td&gt;
      &lt;td&gt;-0.386751&lt;/td&gt;
      &lt;td&gt;-0.417101&lt;/td&gt;
      &lt;td&gt;-0.447204&lt;/td&gt;
      &lt;td&gt;-0.423585&lt;/td&gt;
      &lt;td&gt;-0.318506&lt;/td&gt;
      &lt;td&gt;-0.144364&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.477529&lt;/td&gt;
      &lt;td&gt;-0.487402&lt;/td&gt;
      &lt;td&gt;-0.485995&lt;/td&gt;
      &lt;td&gt;-0.480247&lt;/td&gt;
      &lt;td&gt;-0.496073&lt;/td&gt;
      &lt;td&gt;-0.491603&lt;/td&gt;
      &lt;td&gt;-0.537007&lt;/td&gt;
      &lt;td&gt;-0.475939&lt;/td&gt;
      &lt;td&gt;-0.479505&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.547370&lt;/td&gt;
      &lt;td&gt;-0.546334&lt;/td&gt;
      &lt;td&gt;-0.549748&lt;/td&gt;
      &lt;td&gt;-0.546891&lt;/td&gt;
      &lt;td&gt;-0.550253&lt;/td&gt;
      &lt;td&gt;-0.548429&lt;/td&gt;
      &lt;td&gt;-0.549099&lt;/td&gt;
      &lt;td&gt;-0.556074&lt;/td&gt;
      &lt;td&gt;-0.555707&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.530492&lt;/td&gt;
      &lt;td&gt;-0.537032&lt;/td&gt;
      &lt;td&gt;-0.528957&lt;/td&gt;
      &lt;td&gt;-0.520373&lt;/td&gt;
      &lt;td&gt;-0.530154&lt;/td&gt;
      &lt;td&gt;-0.528187&lt;/td&gt;
      &lt;td&gt;-0.533726&lt;/td&gt;
      &lt;td&gt;-0.528338&lt;/td&gt;
      &lt;td&gt;-0.518618&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.587062&lt;/td&gt;
      &lt;td&gt;-0.587322&lt;/td&gt;
      &lt;td&gt;-0.586417&lt;/td&gt;
      &lt;td&gt;-0.584654&lt;/td&gt;
      &lt;td&gt;-0.585361&lt;/td&gt;
      &lt;td&gt;-0.583648&lt;/td&gt;
      &lt;td&gt;-0.582933&lt;/td&gt;
      &lt;td&gt;-0.583448&lt;/td&gt;
      &lt;td&gt;-0.585703&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.598846&lt;/td&gt;
      &lt;td&gt;-0.596118&lt;/td&gt;
      &lt;td&gt;-0.594087&lt;/td&gt;
      &lt;td&gt;-0.598232&lt;/td&gt;
      &lt;td&gt;-0.604513&lt;/td&gt;
      &lt;td&gt;-0.607462&lt;/td&gt;
      &lt;td&gt;-0.606236&lt;/td&gt;
      &lt;td&gt;-0.602293&lt;/td&gt;
      &lt;td&gt;-0.600885&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.514671&lt;/td&gt;
      &lt;td&gt;-0.518640&lt;/td&gt;
      &lt;td&gt;-0.521285&lt;/td&gt;
      &lt;td&gt;-0.522843&lt;/td&gt;
      &lt;td&gt;-0.529080&lt;/td&gt;
      &lt;td&gt;-0.589589&lt;/td&gt;
      &lt;td&gt;-0.735513&lt;/td&gt;
      &lt;td&gt;-0.963720&lt;/td&gt;
      &lt;td&gt;-1.168972&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-1.566254&lt;/td&gt;
      &lt;td&gt;-1.210887&lt;/td&gt;
      &lt;td&gt;-0.879528&lt;/td&gt;
      &lt;td&gt;-0.638007&lt;/td&gt;
      &lt;td&gt;-0.532520&lt;/td&gt;
      &lt;td&gt;-0.577928&lt;/td&gt;
      &lt;td&gt;-0.628697&lt;/td&gt;
      &lt;td&gt;-0.632625&lt;/td&gt;
      &lt;td&gt;-0.606548&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.718601&lt;/td&gt;
      &lt;td&gt;-0.721093&lt;/td&gt;
      &lt;td&gt;-0.717955&lt;/td&gt;
      &lt;td&gt;-0.722386&lt;/td&gt;
      &lt;td&gt;-0.728969&lt;/td&gt;
      &lt;td&gt;-0.722774&lt;/td&gt;
      &lt;td&gt;-0.730497&lt;/td&gt;
      &lt;td&gt;-0.737313&lt;/td&gt;
      &lt;td&gt;-0.739868&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.680790&lt;/td&gt;
      &lt;td&gt;-0.686406&lt;/td&gt;
      &lt;td&gt;-0.704122&lt;/td&gt;
      &lt;td&gt;-0.722950&lt;/td&gt;
      &lt;td&gt;-0.708337&lt;/td&gt;
      &lt;td&gt;-0.690788&lt;/td&gt;
      &lt;td&gt;-0.692195&lt;/td&gt;
      &lt;td&gt;-0.702812&lt;/td&gt;
      &lt;td&gt;-0.701643&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 53 columns&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dsid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;NATOPS&amp;#39;&lt;/span&gt;   &lt;span class="c1"&gt;# ✳️&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data/UCR/{dsid}/{dsid}.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8640&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;53&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;feat&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;42&lt;/th&gt;
      &lt;th&gt;43&lt;/th&gt;
      &lt;th&gt;44&lt;/th&gt;
      &lt;th&gt;45&lt;/th&gt;
      &lt;th&gt;46&lt;/th&gt;
      &lt;th&gt;47&lt;/th&gt;
      &lt;th&gt;48&lt;/th&gt;
      &lt;th&gt;49&lt;/th&gt;
      &lt;th&gt;50&lt;/th&gt;
      &lt;th&gt;target&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.372758&lt;/td&gt;
      &lt;td&gt;-0.367844&lt;/td&gt;
      &lt;td&gt;-0.378445&lt;/td&gt;
      &lt;td&gt;-0.386751&lt;/td&gt;
      &lt;td&gt;-0.417101&lt;/td&gt;
      &lt;td&gt;-0.447204&lt;/td&gt;
      &lt;td&gt;-0.423585&lt;/td&gt;
      &lt;td&gt;-0.318506&lt;/td&gt;
      &lt;td&gt;-0.144364&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.477529&lt;/td&gt;
      &lt;td&gt;-0.487402&lt;/td&gt;
      &lt;td&gt;-0.485995&lt;/td&gt;
      &lt;td&gt;-0.480247&lt;/td&gt;
      &lt;td&gt;-0.496073&lt;/td&gt;
      &lt;td&gt;-0.491603&lt;/td&gt;
      &lt;td&gt;-0.537007&lt;/td&gt;
      &lt;td&gt;-0.475939&lt;/td&gt;
      &lt;td&gt;-0.479505&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.547370&lt;/td&gt;
      &lt;td&gt;-0.546334&lt;/td&gt;
      &lt;td&gt;-0.549748&lt;/td&gt;
      &lt;td&gt;-0.546891&lt;/td&gt;
      &lt;td&gt;-0.550253&lt;/td&gt;
      &lt;td&gt;-0.548429&lt;/td&gt;
      &lt;td&gt;-0.549099&lt;/td&gt;
      &lt;td&gt;-0.556074&lt;/td&gt;
      &lt;td&gt;-0.555707&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.530492&lt;/td&gt;
      &lt;td&gt;-0.537032&lt;/td&gt;
      &lt;td&gt;-0.528957&lt;/td&gt;
      &lt;td&gt;-0.520373&lt;/td&gt;
      &lt;td&gt;-0.530154&lt;/td&gt;
      &lt;td&gt;-0.528187&lt;/td&gt;
      &lt;td&gt;-0.533726&lt;/td&gt;
      &lt;td&gt;-0.528338&lt;/td&gt;
      &lt;td&gt;-0.518618&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.587062&lt;/td&gt;
      &lt;td&gt;-0.587322&lt;/td&gt;
      &lt;td&gt;-0.586417&lt;/td&gt;
      &lt;td&gt;-0.584654&lt;/td&gt;
      &lt;td&gt;-0.585361&lt;/td&gt;
      &lt;td&gt;-0.583648&lt;/td&gt;
      &lt;td&gt;-0.582933&lt;/td&gt;
      &lt;td&gt;-0.583448&lt;/td&gt;
      &lt;td&gt;-0.585703&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.598846&lt;/td&gt;
      &lt;td&gt;-0.596118&lt;/td&gt;
      &lt;td&gt;-0.594087&lt;/td&gt;
      &lt;td&gt;-0.598232&lt;/td&gt;
      &lt;td&gt;-0.604513&lt;/td&gt;
      &lt;td&gt;-0.607462&lt;/td&gt;
      &lt;td&gt;-0.606236&lt;/td&gt;
      &lt;td&gt;-0.602293&lt;/td&gt;
      &lt;td&gt;-0.600885&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.514671&lt;/td&gt;
      &lt;td&gt;-0.518640&lt;/td&gt;
      &lt;td&gt;-0.521285&lt;/td&gt;
      &lt;td&gt;-0.522843&lt;/td&gt;
      &lt;td&gt;-0.529080&lt;/td&gt;
      &lt;td&gt;-0.589589&lt;/td&gt;
      &lt;td&gt;-0.735513&lt;/td&gt;
      &lt;td&gt;-0.963720&lt;/td&gt;
      &lt;td&gt;-1.168972&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-1.566254&lt;/td&gt;
      &lt;td&gt;-1.210887&lt;/td&gt;
      &lt;td&gt;-0.879528&lt;/td&gt;
      &lt;td&gt;-0.638007&lt;/td&gt;
      &lt;td&gt;-0.532520&lt;/td&gt;
      &lt;td&gt;-0.577928&lt;/td&gt;
      &lt;td&gt;-0.628697&lt;/td&gt;
      &lt;td&gt;-0.632625&lt;/td&gt;
      &lt;td&gt;-0.606548&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;-0.718601&lt;/td&gt;
      &lt;td&gt;-0.721093&lt;/td&gt;
      &lt;td&gt;-0.717955&lt;/td&gt;
      &lt;td&gt;-0.722386&lt;/td&gt;
      &lt;td&gt;-0.728969&lt;/td&gt;
      &lt;td&gt;-0.722774&lt;/td&gt;
      &lt;td&gt;-0.730497&lt;/td&gt;
      &lt;td&gt;-0.737313&lt;/td&gt;
      &lt;td&gt;-0.739868&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;-0.680790&lt;/td&gt;
      &lt;td&gt;-0.686406&lt;/td&gt;
      &lt;td&gt;-0.704122&lt;/td&gt;
      &lt;td&gt;-0.722950&lt;/td&gt;
      &lt;td&gt;-0.708337&lt;/td&gt;
      &lt;td&gt;-0.690788&lt;/td&gt;
      &lt;td&gt;-0.692195&lt;/td&gt;
      &lt;td&gt;-0.702812&lt;/td&gt;
      &lt;td&gt;-0.701643&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 53 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;🔎 To create the TimeSeriesList, you need to select the columns that contain the time series only, neither the target, not the feature (for multivariate TS).&lt;/p&gt;
&lt;p&gt;🔎 You should use &lt;strong&gt;label_cls=CategoryList&lt;/strong&gt; when labels are floats but it is a classification problem. Otherwise, the fastai library would take it as a regression problem.&lt;/p&gt;
&lt;p&gt;1) You need to first TimeSeriesList (custom type of ItemList built for Time Series) from the dataframe. As cols you should only enter the data from the time series (X values, not y).&lt;/p&gt;
&lt;p&gt;2) Then you split the TimeSeriesList into 2 lists (traina and valid). There are multiple ways to do that. More info &lt;a href="https://docs.fast.ai/data_block.html"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3) You need to label the ItemLists. You'll find a lot of information &lt;a href="https://docs.fast.ai/data_block.html"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;4) You enter the train bs and val_bs and crate the databunch object. &lt;/p&gt;
&lt;p&gt;5) You add features and seq_len.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TimeSeriesList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_df&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cols&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;feat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;feat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split_by_rand_pct&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_pct&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label_from_df&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cols&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;target&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label_cls&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;CategoryList&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;databunch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;bs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;val_bs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;bs&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;num_workers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cpus&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scale_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scale_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale_subtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scale_subtype&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale_range&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scale_range&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
     &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;db&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;TSDataBunch&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="nt"&gt;Train&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;LabelList&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;288&lt;/span&gt; &lt;span class="nt"&gt;items&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;x&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;TimeSeriesList&lt;/span&gt;
&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;y&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;CategoryList&lt;/span&gt;
&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;
&lt;span class="nt"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;.;&lt;/span&gt;

&lt;span class="nt"&gt;Valid&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;LabelList&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;72&lt;/span&gt; &lt;span class="nt"&gt;items&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;x&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;TimeSeriesList&lt;/span&gt;
&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;52&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;y&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;CategoryList&lt;/span&gt;
&lt;span class="nt"&gt;3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;5&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;4&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;0&lt;/span&gt;
&lt;span class="nt"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;.;&lt;/span&gt;

&lt;span class="nt"&gt;Test&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;None&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Visualize data&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_batch&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_32_0.png"&gt;&lt;/p&gt;
&lt;h2&gt;03. Build learner 🏗&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;torchtimeseries.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="c1"&gt;# Select one arch from these state-of-the-art time series/ 1D models:&lt;/span&gt;
&lt;span class="c1"&gt;# ResCNN, FCN, InceptionTime, ResNet&lt;/span&gt;
&lt;span class="n"&gt;arch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;                     &lt;span class="c1"&gt;# ✳️   &lt;/span&gt;
&lt;span class="n"&gt;arch_kwargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                     &lt;span class="c1"&gt;# ✳️ &lt;/span&gt;
&lt;span class="n"&gt;opt_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Ranger&lt;/span&gt;                          &lt;span class="c1"&gt;# ✳️ a state-of-the-art optimizer&lt;/span&gt;
&lt;span class="n"&gt;loss_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LabelSmoothingCrossEntropy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# ✳️&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;arch_kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;opt_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;opt_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;stage_0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;InceptionBlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inc_mods&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Inception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxpool&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;MaxPool1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dilation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ceil_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bn&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;affine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;track_running_stats&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Inception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxpool&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;MaxPool1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dilation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ceil_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bn&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;affine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;track_running_stats&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Inception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxpool&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;MaxPool1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dilation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ceil_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bn&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;affine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;track_running_stats&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Inception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxpool&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;MaxPool1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dilation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ceil_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bn&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;affine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;track_running_stats&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Inception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxpool&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;MaxPool1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dilation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ceil_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bn&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;affine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;track_running_stats&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Inception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxpool&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;MaxPool1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dilation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ceil_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bn&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;affine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;track_running_stats&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="k"&gt;None&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="k"&gt;None&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;affine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;track_running_stats&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="k"&gt;None&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="k"&gt;None&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;affine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;track_running_stats&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gap&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;AdaptiveAvgPool1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;in_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bias&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;InceptionTime&lt;/span&gt;
&lt;span class="o"&gt;======================================================================&lt;/span&gt;
&lt;span class="n"&gt;Layer&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="k"&gt;Output&lt;/span&gt; &lt;span class="n"&gt;Shape&lt;/span&gt;         &lt;span class="n"&gt;Param&lt;/span&gt; &lt;span class="o"&gt;#&lt;/span&gt;    &lt;span class="n"&gt;Trainable&lt;/span&gt; 
&lt;span class="o"&gt;======================================================================&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;29&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;984&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;624&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;944&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;MaxPool1d&lt;/span&gt;            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;800&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;256&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;ReLU&lt;/span&gt;                 &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;968&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;488&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;248&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;MaxPool1d&lt;/span&gt;            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;256&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;ReLU&lt;/span&gt;                 &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;968&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;488&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;248&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;MaxPool1d&lt;/span&gt;            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;256&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;ReLU&lt;/span&gt;                 &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;968&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;488&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;248&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;MaxPool1d&lt;/span&gt;            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;256&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;ReLU&lt;/span&gt;                 &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;968&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;488&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;248&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;MaxPool1d&lt;/span&gt;            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;256&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;ReLU&lt;/span&gt;                 &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;968&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;488&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;248&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;MaxPool1d&lt;/span&gt;            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;256&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;ReLU&lt;/span&gt;                 &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;      &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;256&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Conv1d&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;512&lt;/span&gt;     &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;256&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;ReLU&lt;/span&gt;                 &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;AdaptiveAvgPool1d&lt;/span&gt;    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;             &lt;span class="mi"&gt;0&lt;/span&gt;          &lt;span class="k"&gt;False&lt;/span&gt;     
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;
&lt;span class="n"&gt;Linear&lt;/span&gt;               &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;                  &lt;span class="mi"&gt;774&lt;/span&gt;        &lt;span class="k"&gt;True&lt;/span&gt;      
&lt;span class="n"&gt;______________________________________________________________________&lt;/span&gt;

&lt;span class="n"&gt;Total&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;459&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;686&lt;/span&gt;
&lt;span class="n"&gt;Total&lt;/span&gt; &lt;span class="n"&gt;trainable&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;459&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;686&lt;/span&gt;
&lt;span class="n"&gt;Total&lt;/span&gt; &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;trainable&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;Optimized&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="mi"&gt;00200&lt;/span&gt;&lt;span class="n"&gt;EAA6AC80&lt;/span&gt;
&lt;span class="k"&gt;Using&lt;/span&gt; &lt;span class="k"&gt;true&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="n"&gt;decay&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;discussed&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fast&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ai&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2018&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;07&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;adam&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;weight&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;decay&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt; 
&lt;span class="n"&gt;Loss&lt;/span&gt; &lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;LabelSmoothingCrossEntropy&lt;/span&gt;
&lt;span class="o"&gt;======================================================================&lt;/span&gt;
&lt;span class="n"&gt;Callbacks&lt;/span&gt; &lt;span class="n"&gt;functions&lt;/span&gt; &lt;span class="n"&gt;applied&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;04. Train model 🚵🏼‍&lt;/h2&gt;
&lt;h3&gt;LR find 🔎&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;stage_0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lr_find&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;suggestion&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;LR&lt;/span&gt; &lt;span class="n"&gt;Finder&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;complete&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;type&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;learner_name&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;see&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="k"&gt;Min&lt;/span&gt; &lt;span class="n"&gt;numerical&lt;/span&gt; &lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;91&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;
&lt;span class="k"&gt;Min&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="n"&gt;divided&lt;/span&gt; &lt;span class="k"&gt;by&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_38_2.png"&gt;&lt;/p&gt;
&lt;h3&gt;Train 🏃🏽‍♀️&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;         &lt;span class="c1"&gt;# ✳️ &lt;/span&gt;
&lt;span class="n"&gt;max_lr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-2&lt;/span&gt;        &lt;span class="c1"&gt;# ✳️ &lt;/span&gt;
&lt;span class="n"&gt;warmup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;       &lt;span class="c1"&gt;# ✳️&lt;/span&gt;
&lt;span class="n"&gt;pct_start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;       &lt;span class="c1"&gt;# ✳️&lt;/span&gt;
&lt;span class="n"&gt;metrics&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# ✳️&lt;/span&gt;
&lt;span class="n"&gt;wd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;stage_0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_one_cycle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_lr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;max_lr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pct_start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pct_start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;moms&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;85&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;warmup&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;95&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                    &lt;span class="n"&gt;div_factor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;25.0&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;warmup&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;wd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;stage_1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_lr&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_losses&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_metrics&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;div&amp;gt;&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="s s-Atom"&gt;style&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="cm"&gt;/* Turns off some styling */&lt;/span&gt;
        &lt;span class="s s-Atom"&gt;progress&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="cm"&gt;/* gets rid of default border in Firefox and Opera. */&lt;/span&gt;
            &lt;span class="nn"&gt;border&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s s-Atom"&gt;none&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="cm"&gt;/* Needs to be in here for Safari polyfill so background images work as expected. */&lt;/span&gt;
            &lt;span class="s s-Atom"&gt;background&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nn"&gt;size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s s-Atom"&gt;auto&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s s-Atom"&gt;progress&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;interrupted&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s s-Atom"&gt;progress&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nn"&gt;interrupted&lt;/span&gt;&lt;span class="p"&gt;::-&lt;/span&gt;&lt;span class="s s-Atom"&gt;webkit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;progress&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;bar&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="nn"&gt;background&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s s-Atom"&gt;#&lt;/span&gt;&lt;span class="nv"&gt;F44336&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="s s-Atom"&gt;&amp;lt;/style&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="s s-Atom"&gt;progress&lt;/span&gt; &lt;span class="s s-Atom"&gt;value=&amp;#39;8&amp;#39;&lt;/span&gt; &lt;span class="s s-Atom"&gt;class=&amp;#39;&amp;#39;&lt;/span&gt; &lt;span class="s s-Atom"&gt;max=&amp;#39;100&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s s-Atom"&gt;style=&amp;#39;width:300px; height:20px; vertical-align: middle;&amp;#39;&amp;gt;&amp;lt;/progress&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="mf"&gt;8.00&lt;/span&gt;&lt;span class="c1"&gt;% [8/100 21:24&amp;lt;4:06:06]&lt;/span&gt;
&lt;span class="s s-Atom"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="o"&gt;div&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: left;"&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1.803898&lt;/td&gt;
      &lt;td&gt;1.792291&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
      &lt;td&gt;02:39&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.735648&lt;/td&gt;
      &lt;td&gt;1.786683&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
      &lt;td&gt;02:39&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1.612863&lt;/td&gt;
      &lt;td&gt;1.773017&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
      &lt;td&gt;02:39&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1.480261&lt;/td&gt;
      &lt;td&gt;1.743848&lt;/td&gt;
      &lt;td&gt;0.250000&lt;/td&gt;
      &lt;td&gt;02:39&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1.360391&lt;/td&gt;
      &lt;td&gt;1.684378&lt;/td&gt;
      &lt;td&gt;0.597222&lt;/td&gt;
      &lt;td&gt;02:40&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1.259697&lt;/td&gt;
      &lt;td&gt;1.414256&lt;/td&gt;
      &lt;td&gt;0.763889&lt;/td&gt;
      &lt;td&gt;02:41&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;1.174970&lt;/td&gt;
      &lt;td&gt;1.170152&lt;/td&gt;
      &lt;td&gt;0.819444&lt;/td&gt;
      &lt;td&gt;02:43&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1.102794&lt;/td&gt;
      &lt;td&gt;0.943973&lt;/td&gt;
      &lt;td&gt;0.819444&lt;/td&gt;
      &lt;td&gt;02:40&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;

    &lt;div&gt;
        &lt;style&gt;
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        &lt;/style&gt;
      &lt;progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
      0.00% [0/1 00:00&lt;00:00]
    &lt;/div&gt;





&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;archs_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acc_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acces_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acc5_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_params_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;archs_names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="vm"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;early_stop&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ceil&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train_dl&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;acc_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{:.5}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;span class="n"&gt;acces_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{:.5}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;early_stop&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;span class="n"&gt;acc5_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{:.5}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="n"&gt;n_params_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;archs_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acc_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acces_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acc5_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_params_&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                   &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;arch&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;accuracy train loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;max_accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;n_params&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;accuracy train loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ascending&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;




&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;arch&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;accuracy train loss&lt;/th&gt;
      &lt;th&gt;max_accuracy&lt;/th&gt;
      &lt;th&gt;n_params&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;InceptionTime&lt;/td&gt;
      &lt;td&gt;0.88359&lt;/td&gt;
      &lt;td&gt;0.88385&lt;/td&gt;
      &lt;td&gt;0.89193&lt;/td&gt;
      &lt;td&gt;406307&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;


### Results



&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;interp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ClassificationInterpretation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;interp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_confusion_matrix&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;




![png](/images/output_44_0.png)




&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;





&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="Time Series Classification"></category><category term="Machine Learning"></category><category term="timeseriesAI"></category><category term="Time Series Classification"></category><category term="fastai_timeseries"></category></entry><entry><title>Practical Deep Learning for Time Series using fastai/ Pytorch: Part 2</title><link href="https://mmadkour.xyz%5Cposts/2019/10/Machine%20Learning,%20timeseriesAI,%20Time%20Series%20Classification,%20fastai_timeseries,%20TSC%20bechmark/" rel="alternate"></link><published>2019-10-12T13:01:00-04:00</published><updated>2019-10-12T13:01:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2019-10-12:/2019/10/Machine Learning, timeseriesAI, Time Series Classification, fastai_timeseries, TSC bechmark/</id><summary type="html">&lt;p&gt;The UCR datasets are broadly used in TSC problems as s bechmark to measure performance. This notebook will allow you to test any of the available datasets, with the model of your choice and any training scheme. You can easily tweak any of them to try to beat a SOTA …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The UCR datasets are broadly used in TSC problems as s bechmark to measure performance. This notebook will allow you to test any of the available datasets, with the model of your choice and any training scheme. You can easily tweak any of them to try to beat a SOTA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;fastai&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;fastai_timeseries&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;torchtimeseries.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcwd&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fastai :&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fastai&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;torch  :&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;device :&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;oguizadl&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tradingLab&lt;/span&gt;&lt;span class="err"&gt;⚗️&lt;/span&gt;
&lt;span class="n"&gt;fastai&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;57&lt;/span&gt;
&lt;span class="n"&gt;torch&lt;/span&gt;  &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;device&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;cpu&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run_UCR_test&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                 &lt;span class="n"&gt;bs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_lr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;3e-3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pct_start&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;warmup&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                 &lt;span class="n"&gt;scale_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;standardize&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale_subtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;per_channel&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale_range&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                 &lt;span class="n"&gt;opt_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;functools&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Adam&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.99&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; 
                 &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;arch_kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;ds_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acc_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acces_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accmax_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;iter_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;time_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;val_loss_&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;datasets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;listify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; 
        &lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_UCR_databunch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;ds_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;iter_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;epochs_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;arch_kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;defaults&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;opt_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;opt_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;
            &lt;span class="n"&gt;start_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_one_cycle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_lr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;max_lr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pct_start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pct_start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;moms&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;85&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;warmup&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;95&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                &lt;span class="n"&gt;div_factor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;25.0&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;warmup&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;wd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;duration&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;start_time&lt;/span&gt;
            &lt;span class="n"&gt;time_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{:.0f}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;duration&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;early_stop&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ceil&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train_dl&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;acc_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
            &lt;span class="n"&gt;acces_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;early_stop&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
            &lt;span class="n"&gt;accmax_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;loss_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
            &lt;span class="n"&gt;val_loss_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recorder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_losses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;iters&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;ds_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;iter_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epochs_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;val_loss_&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;acc_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acces_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;accmax_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;time_&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;dataset&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;iter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;epochs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                        &lt;span class="s1"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;accuracy_ts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                        &lt;span class="s1"&gt;&amp;#39;max_accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;time (s)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                  &lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;val_loss&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                            &lt;span class="s1"&gt;&amp;#39;accuracy_ts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;max_accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
            &lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com based on:&lt;/span&gt;

&lt;span class="c1"&gt;# Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J., ... &amp;amp; Petitjean, F. (2019). InceptionTime: Finding AlexNet for Time Series Classification. arXiv preprint arXiv:1909.04939.&lt;/span&gt;
&lt;span class="c1"&gt;# Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch.nn&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;nn&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;noop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;shortcut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c_out&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                           &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_out&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Inception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_filters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;bottleneck&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;c_in&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;noop&lt;/span&gt;
        &lt;span class="n"&gt;mts_feat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bottleneck&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;c_in&lt;/span&gt;
        &lt;span class="n"&gt;conv_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;kss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ks&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="c1"&gt;# ensure odd kss until nn.Conv1d with padding=&amp;#39;same&amp;#39; is available in pytorch 1.3&lt;/span&gt;
        &lt;span class="n"&gt;kss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ksi&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;ksi&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;ksi&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ksi&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kss&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kss&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
            &lt;span class="n"&gt;conv_layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mts_feat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_filters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kss&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kss&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv_layers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maxpool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MaxPool1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_filters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BatchNorm1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nb_filters&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;input_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_tensor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;out_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv_layers&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;out_&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out_&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;mp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maxpool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_tensor&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;inc_out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mp&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inc_out&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;InceptionBlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;nb_filters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;residual&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;

        &lt;span class="c1"&gt;#inception &amp;amp; residual layers&lt;/span&gt;
        &lt;span class="n"&gt;inc_mods&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;res_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;inc_mods&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;Inception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_in&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;nb_filters&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="n"&gt;nb_filters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nb_filters&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;res_layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shortcut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_in&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;nb_filters&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_filters&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;res_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;res_layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inc_mods&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inc_mods&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;res_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ModuleList&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res_layers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
            &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inc_mods&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;res_layers&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;
                &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
                &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;act&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;nb_filters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;InceptionBlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;bottleneck&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ks&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;nb_filters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nb_filters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                    &lt;span class="n"&gt;residual&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gap&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AdaptiveAvgPool1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nb_filters&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Data&lt;/span&gt;
&lt;span class="n"&gt;bottom10&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Wine&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;BeetleFly&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;#&amp;#39;CinCECGtorso&amp;#39;, not available for download &lt;/span&gt;
            &lt;span class="s1"&gt;&amp;#39;InlineSkate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;MiddlePhalanxTW&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;OliveOil&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;SmallKitchenAppliances&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;WordSynonyms&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
            &lt;span class="s1"&gt;&amp;#39;MiddlePhalanxOutlineAgeGroup&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;MoteStrain&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Phoneme&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;top3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Herring&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ScreenType&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ChlorineConcentration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;datasets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bottom10&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;top3&lt;/span&gt;
&lt;span class="n"&gt;bs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;
&lt;span class="n"&gt;scale_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;standardize&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;scale_subtype&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;per_channel&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;scale_range&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Arch&lt;/span&gt;
&lt;span class="n"&gt;arch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;
&lt;span class="n"&gt;arch_kwargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# Training&lt;/span&gt;
&lt;span class="n"&gt;iters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;
&lt;span class="n"&gt;max_lr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;3e-3&lt;/span&gt;
&lt;span class="n"&gt;warmup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
&lt;span class="n"&gt;pct_start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="n"&gt;metrics&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;wd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-2&lt;/span&gt;
&lt;span class="n"&gt;opt_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Ranger&lt;/span&gt;
&lt;span class="n"&gt;loss_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LabelSmoothingCrossEntropy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;run_UCR_test&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;arch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;bs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;bs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;max_lr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;max_lr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;pct_start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pct_start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;warmup&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;warmup&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;wd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;wd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;scale_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scale_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;scale_subtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scale_subtype&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;scale_range&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scale_range&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;opt_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;opt_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;arch_kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;dataset&lt;/th&gt;
      &lt;th&gt;iter&lt;/th&gt;
      &lt;th&gt;epochs&lt;/th&gt;
      &lt;th&gt;loss&lt;/th&gt;
      &lt;th&gt;val_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;accuracy_ts&lt;/th&gt;
      &lt;th&gt;max_accuracy&lt;/th&gt;
      &lt;th&gt;time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Wine&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.692424&lt;/td&gt;
      &lt;td&gt;0.693793&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;BeetleFly&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.737083&lt;/td&gt;
      &lt;td&gt;0.697668&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;InlineSkate&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.961044&lt;/td&gt;
      &lt;td&gt;1.951494&lt;/td&gt;
      &lt;td&gt;0.152727&lt;/td&gt;
      &lt;td&gt;0.152727&lt;/td&gt;
      &lt;td&gt;0.152727&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;MiddlePhalanxTW&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.589655&lt;/td&gt;
      &lt;td&gt;1.749170&lt;/td&gt;
      &lt;td&gt;0.272727&lt;/td&gt;
      &lt;td&gt;0.272727&lt;/td&gt;
      &lt;td&gt;0.272727&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;OliveOil&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.667427&lt;/td&gt;
      &lt;td&gt;1.428959&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;SmallKitchenAppliances&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.135667&lt;/td&gt;
      &lt;td&gt;1.109895&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;WordSynonyms&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3.382129&lt;/td&gt;
      &lt;td&gt;3.268570&lt;/td&gt;
      &lt;td&gt;0.021944&lt;/td&gt;
      &lt;td&gt;0.021944&lt;/td&gt;
      &lt;td&gt;0.021944&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;MiddlePhalanxOutlineAgeGroup&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.000210&lt;/td&gt;
      &lt;td&gt;1.080597&lt;/td&gt;
      &lt;td&gt;0.571429&lt;/td&gt;
      &lt;td&gt;0.571429&lt;/td&gt;
      &lt;td&gt;0.571429&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;MoteStrain&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.709574&lt;/td&gt;
      &lt;td&gt;0.690208&lt;/td&gt;
      &lt;td&gt;0.539137&lt;/td&gt;
      &lt;td&gt;0.539137&lt;/td&gt;
      &lt;td&gt;0.539137&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Phoneme&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3.737337&lt;/td&gt;
      &lt;td&gt;3.657671&lt;/td&gt;
      &lt;td&gt;0.004747&lt;/td&gt;
      &lt;td&gt;0.004747&lt;/td&gt;
      &lt;td&gt;0.004747&lt;/td&gt;
      &lt;td&gt;72&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Herring&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.862592&lt;/td&gt;
      &lt;td&gt;0.729897&lt;/td&gt;
      &lt;td&gt;0.406250&lt;/td&gt;
      &lt;td&gt;0.406250&lt;/td&gt;
      &lt;td&gt;0.406250&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;ScreenType&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.117127&lt;/td&gt;
      &lt;td&gt;1.100862&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;ChlorineConcentration&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.032640&lt;/td&gt;
      &lt;td&gt;1.065673&lt;/td&gt;
      &lt;td&gt;0.532552&lt;/td&gt;
      &lt;td&gt;0.532552&lt;/td&gt;
      &lt;td&gt;0.532552&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="Time Series Classification"></category><category term="Machine Learning"></category><category term="timeseriesAI"></category><category term="Time Series Classification"></category><category term="fastai_timeseries"></category><category term="TSC bechmark"></category></entry><entry><title>New data augmentation techniques: cutout, mixup &amp; cutmix: Part 3</title><link href="https://mmadkour.xyz%5Cposts/2019/10/Machine%20Learning,%20timeseriesAI,%20Time%20Series%20Classification,%20fastai_timeseries,%20data%20augmentation/" rel="alternate"></link><published>2019-10-12T13:01:00-04:00</published><updated>2019-10-12T13:01:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2019-10-12:/2019/10/Machine Learning, timeseriesAI, Time Series Classification, fastai_timeseries, data augmentation/</id><summary type="html">&lt;p&gt;As you may know, Jeremy Howard claims in his excellent fastai course that data augmentation is perhaps the most important regularization technique when training a model for Computer Vision, second only to getting more data samples (which is often costly or just impossible).&lt;/p&gt;
&lt;p&gt;During the last 2 years a number …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As you may know, Jeremy Howard claims in his excellent fastai course that data augmentation is perhaps the most important regularization technique when training a model for Computer Vision, second only to getting more data samples (which is often costly or just impossible).&lt;/p&gt;
&lt;p&gt;During the last 2 years a number of data augmentation techniques have been developed with excellent results in vision datasets.&lt;/p&gt;
&lt;p&gt;In this notebook we'll see how you can easily apply some of this new data augmentation techniques to time series using fastai, fastai_timeseries and torchtimeseries.models library available at &lt;a href="https://github.com/timeseriesAI/timeseriesAI"&gt;timeseriesAI&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="nx"&gt;javascript&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;collapsible_headings/main&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hide_input/main&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;autosavetime/main&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;execute_time/ExecuteTime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;code_prettify/code_prettify&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;scroll_down/main&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;utils&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;load_extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;jupyter-js-widgets/extension&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;IPython&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Javascript&lt;/span&gt; &lt;span class="k"&gt;object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Import libraries 📚&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;reload_ext&lt;/span&gt; &lt;span class="n"&gt;autoreload&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;autoreload&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;fastai_timeseries&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;torchtimeseries.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;

&lt;h2&gt;Prepare data 🔢&lt;/h2&gt;
&lt;p&gt;First we'll create a databunch for the 'OliveOil' UCR dataset. You can select any other dataset.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dsid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Beef&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_UCR_databunch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dsid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;db&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;TSDataBunch&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="nt"&gt;Train&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;LabelList&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;30&lt;/span&gt; &lt;span class="nt"&gt;items&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;x&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;TimeSeriesList&lt;/span&gt;
&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;y&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;CategoryList&lt;/span&gt;
&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;
&lt;span class="nt"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;.;&lt;/span&gt;

&lt;span class="nt"&gt;Valid&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;LabelList&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;30&lt;/span&gt; &lt;span class="nt"&gt;items&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;x&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;TimeSeriesList&lt;/span&gt;
&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;TimeSeries&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;ch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;seq_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;470&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;y&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;CategoryList&lt;/span&gt;
&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;
&lt;span class="nt"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;.;&lt;/span&gt;

&lt;span class="nt"&gt;Test&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;None&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once the databunch's been built, we can easy visualize time series and their classes using the show_batch method.&lt;/p&gt;
&lt;p&gt;☣️ Remember that these charts represent different time series with their respective labels.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_batch&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/TSC/output_11_0.png"&gt;&lt;/p&gt;
&lt;h2&gt;Build learner 🏗&lt;/h2&gt;
&lt;p&gt;Now I'll create a learner object. As a model I'll use the new Inceptiontime.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;LabelSmoothingCrossEntropy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Train 🚵🏼‍♀️&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_one_cycle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: left;"&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1.697133&lt;/td&gt;
      &lt;td&gt;1.636551&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.658765&lt;/td&gt;
      &lt;td&gt;1.634878&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1.628749&lt;/td&gt;
      &lt;td&gt;1.633871&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1.603675&lt;/td&gt;
      &lt;td&gt;1.633338&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1.581709&lt;/td&gt;
      &lt;td&gt;1.633209&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1.562016&lt;/td&gt;
      &lt;td&gt;1.633017&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;1.543772&lt;/td&gt;
      &lt;td&gt;1.632773&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1.526412&lt;/td&gt;
      &lt;td&gt;1.632591&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;1.509713&lt;/td&gt;
      &lt;td&gt;1.632315&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;1.493474&lt;/td&gt;
      &lt;td&gt;1.631614&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1.477614&lt;/td&gt;
      &lt;td&gt;1.630401&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;1.462065&lt;/td&gt;
      &lt;td&gt;1.628628&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1.446795&lt;/td&gt;
      &lt;td&gt;1.626409&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;1.431797&lt;/td&gt;
      &lt;td&gt;1.623053&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;1.417064&lt;/td&gt;
      &lt;td&gt;1.619603&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;1.402596&lt;/td&gt;
      &lt;td&gt;1.613142&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1.388477&lt;/td&gt;
      &lt;td&gt;1.609142&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;1.374838&lt;/td&gt;
      &lt;td&gt;1.595912&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1.361802&lt;/td&gt;
      &lt;td&gt;1.584519&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;1.348744&lt;/td&gt;
      &lt;td&gt;1.574727&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;1.335601&lt;/td&gt;
      &lt;td&gt;1.558694&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;1.322362&lt;/td&gt;
      &lt;td&gt;1.539030&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;1.309687&lt;/td&gt;
      &lt;td&gt;1.525543&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;1.297099&lt;/td&gt;
      &lt;td&gt;1.525444&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;1.287485&lt;/td&gt;
      &lt;td&gt;1.487910&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;1.278417&lt;/td&gt;
      &lt;td&gt;1.451224&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;1.267326&lt;/td&gt;
      &lt;td&gt;1.419333&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;1.255071&lt;/td&gt;
      &lt;td&gt;1.531612&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;1.245143&lt;/td&gt;
      &lt;td&gt;1.428932&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;1.233745&lt;/td&gt;
      &lt;td&gt;1.673071&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;1.222732&lt;/td&gt;
      &lt;td&gt;1.317958&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1.210769&lt;/td&gt;
      &lt;td&gt;1.317483&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;1.197816&lt;/td&gt;
      &lt;td&gt;1.636617&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;1.183761&lt;/td&gt;
      &lt;td&gt;1.968882&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;1.169847&lt;/td&gt;
      &lt;td&gt;1.360843&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;1.156803&lt;/td&gt;
      &lt;td&gt;1.217057&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;1.142337&lt;/td&gt;
      &lt;td&gt;2.626117&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;1.130414&lt;/td&gt;
      &lt;td&gt;1.677359&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;1.122333&lt;/td&gt;
      &lt;td&gt;1.932176&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;1.116616&lt;/td&gt;
      &lt;td&gt;1.541641&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;1.105934&lt;/td&gt;
      &lt;td&gt;2.903922&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;1.094385&lt;/td&gt;
      &lt;td&gt;5.271531&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;1.082686&lt;/td&gt;
      &lt;td&gt;5.667654&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;1.070797&lt;/td&gt;
      &lt;td&gt;4.902615&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;44&lt;/td&gt;
      &lt;td&gt;1.058120&lt;/td&gt;
      &lt;td&gt;7.664695&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;1.047126&lt;/td&gt;
      &lt;td&gt;4.719625&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;1.040817&lt;/td&gt;
      &lt;td&gt;3.125497&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;1.033824&lt;/td&gt;
      &lt;td&gt;5.493695&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;48&lt;/td&gt;
      &lt;td&gt;1.025297&lt;/td&gt;
      &lt;td&gt;6.714429&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;49&lt;/td&gt;
      &lt;td&gt;1.016156&lt;/td&gt;
      &lt;td&gt;7.241136&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;1.004743&lt;/td&gt;
      &lt;td&gt;6.179959&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;0.993645&lt;/td&gt;
      &lt;td&gt;8.953449&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;52&lt;/td&gt;
      &lt;td&gt;0.982641&lt;/td&gt;
      &lt;td&gt;11.618028&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;0.972119&lt;/td&gt;
      &lt;td&gt;8.661292&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;0.961185&lt;/td&gt;
      &lt;td&gt;7.684217&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;0.949132&lt;/td&gt;
      &lt;td&gt;9.823573&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;0.937367&lt;/td&gt;
      &lt;td&gt;10.694403&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;57&lt;/td&gt;
      &lt;td&gt;0.925187&lt;/td&gt;
      &lt;td&gt;12.210872&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;0.913146&lt;/td&gt;
      &lt;td&gt;14.403736&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;0.901192&lt;/td&gt;
      &lt;td&gt;13.310433&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;0.889542&lt;/td&gt;
      &lt;td&gt;12.824086&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;0.879126&lt;/td&gt;
      &lt;td&gt;14.573278&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;0.870193&lt;/td&gt;
      &lt;td&gt;11.141336&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;63&lt;/td&gt;
      &lt;td&gt;0.861951&lt;/td&gt;
      &lt;td&gt;4.968851&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;0.854350&lt;/td&gt;
      &lt;td&gt;9.333371&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;65&lt;/td&gt;
      &lt;td&gt;0.847897&lt;/td&gt;
      &lt;td&gt;2.665716&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;66&lt;/td&gt;
      &lt;td&gt;0.842686&lt;/td&gt;
      &lt;td&gt;2.313952&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;0.834853&lt;/td&gt;
      &lt;td&gt;3.875152&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;0.827271&lt;/td&gt;
      &lt;td&gt;2.235546&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;69&lt;/td&gt;
      &lt;td&gt;0.819326&lt;/td&gt;
      &lt;td&gt;2.601296&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;0.811829&lt;/td&gt;
      &lt;td&gt;3.508690&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;0.804304&lt;/td&gt;
      &lt;td&gt;4.183553&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;0.797064&lt;/td&gt;
      &lt;td&gt;3.399729&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;0.789246&lt;/td&gt;
      &lt;td&gt;2.493759&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;0.781297&lt;/td&gt;
      &lt;td&gt;1.851689&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;0.773465&lt;/td&gt;
      &lt;td&gt;1.665282&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;76&lt;/td&gt;
      &lt;td&gt;0.765998&lt;/td&gt;
      &lt;td&gt;5.534258&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;77&lt;/td&gt;
      &lt;td&gt;0.758704&lt;/td&gt;
      &lt;td&gt;1.918662&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;78&lt;/td&gt;
      &lt;td&gt;0.750972&lt;/td&gt;
      &lt;td&gt;2.003186&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;0.743452&lt;/td&gt;
      &lt;td&gt;1.611230&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;0.736011&lt;/td&gt;
      &lt;td&gt;1.628435&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;0.728675&lt;/td&gt;
      &lt;td&gt;1.465575&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;0.721576&lt;/td&gt;
      &lt;td&gt;0.969776&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;0.714612&lt;/td&gt;
      &lt;td&gt;0.898719&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;84&lt;/td&gt;
      &lt;td&gt;0.707672&lt;/td&gt;
      &lt;td&gt;1.032310&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;0.700603&lt;/td&gt;
      &lt;td&gt;1.012637&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;86&lt;/td&gt;
      &lt;td&gt;0.693883&lt;/td&gt;
      &lt;td&gt;1.637516&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;87&lt;/td&gt;
      &lt;td&gt;0.687245&lt;/td&gt;
      &lt;td&gt;1.379606&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;88&lt;/td&gt;
      &lt;td&gt;0.680597&lt;/td&gt;
      &lt;td&gt;0.982019&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;89&lt;/td&gt;
      &lt;td&gt;0.674161&lt;/td&gt;
      &lt;td&gt;1.008814&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;0.667775&lt;/td&gt;
      &lt;td&gt;1.266140&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;91&lt;/td&gt;
      &lt;td&gt;0.661540&lt;/td&gt;
      &lt;td&gt;1.079461&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;92&lt;/td&gt;
      &lt;td&gt;0.655445&lt;/td&gt;
      &lt;td&gt;0.770133&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;93&lt;/td&gt;
      &lt;td&gt;0.649447&lt;/td&gt;
      &lt;td&gt;0.776157&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;94&lt;/td&gt;
      &lt;td&gt;0.643603&lt;/td&gt;
      &lt;td&gt;0.780240&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;95&lt;/td&gt;
      &lt;td&gt;0.637886&lt;/td&gt;
      &lt;td&gt;0.794417&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;0.632302&lt;/td&gt;
      &lt;td&gt;0.794495&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;97&lt;/td&gt;
      &lt;td&gt;0.626835&lt;/td&gt;
      &lt;td&gt;0.836716&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;98&lt;/td&gt;
      &lt;td&gt;0.621506&lt;/td&gt;
      &lt;td&gt;0.952855&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;99&lt;/td&gt;
      &lt;td&gt;0.616283&lt;/td&gt;
      &lt;td&gt;1.031987&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;0.611199&lt;/td&gt;
      &lt;td&gt;0.992564&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;101&lt;/td&gt;
      &lt;td&gt;0.606229&lt;/td&gt;
      &lt;td&gt;0.990812&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;0.601378&lt;/td&gt;
      &lt;td&gt;1.038975&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;0.596639&lt;/td&gt;
      &lt;td&gt;0.925851&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;104&lt;/td&gt;
      &lt;td&gt;0.592018&lt;/td&gt;
      &lt;td&gt;0.839252&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;105&lt;/td&gt;
      &lt;td&gt;0.587503&lt;/td&gt;
      &lt;td&gt;0.846729&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;0.583092&lt;/td&gt;
      &lt;td&gt;0.876285&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;0.578791&lt;/td&gt;
      &lt;td&gt;0.867612&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;108&lt;/td&gt;
      &lt;td&gt;0.574593&lt;/td&gt;
      &lt;td&gt;0.865421&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;0.570497&lt;/td&gt;
      &lt;td&gt;0.861011&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;0.566498&lt;/td&gt;
      &lt;td&gt;0.860369&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;111&lt;/td&gt;
      &lt;td&gt;0.562593&lt;/td&gt;
      &lt;td&gt;0.856723&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;112&lt;/td&gt;
      &lt;td&gt;0.558781&lt;/td&gt;
      &lt;td&gt;0.857777&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;113&lt;/td&gt;
      &lt;td&gt;0.555063&lt;/td&gt;
      &lt;td&gt;0.861587&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;114&lt;/td&gt;
      &lt;td&gt;0.551431&lt;/td&gt;
      &lt;td&gt;0.864382&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;115&lt;/td&gt;
      &lt;td&gt;0.547886&lt;/td&gt;
      &lt;td&gt;0.866298&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;0.544424&lt;/td&gt;
      &lt;td&gt;0.866298&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;117&lt;/td&gt;
      &lt;td&gt;0.541043&lt;/td&gt;
      &lt;td&gt;0.876166&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;118&lt;/td&gt;
      &lt;td&gt;0.537743&lt;/td&gt;
      &lt;td&gt;0.877081&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;119&lt;/td&gt;
      &lt;td&gt;0.534521&lt;/td&gt;
      &lt;td&gt;0.870586&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;0.531374&lt;/td&gt;
      &lt;td&gt;0.871706&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;121&lt;/td&gt;
      &lt;td&gt;0.528300&lt;/td&gt;
      &lt;td&gt;0.868688&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;122&lt;/td&gt;
      &lt;td&gt;0.525299&lt;/td&gt;
      &lt;td&gt;0.864780&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;123&lt;/td&gt;
      &lt;td&gt;0.522367&lt;/td&gt;
      &lt;td&gt;0.863685&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;124&lt;/td&gt;
      &lt;td&gt;0.519504&lt;/td&gt;
      &lt;td&gt;0.860523&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;125&lt;/td&gt;
      &lt;td&gt;0.516706&lt;/td&gt;
      &lt;td&gt;0.858484&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;126&lt;/td&gt;
      &lt;td&gt;0.513973&lt;/td&gt;
      &lt;td&gt;0.856415&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;127&lt;/td&gt;
      &lt;td&gt;0.511304&lt;/td&gt;
      &lt;td&gt;0.855038&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;0.508696&lt;/td&gt;
      &lt;td&gt;0.854263&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;129&lt;/td&gt;
      &lt;td&gt;0.506147&lt;/td&gt;
      &lt;td&gt;0.853070&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;0.503657&lt;/td&gt;
      &lt;td&gt;0.851796&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;131&lt;/td&gt;
      &lt;td&gt;0.501223&lt;/td&gt;
      &lt;td&gt;0.852567&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;132&lt;/td&gt;
      &lt;td&gt;0.498845&lt;/td&gt;
      &lt;td&gt;0.849896&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;133&lt;/td&gt;
      &lt;td&gt;0.496521&lt;/td&gt;
      &lt;td&gt;0.847939&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;134&lt;/td&gt;
      &lt;td&gt;0.494250&lt;/td&gt;
      &lt;td&gt;0.847190&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;135&lt;/td&gt;
      &lt;td&gt;0.492030&lt;/td&gt;
      &lt;td&gt;0.846976&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;0.489860&lt;/td&gt;
      &lt;td&gt;0.848106&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;0.487739&lt;/td&gt;
      &lt;td&gt;0.849875&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;138&lt;/td&gt;
      &lt;td&gt;0.485665&lt;/td&gt;
      &lt;td&gt;0.849752&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;139&lt;/td&gt;
      &lt;td&gt;0.483638&lt;/td&gt;
      &lt;td&gt;0.850015&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;140&lt;/td&gt;
      &lt;td&gt;0.481656&lt;/td&gt;
      &lt;td&gt;0.851885&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;141&lt;/td&gt;
      &lt;td&gt;0.479719&lt;/td&gt;
      &lt;td&gt;0.855177&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;142&lt;/td&gt;
      &lt;td&gt;0.477824&lt;/td&gt;
      &lt;td&gt;0.856939&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;0.475971&lt;/td&gt;
      &lt;td&gt;0.856017&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;144&lt;/td&gt;
      &lt;td&gt;0.474160&lt;/td&gt;
      &lt;td&gt;0.854898&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;0.472389&lt;/td&gt;
      &lt;td&gt;0.854715&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;146&lt;/td&gt;
      &lt;td&gt;0.470656&lt;/td&gt;
      &lt;td&gt;0.854882&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;147&lt;/td&gt;
      &lt;td&gt;0.468962&lt;/td&gt;
      &lt;td&gt;0.854378&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;148&lt;/td&gt;
      &lt;td&gt;0.467305&lt;/td&gt;
      &lt;td&gt;0.853540&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;149&lt;/td&gt;
      &lt;td&gt;0.465685&lt;/td&gt;
      &lt;td&gt;0.853437&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;0.464100&lt;/td&gt;
      &lt;td&gt;0.854188&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;151&lt;/td&gt;
      &lt;td&gt;0.462550&lt;/td&gt;
      &lt;td&gt;0.855247&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;152&lt;/td&gt;
      &lt;td&gt;0.461033&lt;/td&gt;
      &lt;td&gt;0.855636&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;153&lt;/td&gt;
      &lt;td&gt;0.459550&lt;/td&gt;
      &lt;td&gt;0.855190&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;0.458098&lt;/td&gt;
      &lt;td&gt;0.854677&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;155&lt;/td&gt;
      &lt;td&gt;0.456679&lt;/td&gt;
      &lt;td&gt;0.854630&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;156&lt;/td&gt;
      &lt;td&gt;0.455290&lt;/td&gt;
      &lt;td&gt;0.855154&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;157&lt;/td&gt;
      &lt;td&gt;0.453931&lt;/td&gt;
      &lt;td&gt;0.855961&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;0.452602&lt;/td&gt;
      &lt;td&gt;0.856542&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;159&lt;/td&gt;
      &lt;td&gt;0.451301&lt;/td&gt;
      &lt;td&gt;0.856716&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;0.450029&lt;/td&gt;
      &lt;td&gt;0.856649&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;161&lt;/td&gt;
      &lt;td&gt;0.448783&lt;/td&gt;
      &lt;td&gt;0.856666&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;0.447565&lt;/td&gt;
      &lt;td&gt;0.856919&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;163&lt;/td&gt;
      &lt;td&gt;0.446372&lt;/td&gt;
      &lt;td&gt;0.857375&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;164&lt;/td&gt;
      &lt;td&gt;0.445206&lt;/td&gt;
      &lt;td&gt;0.857843&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;165&lt;/td&gt;
      &lt;td&gt;0.444064&lt;/td&gt;
      &lt;td&gt;0.858171&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;166&lt;/td&gt;
      &lt;td&gt;0.442946&lt;/td&gt;
      &lt;td&gt;0.858309&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;167&lt;/td&gt;
      &lt;td&gt;0.441853&lt;/td&gt;
      &lt;td&gt;0.858343&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;168&lt;/td&gt;
      &lt;td&gt;0.440783&lt;/td&gt;
      &lt;td&gt;0.858372&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;0.439735&lt;/td&gt;
      &lt;td&gt;0.858487&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;170&lt;/td&gt;
      &lt;td&gt;0.438710&lt;/td&gt;
      &lt;td&gt;0.858700&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;171&lt;/td&gt;
      &lt;td&gt;0.437707&lt;/td&gt;
      &lt;td&gt;0.858980&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;172&lt;/td&gt;
      &lt;td&gt;0.436725&lt;/td&gt;
      &lt;td&gt;0.859262&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;0.435763&lt;/td&gt;
      &lt;td&gt;0.859469&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;174&lt;/td&gt;
      &lt;td&gt;0.434822&lt;/td&gt;
      &lt;td&gt;0.859581&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;175&lt;/td&gt;
      &lt;td&gt;0.433901&lt;/td&gt;
      &lt;td&gt;0.859597&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;176&lt;/td&gt;
      &lt;td&gt;0.433000&lt;/td&gt;
      &lt;td&gt;0.859544&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;177&lt;/td&gt;
      &lt;td&gt;0.432117&lt;/td&gt;
      &lt;td&gt;0.859459&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;178&lt;/td&gt;
      &lt;td&gt;0.431253&lt;/td&gt;
      &lt;td&gt;0.859385&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;179&lt;/td&gt;
      &lt;td&gt;0.430408&lt;/td&gt;
      &lt;td&gt;0.859341&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;180&lt;/td&gt;
      &lt;td&gt;0.429580&lt;/td&gt;
      &lt;td&gt;0.859343&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;181&lt;/td&gt;
      &lt;td&gt;0.428769&lt;/td&gt;
      &lt;td&gt;0.859393&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;0.427976&lt;/td&gt;
      &lt;td&gt;0.859490&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;0.427199&lt;/td&gt;
      &lt;td&gt;0.859620&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;184&lt;/td&gt;
      &lt;td&gt;0.426438&lt;/td&gt;
      &lt;td&gt;0.859767&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;185&lt;/td&gt;
      &lt;td&gt;0.425694&lt;/td&gt;
      &lt;td&gt;0.859917&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;186&lt;/td&gt;
      &lt;td&gt;0.424965&lt;/td&gt;
      &lt;td&gt;0.860061&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;187&lt;/td&gt;
      &lt;td&gt;0.424251&lt;/td&gt;
      &lt;td&gt;0.860193&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;188&lt;/td&gt;
      &lt;td&gt;0.423552&lt;/td&gt;
      &lt;td&gt;0.860311&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;189&lt;/td&gt;
      &lt;td&gt;0.422868&lt;/td&gt;
      &lt;td&gt;0.860409&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;190&lt;/td&gt;
      &lt;td&gt;0.422198&lt;/td&gt;
      &lt;td&gt;0.860496&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;191&lt;/td&gt;
      &lt;td&gt;0.421542&lt;/td&gt;
      &lt;td&gt;0.860570&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192&lt;/td&gt;
      &lt;td&gt;0.420899&lt;/td&gt;
      &lt;td&gt;0.860630&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;193&lt;/td&gt;
      &lt;td&gt;0.420270&lt;/td&gt;
      &lt;td&gt;0.860679&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;194&lt;/td&gt;
      &lt;td&gt;0.419654&lt;/td&gt;
      &lt;td&gt;0.860717&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;0.419051&lt;/td&gt;
      &lt;td&gt;0.860749&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;196&lt;/td&gt;
      &lt;td&gt;0.418461&lt;/td&gt;
      &lt;td&gt;0.860777&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;197&lt;/td&gt;
      &lt;td&gt;0.417882&lt;/td&gt;
      &lt;td&gt;0.860800&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;198&lt;/td&gt;
      &lt;td&gt;0.417316&lt;/td&gt;
      &lt;td&gt;0.860822&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;199&lt;/td&gt;
      &lt;td&gt;0.416761&lt;/td&gt;
      &lt;td&gt;0.860841&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;83.3% is a pretty good result with the Beef dataset. But let's see if we can improve it even further by using data augmentation.&lt;/p&gt;
&lt;h2&gt;Applying data augmentation techniques&lt;/h2&gt;
&lt;p&gt;In some cases, data augmentation is applied to a single time series. Changes are applied to that individual time series. One of these techniques is Cutout.&lt;/p&gt;
&lt;p&gt;More recently, new data augmentations have appeared that combine a time series with another randomly selected time series, blending both in some way. 2 important techniques applicable to time series are Mixup and CutMix.&lt;/p&gt;
&lt;p&gt;All these techniques work really well in images, but are not still often used with time series. &lt;/p&gt;
&lt;h2&gt;Data augmentation: Single Time Series&lt;/h2&gt;
&lt;p&gt;You'll see that applying these techniques is super easy. You only need to add the required callback.&lt;/p&gt;
&lt;h3&gt;Cutout (DeVries, 2017)&lt;/h3&gt;
&lt;p&gt;https://arxiv.org/abs/1708.04552&lt;/p&gt;
&lt;p&gt;This is a single item transformation, where &lt;strong&gt;a random section of a time series is is replaced by zero&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;You can apply all thes techniques in 2 ways (the result is exactly the same):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cutout&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cutout&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since you cannot see the impact of the technique, I've built a function (show_tfms) to be able to easily visualize it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cutout&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_tfms&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/TSC/output_27_0.png"&gt;&lt;/p&gt;
&lt;p&gt;☣️ Remember that all these are examples of the &lt;strong&gt;same time series, once cutout has been applied&lt;/strong&gt;. All techniques in this notebook are applied randomly on the fly, thus generating an endless amount of variations.&lt;/p&gt;
&lt;h4&gt;Parameter&lt;/h4&gt;
&lt;p&gt;These techniques have a parameter that define the amount of change from the original time series. It's called &lt;strong&gt;alpha&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;For cutout, the default alpha is set to 1, but you can modify it up or down, depending on how much regularization you want to apply.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cutout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_tfms&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/TSC/output_31_0.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cutout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_tfms&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/TSC/output_32_0.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cutout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_tfms&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/TSC/output_33_0.png"&gt;&lt;/p&gt;
&lt;p&gt;The default value is reasonable, but feel free to modify it.&lt;/p&gt;
&lt;h2&gt;Data augmentation: Multi Time Series&lt;/h2&gt;
&lt;p&gt;There are at least a couple of things multiTS data transforms have in common: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;they combine 2 or more TS to create a new synthetic TS&lt;/li&gt;
&lt;li&gt;unlike previous techniques like cutout, the entire TS provides informative datapoints. &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Mixup (Zhang, 2018)&lt;/h3&gt;
&lt;p&gt;https://arxiv.org/abs/1710.09412&lt;/p&gt;
&lt;p&gt;Mixup blends two time series randomly drawn from our training data. A weight λ (between .5-1) is assigned to the first sample, and 1-λ to the second one. 
Despite its simplicity, mixup allows a new state-of-the-art performance in the CIFAR-10, CIFAR- 100, and ImageNet-2012 image classification datasets, and can also improve performance in time series problems.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mixup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_tfms&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/TSC/output_39_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Mixup creates time series that look very 'real', based on a weighted average of 2 time series.&lt;/p&gt;
&lt;p&gt;The parameter for mixup is called alpha, and it's default value set to .4. Usual values range between .2-.4, although you can use any number greater than 0.&lt;/p&gt;
&lt;h3&gt;Cutmix (Yun, 2019)&lt;/h3&gt;
&lt;p&gt;https://arxiv.org/abs/1905.04899&lt;/p&gt;
&lt;p&gt;Cutmix is similar to Cutout, as a single patch is cut and pasted into a different training Time Series.&lt;/p&gt;
&lt;p&gt;CutMix consistently outperforms the state-of-the-art augmentation strategies on CIFAR and ImageNet classification tasks, as well as on the ImageNet weakly- supervised localization task.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cutmix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_tfms&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/TSC/output_44_0.png"&gt;&lt;/p&gt;
&lt;p&gt;For cutmix the default value of alpha is also 1.&lt;/p&gt;
&lt;h2&gt;How to train using data augmentation?&lt;/h2&gt;
&lt;p&gt;It's super easy! The only thing you need to do is: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First you will create your ImageDataBunch as you would normally do.&lt;/li&gt;
&lt;li&gt;The you will create the learner as usual, but you will add to it the selected augmentation you have selected (cutmix, mixup or cutmix). You can only select one of these new data augmentations at a time.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Mixup&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dsis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Beef&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_UCR_databunch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dsid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;LabelSmoothingCrossEntropy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mixup&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;If you want to visualize the effect data augmentation before training (to adjust alpha for example), just add show_tfms()&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_tfms&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/TSC/output_51_0.png"&gt;&lt;/p&gt;
&lt;p&gt;That's it!!. 
You are now ready to train with data augmentation!!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_one_cycle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: left;"&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1.689828&lt;/td&gt;
      &lt;td&gt;1.619471&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.673922&lt;/td&gt;
      &lt;td&gt;1.618781&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1.647962&lt;/td&gt;
      &lt;td&gt;1.618125&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1.631207&lt;/td&gt;
      &lt;td&gt;1.617363&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1.611909&lt;/td&gt;
      &lt;td&gt;1.616646&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1.595307&lt;/td&gt;
      &lt;td&gt;1.615953&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;1.578687&lt;/td&gt;
      &lt;td&gt;1.615269&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1.563238&lt;/td&gt;
      &lt;td&gt;1.614500&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;1.548130&lt;/td&gt;
      &lt;td&gt;1.613729&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;1.534638&lt;/td&gt;
      &lt;td&gt;1.612713&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1.522140&lt;/td&gt;
      &lt;td&gt;1.611550&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;1.512481&lt;/td&gt;
      &lt;td&gt;1.610328&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1.499381&lt;/td&gt;
      &lt;td&gt;1.608953&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;1.486657&lt;/td&gt;
      &lt;td&gt;1.607466&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;1.474970&lt;/td&gt;
      &lt;td&gt;1.605166&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;1.464807&lt;/td&gt;
      &lt;td&gt;1.602398&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1.450602&lt;/td&gt;
      &lt;td&gt;1.599006&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;1.441010&lt;/td&gt;
      &lt;td&gt;1.592957&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1.431140&lt;/td&gt;
      &lt;td&gt;1.585209&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;1.420655&lt;/td&gt;
      &lt;td&gt;1.575528&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;1.411091&lt;/td&gt;
      &lt;td&gt;1.568540&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;1.401187&lt;/td&gt;
      &lt;td&gt;1.557126&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;1.393381&lt;/td&gt;
      &lt;td&gt;1.547969&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;1.386891&lt;/td&gt;
      &lt;td&gt;1.509804&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;1.380682&lt;/td&gt;
      &lt;td&gt;1.517822&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;1.372284&lt;/td&gt;
      &lt;td&gt;1.507112&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;1.363400&lt;/td&gt;
      &lt;td&gt;1.529526&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;1.356471&lt;/td&gt;
      &lt;td&gt;1.546933&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;1.345878&lt;/td&gt;
      &lt;td&gt;1.476422&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;1.338359&lt;/td&gt;
      &lt;td&gt;1.489565&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;1.328831&lt;/td&gt;
      &lt;td&gt;1.370115&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1.319710&lt;/td&gt;
      &lt;td&gt;1.492780&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;1.310245&lt;/td&gt;
      &lt;td&gt;1.909312&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;1.304384&lt;/td&gt;
      &lt;td&gt;1.942166&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;1.298426&lt;/td&gt;
      &lt;td&gt;1.449292&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;1.296161&lt;/td&gt;
      &lt;td&gt;1.392294&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;1.287528&lt;/td&gt;
      &lt;td&gt;1.707830&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;1.279770&lt;/td&gt;
      &lt;td&gt;1.918631&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;1.270381&lt;/td&gt;
      &lt;td&gt;1.791980&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;1.259860&lt;/td&gt;
      &lt;td&gt;3.575068&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;1.254035&lt;/td&gt;
      &lt;td&gt;2.539945&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;1.245580&lt;/td&gt;
      &lt;td&gt;1.968613&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;1.237224&lt;/td&gt;
      &lt;td&gt;2.108842&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;1.228153&lt;/td&gt;
      &lt;td&gt;2.946331&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;44&lt;/td&gt;
      &lt;td&gt;1.220387&lt;/td&gt;
      &lt;td&gt;3.205979&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;1.212358&lt;/td&gt;
      &lt;td&gt;3.939463&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;1.208177&lt;/td&gt;
      &lt;td&gt;5.770495&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;1.201450&lt;/td&gt;
      &lt;td&gt;3.143615&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;48&lt;/td&gt;
      &lt;td&gt;1.195719&lt;/td&gt;
      &lt;td&gt;2.494654&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;49&lt;/td&gt;
      &lt;td&gt;1.189962&lt;/td&gt;
      &lt;td&gt;4.610262&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;1.184943&lt;/td&gt;
      &lt;td&gt;3.094051&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;1.178857&lt;/td&gt;
      &lt;td&gt;4.785711&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;52&lt;/td&gt;
      &lt;td&gt;1.173128&lt;/td&gt;
      &lt;td&gt;5.147786&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;1.166027&lt;/td&gt;
      &lt;td&gt;4.195990&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;1.158504&lt;/td&gt;
      &lt;td&gt;4.618266&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;1.154156&lt;/td&gt;
      &lt;td&gt;5.224677&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;1.146860&lt;/td&gt;
      &lt;td&gt;5.487449&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;57&lt;/td&gt;
      &lt;td&gt;1.143896&lt;/td&gt;
      &lt;td&gt;3.752536&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;1.139026&lt;/td&gt;
      &lt;td&gt;3.471848&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;1.132638&lt;/td&gt;
      &lt;td&gt;3.616133&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;1.127449&lt;/td&gt;
      &lt;td&gt;3.148611&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;1.119508&lt;/td&gt;
      &lt;td&gt;2.473933&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;1.111254&lt;/td&gt;
      &lt;td&gt;2.150029&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;63&lt;/td&gt;
      &lt;td&gt;1.103141&lt;/td&gt;
      &lt;td&gt;1.433178&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;1.095411&lt;/td&gt;
      &lt;td&gt;1.055387&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;65&lt;/td&gt;
      &lt;td&gt;1.088881&lt;/td&gt;
      &lt;td&gt;1.327046&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;66&lt;/td&gt;
      &lt;td&gt;1.081982&lt;/td&gt;
      &lt;td&gt;1.605395&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;1.079995&lt;/td&gt;
      &lt;td&gt;2.084538&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;1.077057&lt;/td&gt;
      &lt;td&gt;2.170066&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;69&lt;/td&gt;
      &lt;td&gt;1.073893&lt;/td&gt;
      &lt;td&gt;2.078325&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;1.070387&lt;/td&gt;
      &lt;td&gt;5.268016&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;1.065864&lt;/td&gt;
      &lt;td&gt;10.335102&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;1.064703&lt;/td&gt;
      &lt;td&gt;4.640256&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1.061717&lt;/td&gt;
      &lt;td&gt;1.847973&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;1.060507&lt;/td&gt;
      &lt;td&gt;1.547381&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;1.057674&lt;/td&gt;
      &lt;td&gt;1.439578&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;76&lt;/td&gt;
      &lt;td&gt;1.055321&lt;/td&gt;
      &lt;td&gt;1.494718&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;77&lt;/td&gt;
      &lt;td&gt;1.054715&lt;/td&gt;
      &lt;td&gt;2.734326&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;78&lt;/td&gt;
      &lt;td&gt;1.049378&lt;/td&gt;
      &lt;td&gt;1.831880&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;1.048055&lt;/td&gt;
      &lt;td&gt;1.342813&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;1.045389&lt;/td&gt;
      &lt;td&gt;1.058503&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;1.038875&lt;/td&gt;
      &lt;td&gt;2.418780&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;1.036652&lt;/td&gt;
      &lt;td&gt;3.206536&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;1.034173&lt;/td&gt;
      &lt;td&gt;2.932166&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;84&lt;/td&gt;
      &lt;td&gt;1.030047&lt;/td&gt;
      &lt;td&gt;2.636901&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;1.027156&lt;/td&gt;
      &lt;td&gt;2.956616&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;86&lt;/td&gt;
      &lt;td&gt;1.020752&lt;/td&gt;
      &lt;td&gt;3.017718&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;87&lt;/td&gt;
      &lt;td&gt;1.016966&lt;/td&gt;
      &lt;td&gt;2.859704&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;88&lt;/td&gt;
      &lt;td&gt;1.011848&lt;/td&gt;
      &lt;td&gt;2.513342&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;89&lt;/td&gt;
      &lt;td&gt;1.007957&lt;/td&gt;
      &lt;td&gt;2.365700&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;1.003033&lt;/td&gt;
      &lt;td&gt;2.211102&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;91&lt;/td&gt;
      &lt;td&gt;1.000160&lt;/td&gt;
      &lt;td&gt;2.693544&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;92&lt;/td&gt;
      &lt;td&gt;0.995621&lt;/td&gt;
      &lt;td&gt;2.895486&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;93&lt;/td&gt;
      &lt;td&gt;0.995153&lt;/td&gt;
      &lt;td&gt;2.610945&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;94&lt;/td&gt;
      &lt;td&gt;0.991598&lt;/td&gt;
      &lt;td&gt;2.286873&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;95&lt;/td&gt;
      &lt;td&gt;0.988696&lt;/td&gt;
      &lt;td&gt;2.728762&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;0.987154&lt;/td&gt;
      &lt;td&gt;2.344796&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;97&lt;/td&gt;
      &lt;td&gt;0.983275&lt;/td&gt;
      &lt;td&gt;3.232719&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;98&lt;/td&gt;
      &lt;td&gt;0.980970&lt;/td&gt;
      &lt;td&gt;1.335799&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;99&lt;/td&gt;
      &lt;td&gt;0.977147&lt;/td&gt;
      &lt;td&gt;1.167713&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;0.972813&lt;/td&gt;
      &lt;td&gt;1.170871&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;101&lt;/td&gt;
      &lt;td&gt;0.971278&lt;/td&gt;
      &lt;td&gt;1.362768&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;0.969613&lt;/td&gt;
      &lt;td&gt;1.461215&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;0.965762&lt;/td&gt;
      &lt;td&gt;1.476665&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;104&lt;/td&gt;
      &lt;td&gt;0.960326&lt;/td&gt;
      &lt;td&gt;2.355848&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;105&lt;/td&gt;
      &lt;td&gt;0.955352&lt;/td&gt;
      &lt;td&gt;2.981581&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;0.949955&lt;/td&gt;
      &lt;td&gt;3.107812&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;0.946355&lt;/td&gt;
      &lt;td&gt;2.925362&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;108&lt;/td&gt;
      &lt;td&gt;0.940663&lt;/td&gt;
      &lt;td&gt;2.415063&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;0.938540&lt;/td&gt;
      &lt;td&gt;1.688057&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;0.937894&lt;/td&gt;
      &lt;td&gt;1.362045&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;111&lt;/td&gt;
      &lt;td&gt;0.933151&lt;/td&gt;
      &lt;td&gt;1.243008&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;112&lt;/td&gt;
      &lt;td&gt;0.932395&lt;/td&gt;
      &lt;td&gt;1.176888&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;113&lt;/td&gt;
      &lt;td&gt;0.928695&lt;/td&gt;
      &lt;td&gt;1.349458&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;114&lt;/td&gt;
      &lt;td&gt;0.926381&lt;/td&gt;
      &lt;td&gt;1.627350&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;115&lt;/td&gt;
      &lt;td&gt;0.921778&lt;/td&gt;
      &lt;td&gt;1.600521&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;0.917558&lt;/td&gt;
      &lt;td&gt;1.366820&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;117&lt;/td&gt;
      &lt;td&gt;0.912869&lt;/td&gt;
      &lt;td&gt;1.430818&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;118&lt;/td&gt;
      &lt;td&gt;0.909506&lt;/td&gt;
      &lt;td&gt;1.488323&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;119&lt;/td&gt;
      &lt;td&gt;0.908174&lt;/td&gt;
      &lt;td&gt;1.238361&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;0.906753&lt;/td&gt;
      &lt;td&gt;0.972730&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;121&lt;/td&gt;
      &lt;td&gt;0.902651&lt;/td&gt;
      &lt;td&gt;0.901888&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;122&lt;/td&gt;
      &lt;td&gt;0.899289&lt;/td&gt;
      &lt;td&gt;0.816972&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;123&lt;/td&gt;
      &lt;td&gt;0.894561&lt;/td&gt;
      &lt;td&gt;0.944673&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;124&lt;/td&gt;
      &lt;td&gt;0.892816&lt;/td&gt;
      &lt;td&gt;0.783612&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;125&lt;/td&gt;
      &lt;td&gt;0.887467&lt;/td&gt;
      &lt;td&gt;0.708474&lt;/td&gt;
      &lt;td&gt;0.900000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;126&lt;/td&gt;
      &lt;td&gt;0.885093&lt;/td&gt;
      &lt;td&gt;0.726909&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;127&lt;/td&gt;
      &lt;td&gt;0.881646&lt;/td&gt;
      &lt;td&gt;0.995866&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;0.875917&lt;/td&gt;
      &lt;td&gt;1.191868&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;129&lt;/td&gt;
      &lt;td&gt;0.871996&lt;/td&gt;
      &lt;td&gt;1.267549&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;0.869246&lt;/td&gt;
      &lt;td&gt;1.369829&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;131&lt;/td&gt;
      &lt;td&gt;0.867821&lt;/td&gt;
      &lt;td&gt;1.436767&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;132&lt;/td&gt;
      &lt;td&gt;0.864062&lt;/td&gt;
      &lt;td&gt;1.160231&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;133&lt;/td&gt;
      &lt;td&gt;0.859628&lt;/td&gt;
      &lt;td&gt;1.105737&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;134&lt;/td&gt;
      &lt;td&gt;0.859078&lt;/td&gt;
      &lt;td&gt;0.851334&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;135&lt;/td&gt;
      &lt;td&gt;0.858720&lt;/td&gt;
      &lt;td&gt;0.778529&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;0.856945&lt;/td&gt;
      &lt;td&gt;1.147635&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;0.854129&lt;/td&gt;
      &lt;td&gt;1.129824&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;138&lt;/td&gt;
      &lt;td&gt;0.852220&lt;/td&gt;
      &lt;td&gt;0.979698&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;139&lt;/td&gt;
      &lt;td&gt;0.847723&lt;/td&gt;
      &lt;td&gt;0.809028&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;140&lt;/td&gt;
      &lt;td&gt;0.843133&lt;/td&gt;
      &lt;td&gt;0.673137&lt;/td&gt;
      &lt;td&gt;0.933333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;141&lt;/td&gt;
      &lt;td&gt;0.839500&lt;/td&gt;
      &lt;td&gt;0.736410&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;142&lt;/td&gt;
      &lt;td&gt;0.835289&lt;/td&gt;
      &lt;td&gt;0.999134&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;0.833026&lt;/td&gt;
      &lt;td&gt;1.256068&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;144&lt;/td&gt;
      &lt;td&gt;0.833735&lt;/td&gt;
      &lt;td&gt;1.237204&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;0.834965&lt;/td&gt;
      &lt;td&gt;1.282824&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;146&lt;/td&gt;
      &lt;td&gt;0.833917&lt;/td&gt;
      &lt;td&gt;1.396549&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;147&lt;/td&gt;
      &lt;td&gt;0.828235&lt;/td&gt;
      &lt;td&gt;1.317177&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;148&lt;/td&gt;
      &lt;td&gt;0.827091&lt;/td&gt;
      &lt;td&gt;1.111997&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;149&lt;/td&gt;
      &lt;td&gt;0.824293&lt;/td&gt;
      &lt;td&gt;0.851436&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;0.823835&lt;/td&gt;
      &lt;td&gt;0.715306&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;151&lt;/td&gt;
      &lt;td&gt;0.822530&lt;/td&gt;
      &lt;td&gt;0.689193&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;152&lt;/td&gt;
      &lt;td&gt;0.817367&lt;/td&gt;
      &lt;td&gt;0.732036&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;153&lt;/td&gt;
      &lt;td&gt;0.817202&lt;/td&gt;
      &lt;td&gt;0.856252&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;0.816193&lt;/td&gt;
      &lt;td&gt;0.948537&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;155&lt;/td&gt;
      &lt;td&gt;0.813613&lt;/td&gt;
      &lt;td&gt;1.066483&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;156&lt;/td&gt;
      &lt;td&gt;0.811144&lt;/td&gt;
      &lt;td&gt;1.068854&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;157&lt;/td&gt;
      &lt;td&gt;0.810831&lt;/td&gt;
      &lt;td&gt;1.071055&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;0.808077&lt;/td&gt;
      &lt;td&gt;0.977296&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;159&lt;/td&gt;
      &lt;td&gt;0.804630&lt;/td&gt;
      &lt;td&gt;0.838821&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;0.802261&lt;/td&gt;
      &lt;td&gt;0.772696&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;161&lt;/td&gt;
      &lt;td&gt;0.802727&lt;/td&gt;
      &lt;td&gt;0.791702&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;0.798813&lt;/td&gt;
      &lt;td&gt;0.835375&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;163&lt;/td&gt;
      &lt;td&gt;0.797573&lt;/td&gt;
      &lt;td&gt;0.865562&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;164&lt;/td&gt;
      &lt;td&gt;0.798201&lt;/td&gt;
      &lt;td&gt;0.891660&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;165&lt;/td&gt;
      &lt;td&gt;0.795692&lt;/td&gt;
      &lt;td&gt;0.892899&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;166&lt;/td&gt;
      &lt;td&gt;0.793362&lt;/td&gt;
      &lt;td&gt;0.867864&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;167&lt;/td&gt;
      &lt;td&gt;0.792883&lt;/td&gt;
      &lt;td&gt;0.810626&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;168&lt;/td&gt;
      &lt;td&gt;0.791444&lt;/td&gt;
      &lt;td&gt;0.769112&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;0.788628&lt;/td&gt;
      &lt;td&gt;0.742704&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;170&lt;/td&gt;
      &lt;td&gt;0.787844&lt;/td&gt;
      &lt;td&gt;0.720856&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;171&lt;/td&gt;
      &lt;td&gt;0.784512&lt;/td&gt;
      &lt;td&gt;0.715271&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;172&lt;/td&gt;
      &lt;td&gt;0.782812&lt;/td&gt;
      &lt;td&gt;0.724146&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;0.780747&lt;/td&gt;
      &lt;td&gt;0.742088&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;174&lt;/td&gt;
      &lt;td&gt;0.779653&lt;/td&gt;
      &lt;td&gt;0.765256&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;175&lt;/td&gt;
      &lt;td&gt;0.777027&lt;/td&gt;
      &lt;td&gt;0.789565&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;176&lt;/td&gt;
      &lt;td&gt;0.777006&lt;/td&gt;
      &lt;td&gt;0.810619&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;177&lt;/td&gt;
      &lt;td&gt;0.777498&lt;/td&gt;
      &lt;td&gt;0.812250&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;178&lt;/td&gt;
      &lt;td&gt;0.774280&lt;/td&gt;
      &lt;td&gt;0.812091&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;179&lt;/td&gt;
      &lt;td&gt;0.774260&lt;/td&gt;
      &lt;td&gt;0.810058&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;180&lt;/td&gt;
      &lt;td&gt;0.773745&lt;/td&gt;
      &lt;td&gt;0.804928&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;181&lt;/td&gt;
      &lt;td&gt;0.771602&lt;/td&gt;
      &lt;td&gt;0.797569&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;0.770738&lt;/td&gt;
      &lt;td&gt;0.778828&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;0.769796&lt;/td&gt;
      &lt;td&gt;0.761000&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;184&lt;/td&gt;
      &lt;td&gt;0.769606&lt;/td&gt;
      &lt;td&gt;0.746166&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;185&lt;/td&gt;
      &lt;td&gt;0.769999&lt;/td&gt;
      &lt;td&gt;0.735135&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;186&lt;/td&gt;
      &lt;td&gt;0.769042&lt;/td&gt;
      &lt;td&gt;0.724371&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;187&lt;/td&gt;
      &lt;td&gt;0.765944&lt;/td&gt;
      &lt;td&gt;0.714545&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;188&lt;/td&gt;
      &lt;td&gt;0.766425&lt;/td&gt;
      &lt;td&gt;0.709452&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;189&lt;/td&gt;
      &lt;td&gt;0.765466&lt;/td&gt;
      &lt;td&gt;0.703008&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;190&lt;/td&gt;
      &lt;td&gt;0.761368&lt;/td&gt;
      &lt;td&gt;0.699016&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;191&lt;/td&gt;
      &lt;td&gt;0.759790&lt;/td&gt;
      &lt;td&gt;0.696969&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192&lt;/td&gt;
      &lt;td&gt;0.758059&lt;/td&gt;
      &lt;td&gt;0.694304&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;193&lt;/td&gt;
      &lt;td&gt;0.756838&lt;/td&gt;
      &lt;td&gt;0.691365&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;194&lt;/td&gt;
      &lt;td&gt;0.756011&lt;/td&gt;
      &lt;td&gt;0.691939&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;0.755389&lt;/td&gt;
      &lt;td&gt;0.692854&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;196&lt;/td&gt;
      &lt;td&gt;0.754549&lt;/td&gt;
      &lt;td&gt;0.691379&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;197&lt;/td&gt;
      &lt;td&gt;0.754667&lt;/td&gt;
      &lt;td&gt;0.690486&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;198&lt;/td&gt;
      &lt;td&gt;0.754686&lt;/td&gt;
      &lt;td&gt;0.692739&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;199&lt;/td&gt;
      &lt;td&gt;0.753276&lt;/td&gt;
      &lt;td&gt;0.694158&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;☣️ I've built a chart to compare performance with and without mixup. 
As you can see, and this has occurred in many experiments I've done, it takes longer to get a high level of performance with mixup, but then it tends to keep growing more than without mixup. 
This is something to take into account when designing your experiments.&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/beef_mixup.jpg"&gt;&lt;/p&gt;
&lt;h4&gt;Cutmix&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;LabelSmoothingCrossEntropy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cutmix&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_one_cycle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: left;"&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1.706453&lt;/td&gt;
      &lt;td&gt;1.624805&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.685710&lt;/td&gt;
      &lt;td&gt;1.624133&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1.661669&lt;/td&gt;
      &lt;td&gt;1.623917&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1.638445&lt;/td&gt;
      &lt;td&gt;1.623724&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1.624182&lt;/td&gt;
      &lt;td&gt;1.623581&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1.614200&lt;/td&gt;
      &lt;td&gt;1.623360&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;1.604189&lt;/td&gt;
      &lt;td&gt;1.623062&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1.591671&lt;/td&gt;
      &lt;td&gt;1.622744&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;1.579674&lt;/td&gt;
      &lt;td&gt;1.622297&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;1.569131&lt;/td&gt;
      &lt;td&gt;1.621474&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1.561477&lt;/td&gt;
      &lt;td&gt;1.620105&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;1.550535&lt;/td&gt;
      &lt;td&gt;1.618287&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1.537226&lt;/td&gt;
      &lt;td&gt;1.616055&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;1.533442&lt;/td&gt;
      &lt;td&gt;1.613569&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;1.529642&lt;/td&gt;
      &lt;td&gt;1.610154&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;1.526031&lt;/td&gt;
      &lt;td&gt;1.606566&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1.516714&lt;/td&gt;
      &lt;td&gt;1.601131&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;1.509571&lt;/td&gt;
      &lt;td&gt;1.593389&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1.506086&lt;/td&gt;
      &lt;td&gt;1.585316&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;1.502734&lt;/td&gt;
      &lt;td&gt;1.573562&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;1.499156&lt;/td&gt;
      &lt;td&gt;1.554533&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;1.488737&lt;/td&gt;
      &lt;td&gt;1.531936&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;1.484465&lt;/td&gt;
      &lt;td&gt;1.516183&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;1.481679&lt;/td&gt;
      &lt;td&gt;1.487968&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;1.480139&lt;/td&gt;
      &lt;td&gt;1.481755&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;1.474577&lt;/td&gt;
      &lt;td&gt;1.457397&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;1.471540&lt;/td&gt;
      &lt;td&gt;1.453811&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;1.470596&lt;/td&gt;
      &lt;td&gt;1.458764&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;1.469030&lt;/td&gt;
      &lt;td&gt;1.463857&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;1.466600&lt;/td&gt;
      &lt;td&gt;1.523658&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;1.464954&lt;/td&gt;
      &lt;td&gt;1.616127&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1.463124&lt;/td&gt;
      &lt;td&gt;1.639686&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;1.458457&lt;/td&gt;
      &lt;td&gt;1.663750&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;1.452542&lt;/td&gt;
      &lt;td&gt;1.680489&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;1.448779&lt;/td&gt;
      &lt;td&gt;1.987832&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;1.443480&lt;/td&gt;
      &lt;td&gt;1.724338&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;1.439493&lt;/td&gt;
      &lt;td&gt;2.210143&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;1.436260&lt;/td&gt;
      &lt;td&gt;2.561839&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;1.435892&lt;/td&gt;
      &lt;td&gt;1.457669&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;1.433157&lt;/td&gt;
      &lt;td&gt;1.703312&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;1.431497&lt;/td&gt;
      &lt;td&gt;2.224642&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;1.430971&lt;/td&gt;
      &lt;td&gt;2.875991&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;1.428263&lt;/td&gt;
      &lt;td&gt;2.325544&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;1.427699&lt;/td&gt;
      &lt;td&gt;1.876932&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;44&lt;/td&gt;
      &lt;td&gt;1.422279&lt;/td&gt;
      &lt;td&gt;1.727904&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;1.418207&lt;/td&gt;
      &lt;td&gt;1.762134&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;1.416281&lt;/td&gt;
      &lt;td&gt;1.538334&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;1.415849&lt;/td&gt;
      &lt;td&gt;1.947046&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;48&lt;/td&gt;
      &lt;td&gt;1.412131&lt;/td&gt;
      &lt;td&gt;1.897876&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;49&lt;/td&gt;
      &lt;td&gt;1.409524&lt;/td&gt;
      &lt;td&gt;2.145555&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;1.404963&lt;/td&gt;
      &lt;td&gt;6.031844&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;1.396030&lt;/td&gt;
      &lt;td&gt;6.310513&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;52&lt;/td&gt;
      &lt;td&gt;1.396604&lt;/td&gt;
      &lt;td&gt;5.209888&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;1.394261&lt;/td&gt;
      &lt;td&gt;4.222475&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;1.391686&lt;/td&gt;
      &lt;td&gt;2.320999&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;1.388773&lt;/td&gt;
      &lt;td&gt;1.465874&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;1.386416&lt;/td&gt;
      &lt;td&gt;2.058067&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;57&lt;/td&gt;
      &lt;td&gt;1.386596&lt;/td&gt;
      &lt;td&gt;3.500876&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;1.384054&lt;/td&gt;
      &lt;td&gt;2.610673&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;1.384070&lt;/td&gt;
      &lt;td&gt;2.270039&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;1.383814&lt;/td&gt;
      &lt;td&gt;1.708934&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;1.380550&lt;/td&gt;
      &lt;td&gt;1.421436&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;1.382743&lt;/td&gt;
      &lt;td&gt;1.412282&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;63&lt;/td&gt;
      &lt;td&gt;1.384651&lt;/td&gt;
      &lt;td&gt;2.413202&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;1.380379&lt;/td&gt;
      &lt;td&gt;2.628878&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;65&lt;/td&gt;
      &lt;td&gt;1.380742&lt;/td&gt;
      &lt;td&gt;2.428576&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;66&lt;/td&gt;
      &lt;td&gt;1.378306&lt;/td&gt;
      &lt;td&gt;1.427382&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;1.377688&lt;/td&gt;
      &lt;td&gt;1.407880&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;1.377784&lt;/td&gt;
      &lt;td&gt;1.648727&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;69&lt;/td&gt;
      &lt;td&gt;1.374915&lt;/td&gt;
      &lt;td&gt;1.851315&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;1.372057&lt;/td&gt;
      &lt;td&gt;1.959223&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;1.367003&lt;/td&gt;
      &lt;td&gt;1.710080&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;1.366259&lt;/td&gt;
      &lt;td&gt;1.444495&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1.366753&lt;/td&gt;
      &lt;td&gt;1.294768&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;1.362236&lt;/td&gt;
      &lt;td&gt;1.499587&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;1.359724&lt;/td&gt;
      &lt;td&gt;2.356512&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;76&lt;/td&gt;
      &lt;td&gt;1.359129&lt;/td&gt;
      &lt;td&gt;2.694739&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;77&lt;/td&gt;
      &lt;td&gt;1.358984&lt;/td&gt;
      &lt;td&gt;2.540057&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;78&lt;/td&gt;
      &lt;td&gt;1.357662&lt;/td&gt;
      &lt;td&gt;2.659967&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;1.360360&lt;/td&gt;
      &lt;td&gt;2.046504&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;1.356875&lt;/td&gt;
      &lt;td&gt;1.603783&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;1.356482&lt;/td&gt;
      &lt;td&gt;1.273809&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;1.354857&lt;/td&gt;
      &lt;td&gt;1.436357&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;1.352965&lt;/td&gt;
      &lt;td&gt;1.385521&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;84&lt;/td&gt;
      &lt;td&gt;1.348206&lt;/td&gt;
      &lt;td&gt;1.277132&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;1.347547&lt;/td&gt;
      &lt;td&gt;1.401034&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;86&lt;/td&gt;
      &lt;td&gt;1.346372&lt;/td&gt;
      &lt;td&gt;1.559262&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;87&lt;/td&gt;
      &lt;td&gt;1.344510&lt;/td&gt;
      &lt;td&gt;1.635159&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;88&lt;/td&gt;
      &lt;td&gt;1.344424&lt;/td&gt;
      &lt;td&gt;1.650026&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;89&lt;/td&gt;
      &lt;td&gt;1.342335&lt;/td&gt;
      &lt;td&gt;1.612467&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;1.341733&lt;/td&gt;
      &lt;td&gt;1.306708&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;91&lt;/td&gt;
      &lt;td&gt;1.338287&lt;/td&gt;
      &lt;td&gt;1.169277&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;92&lt;/td&gt;
      &lt;td&gt;1.337811&lt;/td&gt;
      &lt;td&gt;1.212823&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;93&lt;/td&gt;
      &lt;td&gt;1.337693&lt;/td&gt;
      &lt;td&gt;1.435008&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;94&lt;/td&gt;
      &lt;td&gt;1.331457&lt;/td&gt;
      &lt;td&gt;1.337413&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;95&lt;/td&gt;
      &lt;td&gt;1.331445&lt;/td&gt;
      &lt;td&gt;1.105399&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;1.331121&lt;/td&gt;
      &lt;td&gt;1.171597&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;97&lt;/td&gt;
      &lt;td&gt;1.324570&lt;/td&gt;
      &lt;td&gt;1.264037&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;98&lt;/td&gt;
      &lt;td&gt;1.322947&lt;/td&gt;
      &lt;td&gt;1.286684&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;99&lt;/td&gt;
      &lt;td&gt;1.323301&lt;/td&gt;
      &lt;td&gt;1.347077&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;1.321393&lt;/td&gt;
      &lt;td&gt;1.297375&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;101&lt;/td&gt;
      &lt;td&gt;1.319361&lt;/td&gt;
      &lt;td&gt;1.191885&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;1.315395&lt;/td&gt;
      &lt;td&gt;1.189938&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;1.315025&lt;/td&gt;
      &lt;td&gt;1.259681&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;104&lt;/td&gt;
      &lt;td&gt;1.308935&lt;/td&gt;
      &lt;td&gt;1.349674&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;105&lt;/td&gt;
      &lt;td&gt;1.305654&lt;/td&gt;
      &lt;td&gt;1.378004&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;1.305785&lt;/td&gt;
      &lt;td&gt;1.346191&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;1.305715&lt;/td&gt;
      &lt;td&gt;1.356849&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;108&lt;/td&gt;
      &lt;td&gt;1.304183&lt;/td&gt;
      &lt;td&gt;1.541104&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;1.302752&lt;/td&gt;
      &lt;td&gt;1.282268&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;1.303141&lt;/td&gt;
      &lt;td&gt;1.279333&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;111&lt;/td&gt;
      &lt;td&gt;1.300831&lt;/td&gt;
      &lt;td&gt;1.186200&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;112&lt;/td&gt;
      &lt;td&gt;1.300369&lt;/td&gt;
      &lt;td&gt;1.150524&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;113&lt;/td&gt;
      &lt;td&gt;1.304650&lt;/td&gt;
      &lt;td&gt;1.354581&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;114&lt;/td&gt;
      &lt;td&gt;1.303918&lt;/td&gt;
      &lt;td&gt;1.443647&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;115&lt;/td&gt;
      &lt;td&gt;1.302446&lt;/td&gt;
      &lt;td&gt;1.253269&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;1.299625&lt;/td&gt;
      &lt;td&gt;1.254723&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;117&lt;/td&gt;
      &lt;td&gt;1.297959&lt;/td&gt;
      &lt;td&gt;1.355177&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;118&lt;/td&gt;
      &lt;td&gt;1.295360&lt;/td&gt;
      &lt;td&gt;1.413822&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;119&lt;/td&gt;
      &lt;td&gt;1.294235&lt;/td&gt;
      &lt;td&gt;1.272771&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;1.294245&lt;/td&gt;
      &lt;td&gt;1.135344&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;121&lt;/td&gt;
      &lt;td&gt;1.290968&lt;/td&gt;
      &lt;td&gt;1.179739&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;122&lt;/td&gt;
      &lt;td&gt;1.291180&lt;/td&gt;
      &lt;td&gt;1.224161&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;123&lt;/td&gt;
      &lt;td&gt;1.288947&lt;/td&gt;
      &lt;td&gt;1.178296&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;124&lt;/td&gt;
      &lt;td&gt;1.286780&lt;/td&gt;
      &lt;td&gt;1.094188&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;125&lt;/td&gt;
      &lt;td&gt;1.278990&lt;/td&gt;
      &lt;td&gt;1.079829&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;126&lt;/td&gt;
      &lt;td&gt;1.280690&lt;/td&gt;
      &lt;td&gt;1.146522&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;127&lt;/td&gt;
      &lt;td&gt;1.277659&lt;/td&gt;
      &lt;td&gt;1.112404&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;1.275256&lt;/td&gt;
      &lt;td&gt;1.077389&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;129&lt;/td&gt;
      &lt;td&gt;1.274448&lt;/td&gt;
      &lt;td&gt;1.371475&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;1.273802&lt;/td&gt;
      &lt;td&gt;1.661546&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;131&lt;/td&gt;
      &lt;td&gt;1.275651&lt;/td&gt;
      &lt;td&gt;1.745858&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;132&lt;/td&gt;
      &lt;td&gt;1.273929&lt;/td&gt;
      &lt;td&gt;1.663937&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;133&lt;/td&gt;
      &lt;td&gt;1.270650&lt;/td&gt;
      &lt;td&gt;1.477462&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;134&lt;/td&gt;
      &lt;td&gt;1.269193&lt;/td&gt;
      &lt;td&gt;1.260925&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;135&lt;/td&gt;
      &lt;td&gt;1.267992&lt;/td&gt;
      &lt;td&gt;1.182368&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;1.265650&lt;/td&gt;
      &lt;td&gt;1.268212&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;1.263543&lt;/td&gt;
      &lt;td&gt;1.349007&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;138&lt;/td&gt;
      &lt;td&gt;1.262578&lt;/td&gt;
      &lt;td&gt;1.366768&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;139&lt;/td&gt;
      &lt;td&gt;1.260029&lt;/td&gt;
      &lt;td&gt;1.291980&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;140&lt;/td&gt;
      &lt;td&gt;1.258410&lt;/td&gt;
      &lt;td&gt;1.213087&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;141&lt;/td&gt;
      &lt;td&gt;1.260078&lt;/td&gt;
      &lt;td&gt;1.172351&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;142&lt;/td&gt;
      &lt;td&gt;1.258358&lt;/td&gt;
      &lt;td&gt;1.161846&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;1.252187&lt;/td&gt;
      &lt;td&gt;1.153422&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;144&lt;/td&gt;
      &lt;td&gt;1.251021&lt;/td&gt;
      &lt;td&gt;1.143518&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;1.251198&lt;/td&gt;
      &lt;td&gt;1.133091&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;146&lt;/td&gt;
      &lt;td&gt;1.249392&lt;/td&gt;
      &lt;td&gt;1.119584&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;147&lt;/td&gt;
      &lt;td&gt;1.248203&lt;/td&gt;
      &lt;td&gt;1.107645&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;148&lt;/td&gt;
      &lt;td&gt;1.247276&lt;/td&gt;
      &lt;td&gt;1.119978&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;149&lt;/td&gt;
      &lt;td&gt;1.243595&lt;/td&gt;
      &lt;td&gt;1.146225&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;1.241543&lt;/td&gt;
      &lt;td&gt;1.176757&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;151&lt;/td&gt;
      &lt;td&gt;1.238316&lt;/td&gt;
      &lt;td&gt;1.200777&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;152&lt;/td&gt;
      &lt;td&gt;1.237871&lt;/td&gt;
      &lt;td&gt;1.213209&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;153&lt;/td&gt;
      &lt;td&gt;1.235683&lt;/td&gt;
      &lt;td&gt;1.203346&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;1.233224&lt;/td&gt;
      &lt;td&gt;1.185343&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;155&lt;/td&gt;
      &lt;td&gt;1.232618&lt;/td&gt;
      &lt;td&gt;1.150263&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;156&lt;/td&gt;
      &lt;td&gt;1.233111&lt;/td&gt;
      &lt;td&gt;1.124269&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;157&lt;/td&gt;
      &lt;td&gt;1.232996&lt;/td&gt;
      &lt;td&gt;1.082658&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;1.231997&lt;/td&gt;
      &lt;td&gt;1.048401&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;159&lt;/td&gt;
      &lt;td&gt;1.232146&lt;/td&gt;
      &lt;td&gt;1.027407&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;1.232651&lt;/td&gt;
      &lt;td&gt;1.024449&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;161&lt;/td&gt;
      &lt;td&gt;1.228856&lt;/td&gt;
      &lt;td&gt;1.025052&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;1.230592&lt;/td&gt;
      &lt;td&gt;1.037613&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;163&lt;/td&gt;
      &lt;td&gt;1.230132&lt;/td&gt;
      &lt;td&gt;1.037835&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;164&lt;/td&gt;
      &lt;td&gt;1.226062&lt;/td&gt;
      &lt;td&gt;1.028810&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;165&lt;/td&gt;
      &lt;td&gt;1.220277&lt;/td&gt;
      &lt;td&gt;1.017511&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;166&lt;/td&gt;
      &lt;td&gt;1.219127&lt;/td&gt;
      &lt;td&gt;1.005891&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;167&lt;/td&gt;
      &lt;td&gt;1.217834&lt;/td&gt;
      &lt;td&gt;0.992963&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;168&lt;/td&gt;
      &lt;td&gt;1.215868&lt;/td&gt;
      &lt;td&gt;0.988810&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;1.210998&lt;/td&gt;
      &lt;td&gt;0.987222&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;170&lt;/td&gt;
      &lt;td&gt;1.205445&lt;/td&gt;
      &lt;td&gt;0.989531&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;171&lt;/td&gt;
      &lt;td&gt;1.202443&lt;/td&gt;
      &lt;td&gt;0.994882&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;172&lt;/td&gt;
      &lt;td&gt;1.200605&lt;/td&gt;
      &lt;td&gt;0.996973&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;1.199470&lt;/td&gt;
      &lt;td&gt;0.996149&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;174&lt;/td&gt;
      &lt;td&gt;1.196583&lt;/td&gt;
      &lt;td&gt;0.994541&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;175&lt;/td&gt;
      &lt;td&gt;1.195204&lt;/td&gt;
      &lt;td&gt;0.992158&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;176&lt;/td&gt;
      &lt;td&gt;1.194456&lt;/td&gt;
      &lt;td&gt;0.990747&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;177&lt;/td&gt;
      &lt;td&gt;1.192639&lt;/td&gt;
      &lt;td&gt;0.986806&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;178&lt;/td&gt;
      &lt;td&gt;1.189554&lt;/td&gt;
      &lt;td&gt;0.983644&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;179&lt;/td&gt;
      &lt;td&gt;1.188267&lt;/td&gt;
      &lt;td&gt;0.980869&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;180&lt;/td&gt;
      &lt;td&gt;1.185815&lt;/td&gt;
      &lt;td&gt;0.978657&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;181&lt;/td&gt;
      &lt;td&gt;1.185371&lt;/td&gt;
      &lt;td&gt;0.974919&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;1.183739&lt;/td&gt;
      &lt;td&gt;0.973566&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;1.179749&lt;/td&gt;
      &lt;td&gt;0.973964&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;184&lt;/td&gt;
      &lt;td&gt;1.177038&lt;/td&gt;
      &lt;td&gt;0.974452&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;185&lt;/td&gt;
      &lt;td&gt;1.167234&lt;/td&gt;
      &lt;td&gt;0.976603&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;186&lt;/td&gt;
      &lt;td&gt;1.166255&lt;/td&gt;
      &lt;td&gt;0.980606&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;187&lt;/td&gt;
      &lt;td&gt;1.164219&lt;/td&gt;
      &lt;td&gt;0.982645&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;188&lt;/td&gt;
      &lt;td&gt;1.161877&lt;/td&gt;
      &lt;td&gt;0.983812&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;189&lt;/td&gt;
      &lt;td&gt;1.160285&lt;/td&gt;
      &lt;td&gt;0.987663&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;190&lt;/td&gt;
      &lt;td&gt;1.158639&lt;/td&gt;
      &lt;td&gt;0.989382&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;191&lt;/td&gt;
      &lt;td&gt;1.157610&lt;/td&gt;
      &lt;td&gt;0.992286&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192&lt;/td&gt;
      &lt;td&gt;1.156571&lt;/td&gt;
      &lt;td&gt;0.991146&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;193&lt;/td&gt;
      &lt;td&gt;1.157177&lt;/td&gt;
      &lt;td&gt;0.990459&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;194&lt;/td&gt;
      &lt;td&gt;1.159675&lt;/td&gt;
      &lt;td&gt;0.990053&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;1.161296&lt;/td&gt;
      &lt;td&gt;0.990250&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;196&lt;/td&gt;
      &lt;td&gt;1.160810&lt;/td&gt;
      &lt;td&gt;0.989652&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;197&lt;/td&gt;
      &lt;td&gt;1.161151&lt;/td&gt;
      &lt;td&gt;0.988033&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;198&lt;/td&gt;
      &lt;td&gt;1.160224&lt;/td&gt;
      &lt;td&gt;0.986137&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;199&lt;/td&gt;
      &lt;td&gt;1.159139&lt;/td&gt;
      &lt;td&gt;0.985020&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4&gt;Cutout&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;LabelSmoothingCrossEntropy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cutout&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_one_cycle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: left;"&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1.660396&lt;/td&gt;
      &lt;td&gt;1.620012&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.637469&lt;/td&gt;
      &lt;td&gt;1.619628&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1.631980&lt;/td&gt;
      &lt;td&gt;1.619524&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1.618567&lt;/td&gt;
      &lt;td&gt;1.619128&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1.604060&lt;/td&gt;
      &lt;td&gt;1.618873&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1.591112&lt;/td&gt;
      &lt;td&gt;1.618706&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;1.577234&lt;/td&gt;
      &lt;td&gt;1.618439&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1.566691&lt;/td&gt;
      &lt;td&gt;1.618009&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;1.574861&lt;/td&gt;
      &lt;td&gt;1.617688&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;1.565786&lt;/td&gt;
      &lt;td&gt;1.617103&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1.553699&lt;/td&gt;
      &lt;td&gt;1.616126&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;1.540023&lt;/td&gt;
      &lt;td&gt;1.614528&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1.527577&lt;/td&gt;
      &lt;td&gt;1.612250&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;1.518896&lt;/td&gt;
      &lt;td&gt;1.608595&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;1.507092&lt;/td&gt;
      &lt;td&gt;1.604372&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;1.501131&lt;/td&gt;
      &lt;td&gt;1.597838&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1.504705&lt;/td&gt;
      &lt;td&gt;1.588038&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;1.493358&lt;/td&gt;
      &lt;td&gt;1.578237&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1.483621&lt;/td&gt;
      &lt;td&gt;1.567515&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;1.474008&lt;/td&gt;
      &lt;td&gt;1.555968&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;1.465212&lt;/td&gt;
      &lt;td&gt;1.544741&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;1.454736&lt;/td&gt;
      &lt;td&gt;1.529409&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;1.443652&lt;/td&gt;
      &lt;td&gt;1.509047&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;1.434206&lt;/td&gt;
      &lt;td&gt;1.488219&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;1.424903&lt;/td&gt;
      &lt;td&gt;1.487186&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;1.414110&lt;/td&gt;
      &lt;td&gt;1.454912&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;1.403112&lt;/td&gt;
      &lt;td&gt;1.411377&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;1.400361&lt;/td&gt;
      &lt;td&gt;1.454942&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;1.394396&lt;/td&gt;
      &lt;td&gt;2.853700&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;1.386278&lt;/td&gt;
      &lt;td&gt;3.738343&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;1.380608&lt;/td&gt;
      &lt;td&gt;3.026152&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1.375208&lt;/td&gt;
      &lt;td&gt;2.086259&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;1.372596&lt;/td&gt;
      &lt;td&gt;2.029034&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;1.368522&lt;/td&gt;
      &lt;td&gt;1.776222&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;1.364299&lt;/td&gt;
      &lt;td&gt;1.564647&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;1.356729&lt;/td&gt;
      &lt;td&gt;1.687982&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;1.349027&lt;/td&gt;
      &lt;td&gt;1.828559&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;1.341715&lt;/td&gt;
      &lt;td&gt;1.832533&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;1.331327&lt;/td&gt;
      &lt;td&gt;1.929781&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;1.324214&lt;/td&gt;
      &lt;td&gt;1.609313&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;1.316651&lt;/td&gt;
      &lt;td&gt;3.501971&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;1.309119&lt;/td&gt;
      &lt;td&gt;4.311689&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;1.313026&lt;/td&gt;
      &lt;td&gt;13.606978&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;1.311430&lt;/td&gt;
      &lt;td&gt;9.567814&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;44&lt;/td&gt;
      &lt;td&gt;1.308879&lt;/td&gt;
      &lt;td&gt;7.534220&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;1.306159&lt;/td&gt;
      &lt;td&gt;3.707384&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;1.301580&lt;/td&gt;
      &lt;td&gt;2.191738&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;1.295914&lt;/td&gt;
      &lt;td&gt;2.324064&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;48&lt;/td&gt;
      &lt;td&gt;1.307469&lt;/td&gt;
      &lt;td&gt;9.194708&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;49&lt;/td&gt;
      &lt;td&gt;1.302346&lt;/td&gt;
      &lt;td&gt;4.097297&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;1.296714&lt;/td&gt;
      &lt;td&gt;3.400907&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;1.291286&lt;/td&gt;
      &lt;td&gt;4.134081&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;52&lt;/td&gt;
      &lt;td&gt;1.292245&lt;/td&gt;
      &lt;td&gt;9.854806&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;1.291874&lt;/td&gt;
      &lt;td&gt;32.586937&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;1.288160&lt;/td&gt;
      &lt;td&gt;29.200527&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;1.284828&lt;/td&gt;
      &lt;td&gt;16.745173&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;1.283797&lt;/td&gt;
      &lt;td&gt;11.435283&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;57&lt;/td&gt;
      &lt;td&gt;1.277688&lt;/td&gt;
      &lt;td&gt;9.402293&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;1.272753&lt;/td&gt;
      &lt;td&gt;7.304148&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;1.266980&lt;/td&gt;
      &lt;td&gt;5.996444&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;1.264276&lt;/td&gt;
      &lt;td&gt;6.278485&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;1.258912&lt;/td&gt;
      &lt;td&gt;11.868817&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;1.253075&lt;/td&gt;
      &lt;td&gt;9.906275&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;63&lt;/td&gt;
      &lt;td&gt;1.252298&lt;/td&gt;
      &lt;td&gt;8.497372&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;1.248089&lt;/td&gt;
      &lt;td&gt;8.165295&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;65&lt;/td&gt;
      &lt;td&gt;1.244134&lt;/td&gt;
      &lt;td&gt;5.703846&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;66&lt;/td&gt;
      &lt;td&gt;1.238663&lt;/td&gt;
      &lt;td&gt;3.617159&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;1.232986&lt;/td&gt;
      &lt;td&gt;2.547888&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;1.228218&lt;/td&gt;
      &lt;td&gt;2.249779&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;69&lt;/td&gt;
      &lt;td&gt;1.234005&lt;/td&gt;
      &lt;td&gt;1.480027&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;1.244705&lt;/td&gt;
      &lt;td&gt;5.166591&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;1.243025&lt;/td&gt;
      &lt;td&gt;9.313371&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;1.242977&lt;/td&gt;
      &lt;td&gt;9.378866&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1.242423&lt;/td&gt;
      &lt;td&gt;7.334600&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;1.243052&lt;/td&gt;
      &lt;td&gt;6.318696&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;1.247443&lt;/td&gt;
      &lt;td&gt;5.345894&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;76&lt;/td&gt;
      &lt;td&gt;1.245416&lt;/td&gt;
      &lt;td&gt;4.845418&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;77&lt;/td&gt;
      &lt;td&gt;1.244565&lt;/td&gt;
      &lt;td&gt;5.320508&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;78&lt;/td&gt;
      &lt;td&gt;1.241501&lt;/td&gt;
      &lt;td&gt;3.297099&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;1.236092&lt;/td&gt;
      &lt;td&gt;3.492207&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;1.233410&lt;/td&gt;
      &lt;td&gt;3.885850&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;1.227951&lt;/td&gt;
      &lt;td&gt;3.243068&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;1.225131&lt;/td&gt;
      &lt;td&gt;1.910741&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;1.223312&lt;/td&gt;
      &lt;td&gt;1.487790&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;84&lt;/td&gt;
      &lt;td&gt;1.216726&lt;/td&gt;
      &lt;td&gt;1.447462&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;1.220145&lt;/td&gt;
      &lt;td&gt;1.574987&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;86&lt;/td&gt;
      &lt;td&gt;1.218359&lt;/td&gt;
      &lt;td&gt;2.194073&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;87&lt;/td&gt;
      &lt;td&gt;1.215006&lt;/td&gt;
      &lt;td&gt;2.299147&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;88&lt;/td&gt;
      &lt;td&gt;1.210736&lt;/td&gt;
      &lt;td&gt;2.274392&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;89&lt;/td&gt;
      &lt;td&gt;1.207281&lt;/td&gt;
      &lt;td&gt;2.524296&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;1.205115&lt;/td&gt;
      &lt;td&gt;2.238126&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;91&lt;/td&gt;
      &lt;td&gt;1.204487&lt;/td&gt;
      &lt;td&gt;2.013067&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;92&lt;/td&gt;
      &lt;td&gt;1.199850&lt;/td&gt;
      &lt;td&gt;2.660136&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;93&lt;/td&gt;
      &lt;td&gt;1.196869&lt;/td&gt;
      &lt;td&gt;3.244203&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;94&lt;/td&gt;
      &lt;td&gt;1.194110&lt;/td&gt;
      &lt;td&gt;3.232043&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;95&lt;/td&gt;
      &lt;td&gt;1.192502&lt;/td&gt;
      &lt;td&gt;2.691142&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;1.195390&lt;/td&gt;
      &lt;td&gt;2.010396&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;97&lt;/td&gt;
      &lt;td&gt;1.190254&lt;/td&gt;
      &lt;td&gt;1.854620&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;98&lt;/td&gt;
      &lt;td&gt;1.184024&lt;/td&gt;
      &lt;td&gt;1.996308&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;99&lt;/td&gt;
      &lt;td&gt;1.177545&lt;/td&gt;
      &lt;td&gt;1.911293&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;1.174493&lt;/td&gt;
      &lt;td&gt;1.540360&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;101&lt;/td&gt;
      &lt;td&gt;1.167482&lt;/td&gt;
      &lt;td&gt;1.370175&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;1.159704&lt;/td&gt;
      &lt;td&gt;1.308586&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;1.153548&lt;/td&gt;
      &lt;td&gt;1.548130&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;104&lt;/td&gt;
      &lt;td&gt;1.146871&lt;/td&gt;
      &lt;td&gt;1.348858&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;105&lt;/td&gt;
      &lt;td&gt;1.146403&lt;/td&gt;
      &lt;td&gt;1.077422&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;1.141683&lt;/td&gt;
      &lt;td&gt;1.196881&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;1.135765&lt;/td&gt;
      &lt;td&gt;1.291074&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;108&lt;/td&gt;
      &lt;td&gt;1.129827&lt;/td&gt;
      &lt;td&gt;1.262042&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;1.123418&lt;/td&gt;
      &lt;td&gt;1.167186&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;1.116877&lt;/td&gt;
      &lt;td&gt;1.232698&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;111&lt;/td&gt;
      &lt;td&gt;1.113724&lt;/td&gt;
      &lt;td&gt;1.866791&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;112&lt;/td&gt;
      &lt;td&gt;1.111017&lt;/td&gt;
      &lt;td&gt;2.025032&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;113&lt;/td&gt;
      &lt;td&gt;1.109310&lt;/td&gt;
      &lt;td&gt;1.887846&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;114&lt;/td&gt;
      &lt;td&gt;1.102472&lt;/td&gt;
      &lt;td&gt;1.619525&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;115&lt;/td&gt;
      &lt;td&gt;1.095449&lt;/td&gt;
      &lt;td&gt;1.380898&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;1.090489&lt;/td&gt;
      &lt;td&gt;1.227257&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;117&lt;/td&gt;
      &lt;td&gt;1.085784&lt;/td&gt;
      &lt;td&gt;1.403344&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;118&lt;/td&gt;
      &lt;td&gt;1.078969&lt;/td&gt;
      &lt;td&gt;1.733581&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;119&lt;/td&gt;
      &lt;td&gt;1.074235&lt;/td&gt;
      &lt;td&gt;1.987759&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;1.083529&lt;/td&gt;
      &lt;td&gt;1.523327&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;121&lt;/td&gt;
      &lt;td&gt;1.083109&lt;/td&gt;
      &lt;td&gt;1.330128&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;122&lt;/td&gt;
      &lt;td&gt;1.078421&lt;/td&gt;
      &lt;td&gt;1.807096&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;123&lt;/td&gt;
      &lt;td&gt;1.077411&lt;/td&gt;
      &lt;td&gt;2.611065&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;124&lt;/td&gt;
      &lt;td&gt;1.076933&lt;/td&gt;
      &lt;td&gt;3.256675&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;125&lt;/td&gt;
      &lt;td&gt;1.078660&lt;/td&gt;
      &lt;td&gt;3.346977&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;126&lt;/td&gt;
      &lt;td&gt;1.073926&lt;/td&gt;
      &lt;td&gt;2.891910&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;127&lt;/td&gt;
      &lt;td&gt;1.072688&lt;/td&gt;
      &lt;td&gt;2.565595&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;1.067860&lt;/td&gt;
      &lt;td&gt;2.095694&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;129&lt;/td&gt;
      &lt;td&gt;1.068164&lt;/td&gt;
      &lt;td&gt;1.778149&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;1.066739&lt;/td&gt;
      &lt;td&gt;1.461159&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;131&lt;/td&gt;
      &lt;td&gt;1.063635&lt;/td&gt;
      &lt;td&gt;1.250543&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;132&lt;/td&gt;
      &lt;td&gt;1.061969&lt;/td&gt;
      &lt;td&gt;1.226142&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;133&lt;/td&gt;
      &lt;td&gt;1.057962&lt;/td&gt;
      &lt;td&gt;1.190449&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;134&lt;/td&gt;
      &lt;td&gt;1.051249&lt;/td&gt;
      &lt;td&gt;1.223222&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;135&lt;/td&gt;
      &lt;td&gt;1.046239&lt;/td&gt;
      &lt;td&gt;1.219140&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;1.043587&lt;/td&gt;
      &lt;td&gt;1.158116&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;1.037572&lt;/td&gt;
      &lt;td&gt;1.107074&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;138&lt;/td&gt;
      &lt;td&gt;1.034447&lt;/td&gt;
      &lt;td&gt;1.136540&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;139&lt;/td&gt;
      &lt;td&gt;1.027728&lt;/td&gt;
      &lt;td&gt;1.185949&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;140&lt;/td&gt;
      &lt;td&gt;1.027412&lt;/td&gt;
      &lt;td&gt;1.308161&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;141&lt;/td&gt;
      &lt;td&gt;1.021058&lt;/td&gt;
      &lt;td&gt;1.282450&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;142&lt;/td&gt;
      &lt;td&gt;1.017411&lt;/td&gt;
      &lt;td&gt;1.306550&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;1.016686&lt;/td&gt;
      &lt;td&gt;1.263149&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;144&lt;/td&gt;
      &lt;td&gt;1.010793&lt;/td&gt;
      &lt;td&gt;1.198263&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;1.008476&lt;/td&gt;
      &lt;td&gt;1.317031&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;146&lt;/td&gt;
      &lt;td&gt;1.005065&lt;/td&gt;
      &lt;td&gt;1.481030&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;147&lt;/td&gt;
      &lt;td&gt;0.999182&lt;/td&gt;
      &lt;td&gt;1.471093&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;148&lt;/td&gt;
      &lt;td&gt;0.997035&lt;/td&gt;
      &lt;td&gt;1.308852&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;149&lt;/td&gt;
      &lt;td&gt;0.994885&lt;/td&gt;
      &lt;td&gt;1.158710&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;0.988591&lt;/td&gt;
      &lt;td&gt;1.089001&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;151&lt;/td&gt;
      &lt;td&gt;0.983139&lt;/td&gt;
      &lt;td&gt;1.057717&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;152&lt;/td&gt;
      &lt;td&gt;0.980064&lt;/td&gt;
      &lt;td&gt;1.021482&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;153&lt;/td&gt;
      &lt;td&gt;0.976560&lt;/td&gt;
      &lt;td&gt;1.005424&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;0.974256&lt;/td&gt;
      &lt;td&gt;1.056330&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;155&lt;/td&gt;
      &lt;td&gt;0.970273&lt;/td&gt;
      &lt;td&gt;1.198120&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;156&lt;/td&gt;
      &lt;td&gt;0.965092&lt;/td&gt;
      &lt;td&gt;1.395134&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;157&lt;/td&gt;
      &lt;td&gt;0.962309&lt;/td&gt;
      &lt;td&gt;1.325926&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;0.958749&lt;/td&gt;
      &lt;td&gt;1.232951&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;159&lt;/td&gt;
      &lt;td&gt;0.953150&lt;/td&gt;
      &lt;td&gt;1.236645&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;0.948714&lt;/td&gt;
      &lt;td&gt;1.141429&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;161&lt;/td&gt;
      &lt;td&gt;0.943281&lt;/td&gt;
      &lt;td&gt;1.050981&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;0.942111&lt;/td&gt;
      &lt;td&gt;1.027893&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;163&lt;/td&gt;
      &lt;td&gt;0.935896&lt;/td&gt;
      &lt;td&gt;1.021700&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;164&lt;/td&gt;
      &lt;td&gt;0.934182&lt;/td&gt;
      &lt;td&gt;1.058105&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;165&lt;/td&gt;
      &lt;td&gt;0.931000&lt;/td&gt;
      &lt;td&gt;1.137445&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;166&lt;/td&gt;
      &lt;td&gt;0.934147&lt;/td&gt;
      &lt;td&gt;1.215132&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;167&lt;/td&gt;
      &lt;td&gt;0.930111&lt;/td&gt;
      &lt;td&gt;1.241952&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;168&lt;/td&gt;
      &lt;td&gt;0.926065&lt;/td&gt;
      &lt;td&gt;1.256834&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;0.920515&lt;/td&gt;
      &lt;td&gt;1.266970&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;170&lt;/td&gt;
      &lt;td&gt;0.916091&lt;/td&gt;
      &lt;td&gt;1.295894&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;171&lt;/td&gt;
      &lt;td&gt;0.916563&lt;/td&gt;
      &lt;td&gt;1.379379&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;172&lt;/td&gt;
      &lt;td&gt;0.913004&lt;/td&gt;
      &lt;td&gt;1.357460&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;0.909355&lt;/td&gt;
      &lt;td&gt;1.322893&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;174&lt;/td&gt;
      &lt;td&gt;0.907756&lt;/td&gt;
      &lt;td&gt;1.289818&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;175&lt;/td&gt;
      &lt;td&gt;0.905712&lt;/td&gt;
      &lt;td&gt;1.310621&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;176&lt;/td&gt;
      &lt;td&gt;0.906727&lt;/td&gt;
      &lt;td&gt;1.289430&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;177&lt;/td&gt;
      &lt;td&gt;0.906684&lt;/td&gt;
      &lt;td&gt;1.339022&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;178&lt;/td&gt;
      &lt;td&gt;0.906677&lt;/td&gt;
      &lt;td&gt;1.321404&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;179&lt;/td&gt;
      &lt;td&gt;0.903140&lt;/td&gt;
      &lt;td&gt;1.323079&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;180&lt;/td&gt;
      &lt;td&gt;0.899265&lt;/td&gt;
      &lt;td&gt;1.351478&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;181&lt;/td&gt;
      &lt;td&gt;0.895234&lt;/td&gt;
      &lt;td&gt;1.308878&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;0.894889&lt;/td&gt;
      &lt;td&gt;1.251764&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;0.893129&lt;/td&gt;
      &lt;td&gt;1.269285&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;184&lt;/td&gt;
      &lt;td&gt;0.887717&lt;/td&gt;
      &lt;td&gt;1.244808&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;185&lt;/td&gt;
      &lt;td&gt;0.884424&lt;/td&gt;
      &lt;td&gt;1.245035&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;186&lt;/td&gt;
      &lt;td&gt;0.888531&lt;/td&gt;
      &lt;td&gt;1.224573&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;187&lt;/td&gt;
      &lt;td&gt;0.885721&lt;/td&gt;
      &lt;td&gt;1.242810&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;188&lt;/td&gt;
      &lt;td&gt;0.883915&lt;/td&gt;
      &lt;td&gt;1.238724&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;189&lt;/td&gt;
      &lt;td&gt;0.880226&lt;/td&gt;
      &lt;td&gt;1.209234&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;190&lt;/td&gt;
      &lt;td&gt;0.877577&lt;/td&gt;
      &lt;td&gt;1.236441&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;191&lt;/td&gt;
      &lt;td&gt;0.874377&lt;/td&gt;
      &lt;td&gt;1.232569&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192&lt;/td&gt;
      &lt;td&gt;0.871007&lt;/td&gt;
      &lt;td&gt;1.249061&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;193&lt;/td&gt;
      &lt;td&gt;0.873851&lt;/td&gt;
      &lt;td&gt;1.186095&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;194&lt;/td&gt;
      &lt;td&gt;0.869425&lt;/td&gt;
      &lt;td&gt;1.165819&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;0.865002&lt;/td&gt;
      &lt;td&gt;1.161543&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;196&lt;/td&gt;
      &lt;td&gt;0.863245&lt;/td&gt;
      &lt;td&gt;1.160168&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;197&lt;/td&gt;
      &lt;td&gt;0.861162&lt;/td&gt;
      &lt;td&gt;1.164579&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;198&lt;/td&gt;
      &lt;td&gt;0.859056&lt;/td&gt;
      &lt;td&gt;1.186687&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;199&lt;/td&gt;
      &lt;td&gt;0.862104&lt;/td&gt;
      &lt;td&gt;1.236917&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2&gt;Scheduled data transformation&lt;/h2&gt;
&lt;p&gt;As a bonus, for those of you who enjoy more complex approaches, I've created a function that will allow you to automatically adjust the value of the alpha parameter during training. Let's see how it works.&lt;/p&gt;
&lt;p&gt;☣️ Please, bear in mind that the minimum value of alpha for mixup is &amp;gt; 0 (this is a current fastai constraint). So if you want to start from 0, you can use something like .001 instead. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;LabelSmoothingCrossEntropy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="n"&gt;tfm_fn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mixup&lt;/span&gt;
&lt;span class="n"&gt;sch_param&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;alpha&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;sch_val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mo"&gt;001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;              &lt;span class="c1"&gt;# values of parameter alpha (initial, final)&lt;/span&gt;
&lt;span class="n"&gt;sch_iter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;               &lt;span class="c1"&gt;# percent of training epochs (start, end)&lt;/span&gt;
&lt;span class="n"&gt;sch_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;annealing_cos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# annealing_cos, None = annealing_linear, cosine_annealing&lt;/span&gt;
&lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;                       &lt;span class="c1"&gt;# set to True for adjusting the values. When ready to train set to False&lt;/span&gt;
&lt;span class="n"&gt;sch_tfm_cb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TfmScheduler&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tfm_fn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tfm_fn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sch_param&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sch_param&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sch_val&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sch_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                      &lt;span class="n"&gt;sch_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sch_iter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sch_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sch_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;callback_fns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sch_tfm_cb&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_one_cycle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="k"&gt;between&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;001&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;iters&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;70&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/TSC/output_62_1.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;div&amp;gt;&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="s s-Atom"&gt;style&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="cm"&gt;/* Turns off some styling */&lt;/span&gt;
        &lt;span class="s s-Atom"&gt;progress&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="cm"&gt;/* gets rid of default border in Firefox and Opera. */&lt;/span&gt;
            &lt;span class="nn"&gt;border&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s s-Atom"&gt;none&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="cm"&gt;/* Needs to be in here for Safari polyfill so background images work as expected. */&lt;/span&gt;
            &lt;span class="s s-Atom"&gt;background&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nn"&gt;size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s s-Atom"&gt;auto&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s s-Atom"&gt;progress&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;interrupted&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="s s-Atom"&gt;progress&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nn"&gt;interrupted&lt;/span&gt;&lt;span class="p"&gt;::-&lt;/span&gt;&lt;span class="s s-Atom"&gt;webkit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;progress&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="s s-Atom"&gt;bar&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="nn"&gt;background&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s s-Atom"&gt;#&lt;/span&gt;&lt;span class="nv"&gt;F44336&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="s s-Atom"&gt;&amp;lt;/style&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="s s-Atom"&gt;progress&lt;/span&gt; &lt;span class="s s-Atom"&gt;value=&amp;#39;0&amp;#39;&lt;/span&gt; &lt;span class="s s-Atom"&gt;class=&amp;#39;&amp;#39;&lt;/span&gt; &lt;span class="s s-Atom"&gt;max=&amp;#39;200&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s s-Atom"&gt;style=&amp;#39;width:300px; height:20px; vertical-align: middle;&amp;#39;&amp;gt;&amp;lt;/progress&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="mf"&gt;0.00&lt;/span&gt;&lt;span class="c1"&gt;% [0/200 00:00&amp;lt;00:00]&lt;/span&gt;
&lt;span class="s s-Atom"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="o"&gt;div&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: left;"&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;

    &lt;div&gt;
        &lt;style&gt;
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        &lt;/style&gt;
      &lt;progress value='0' class='progress-bar-interrupted' max='1', style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
      Interrupted
    &lt;/div&gt;





&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;learn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Learner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InceptionTime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;loss_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;LabelSmoothingCrossEntropy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="n"&gt;tfm_fn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mixup&lt;/span&gt;
&lt;span class="n"&gt;sch_param&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;alpha&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;sch_val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mo"&gt;001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;              &lt;span class="c1"&gt;# values of parameter alpha (initial, final)&lt;/span&gt;
&lt;span class="n"&gt;sch_iter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;               &lt;span class="c1"&gt;# percent of training epochs (start, end)&lt;/span&gt;
&lt;span class="n"&gt;sch_func&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;annealing_cos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# annealing_cos, None = annealing_linear, cosine_annealing&lt;/span&gt;
&lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;                      &lt;span class="c1"&gt;# set to True for adjusting the values. When ready to train set to False&lt;/span&gt;
&lt;span class="n"&gt;sch_tfm_cb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TfmScheduler&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tfm_fn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tfm_fn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sch_param&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sch_param&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sch_val&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sch_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                      &lt;span class="n"&gt;sch_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sch_iter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sch_func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sch_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;callback_fns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sch_tfm_cb&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;learn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_one_cycle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;




     alpha between 0.001 and 1.0 in iters 0.00 to 0.70



![png](/images/TSC/output_63_1.png)



&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: left;"&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1.626387&lt;/td&gt;
      &lt;td&gt;1.627592&lt;/td&gt;
      &lt;td&gt;0.100000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.601632&lt;/td&gt;
      &lt;td&gt;1.626852&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1.580567&lt;/td&gt;
      &lt;td&gt;1.626486&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;1.561646&lt;/td&gt;
      &lt;td&gt;1.626253&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1.543889&lt;/td&gt;
      &lt;td&gt;1.625805&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1.526808&lt;/td&gt;
      &lt;td&gt;1.625060&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;1.510128&lt;/td&gt;
      &lt;td&gt;1.624043&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;1.493622&lt;/td&gt;
      &lt;td&gt;1.622928&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;1.477247&lt;/td&gt;
      &lt;td&gt;1.621706&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;1.461012&lt;/td&gt;
      &lt;td&gt;1.620356&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1.444964&lt;/td&gt;
      &lt;td&gt;1.618782&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;1.429263&lt;/td&gt;
      &lt;td&gt;1.616995&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;1.415805&lt;/td&gt;
      &lt;td&gt;1.614870&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;1.401853&lt;/td&gt;
      &lt;td&gt;1.613464&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;1.388338&lt;/td&gt;
      &lt;td&gt;1.609434&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;1.374339&lt;/td&gt;
      &lt;td&gt;1.610430&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1.362183&lt;/td&gt;
      &lt;td&gt;1.602663&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;1.348864&lt;/td&gt;
      &lt;td&gt;1.601656&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;1.335258&lt;/td&gt;
      &lt;td&gt;1.606995&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;1.321574&lt;/td&gt;
      &lt;td&gt;1.596013&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;1.306098&lt;/td&gt;
      &lt;td&gt;1.592437&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;1.293900&lt;/td&gt;
      &lt;td&gt;1.581123&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;1.279845&lt;/td&gt;
      &lt;td&gt;1.564399&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;1.271103&lt;/td&gt;
      &lt;td&gt;1.500022&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;1.261507&lt;/td&gt;
      &lt;td&gt;1.535057&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;1.248613&lt;/td&gt;
      &lt;td&gt;1.472087&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;1.237349&lt;/td&gt;
      &lt;td&gt;1.417059&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;1.225417&lt;/td&gt;
      &lt;td&gt;1.435310&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;1.214563&lt;/td&gt;
      &lt;td&gt;1.365397&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;1.203867&lt;/td&gt;
      &lt;td&gt;1.452246&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;1.194183&lt;/td&gt;
      &lt;td&gt;1.263637&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1.185022&lt;/td&gt;
      &lt;td&gt;1.283553&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;1.171834&lt;/td&gt;
      &lt;td&gt;1.517067&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;1.163586&lt;/td&gt;
      &lt;td&gt;1.597277&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;1.149949&lt;/td&gt;
      &lt;td&gt;1.694383&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;1.138015&lt;/td&gt;
      &lt;td&gt;1.358102&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;1.124267&lt;/td&gt;
      &lt;td&gt;2.482912&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;1.120735&lt;/td&gt;
      &lt;td&gt;1.297349&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;1.109981&lt;/td&gt;
      &lt;td&gt;2.298659&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;1.103910&lt;/td&gt;
      &lt;td&gt;4.613716&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;1.101009&lt;/td&gt;
      &lt;td&gt;9.654345&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;1.094292&lt;/td&gt;
      &lt;td&gt;5.961040&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;1.091424&lt;/td&gt;
      &lt;td&gt;4.990852&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;1.085680&lt;/td&gt;
      &lt;td&gt;6.741884&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;44&lt;/td&gt;
      &lt;td&gt;1.078918&lt;/td&gt;
      &lt;td&gt;1.311232&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;1.077116&lt;/td&gt;
      &lt;td&gt;3.062059&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;1.070217&lt;/td&gt;
      &lt;td&gt;1.283510&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;1.064868&lt;/td&gt;
      &lt;td&gt;3.715569&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;48&lt;/td&gt;
      &lt;td&gt;1.059177&lt;/td&gt;
      &lt;td&gt;1.724050&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;49&lt;/td&gt;
      &lt;td&gt;1.054424&lt;/td&gt;
      &lt;td&gt;4.899724&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;1.054437&lt;/td&gt;
      &lt;td&gt;2.283245&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;1.053111&lt;/td&gt;
      &lt;td&gt;2.297719&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;52&lt;/td&gt;
      &lt;td&gt;1.050523&lt;/td&gt;
      &lt;td&gt;2.093637&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;1.047141&lt;/td&gt;
      &lt;td&gt;1.727470&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;1.046703&lt;/td&gt;
      &lt;td&gt;4.376657&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;1.043961&lt;/td&gt;
      &lt;td&gt;6.196053&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;1.039703&lt;/td&gt;
      &lt;td&gt;6.152739&lt;/td&gt;
      &lt;td&gt;0.266667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;57&lt;/td&gt;
      &lt;td&gt;1.035884&lt;/td&gt;
      &lt;td&gt;8.199553&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;1.033973&lt;/td&gt;
      &lt;td&gt;9.609694&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;1.030891&lt;/td&gt;
      &lt;td&gt;6.227965&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;1.028900&lt;/td&gt;
      &lt;td&gt;5.746769&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;1.027948&lt;/td&gt;
      &lt;td&gt;5.763941&lt;/td&gt;
      &lt;td&gt;0.200000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;1.028211&lt;/td&gt;
      &lt;td&gt;2.939988&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;63&lt;/td&gt;
      &lt;td&gt;1.028534&lt;/td&gt;
      &lt;td&gt;1.482004&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;1.029271&lt;/td&gt;
      &lt;td&gt;4.230787&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;65&lt;/td&gt;
      &lt;td&gt;1.029912&lt;/td&gt;
      &lt;td&gt;6.466330&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;66&lt;/td&gt;
      &lt;td&gt;1.027463&lt;/td&gt;
      &lt;td&gt;3.925814&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;67&lt;/td&gt;
      &lt;td&gt;1.025617&lt;/td&gt;
      &lt;td&gt;3.920921&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;1.022813&lt;/td&gt;
      &lt;td&gt;3.472798&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;69&lt;/td&gt;
      &lt;td&gt;1.018501&lt;/td&gt;
      &lt;td&gt;3.049520&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;1.018678&lt;/td&gt;
      &lt;td&gt;2.491311&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;1.017646&lt;/td&gt;
      &lt;td&gt;1.477216&lt;/td&gt;
      &lt;td&gt;0.300000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;1.015955&lt;/td&gt;
      &lt;td&gt;2.422115&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1.011675&lt;/td&gt;
      &lt;td&gt;1.438160&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;1.006047&lt;/td&gt;
      &lt;td&gt;1.375284&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;1.002805&lt;/td&gt;
      &lt;td&gt;1.802636&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;76&lt;/td&gt;
      &lt;td&gt;0.998354&lt;/td&gt;
      &lt;td&gt;3.754055&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;77&lt;/td&gt;
      &lt;td&gt;0.994339&lt;/td&gt;
      &lt;td&gt;2.482006&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;78&lt;/td&gt;
      &lt;td&gt;0.994594&lt;/td&gt;
      &lt;td&gt;1.123771&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;79&lt;/td&gt;
      &lt;td&gt;0.992726&lt;/td&gt;
      &lt;td&gt;1.100370&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;0.993869&lt;/td&gt;
      &lt;td&gt;1.098626&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;0.989084&lt;/td&gt;
      &lt;td&gt;0.969644&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;0.986687&lt;/td&gt;
      &lt;td&gt;1.031124&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;0.985856&lt;/td&gt;
      &lt;td&gt;1.389311&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;84&lt;/td&gt;
      &lt;td&gt;0.982548&lt;/td&gt;
      &lt;td&gt;1.677026&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;0.980049&lt;/td&gt;
      &lt;td&gt;1.984690&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;86&lt;/td&gt;
      &lt;td&gt;0.977262&lt;/td&gt;
      &lt;td&gt;2.663417&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;87&lt;/td&gt;
      &lt;td&gt;0.974976&lt;/td&gt;
      &lt;td&gt;2.417084&lt;/td&gt;
      &lt;td&gt;0.233333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;88&lt;/td&gt;
      &lt;td&gt;0.975138&lt;/td&gt;
      &lt;td&gt;1.385765&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;89&lt;/td&gt;
      &lt;td&gt;0.972034&lt;/td&gt;
      &lt;td&gt;1.563319&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;0.969463&lt;/td&gt;
      &lt;td&gt;1.633355&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;91&lt;/td&gt;
      &lt;td&gt;0.968935&lt;/td&gt;
      &lt;td&gt;2.039129&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;92&lt;/td&gt;
      &lt;td&gt;0.967603&lt;/td&gt;
      &lt;td&gt;1.541844&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;93&lt;/td&gt;
      &lt;td&gt;0.968810&lt;/td&gt;
      &lt;td&gt;1.315756&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;94&lt;/td&gt;
      &lt;td&gt;0.970300&lt;/td&gt;
      &lt;td&gt;3.284852&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;95&lt;/td&gt;
      &lt;td&gt;0.971463&lt;/td&gt;
      &lt;td&gt;3.589286&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;0.971568&lt;/td&gt;
      &lt;td&gt;2.353341&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;97&lt;/td&gt;
      &lt;td&gt;0.970776&lt;/td&gt;
      &lt;td&gt;2.591434&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;98&lt;/td&gt;
      &lt;td&gt;0.970075&lt;/td&gt;
      &lt;td&gt;2.927469&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;99&lt;/td&gt;
      &lt;td&gt;0.971289&lt;/td&gt;
      &lt;td&gt;2.609849&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;0.974466&lt;/td&gt;
      &lt;td&gt;2.325409&lt;/td&gt;
      &lt;td&gt;0.333333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;101&lt;/td&gt;
      &lt;td&gt;0.974490&lt;/td&gt;
      &lt;td&gt;2.081188&lt;/td&gt;
      &lt;td&gt;0.366667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;0.973824&lt;/td&gt;
      &lt;td&gt;1.359118&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;103&lt;/td&gt;
      &lt;td&gt;0.972219&lt;/td&gt;
      &lt;td&gt;1.090843&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;104&lt;/td&gt;
      &lt;td&gt;0.971711&lt;/td&gt;
      &lt;td&gt;1.190391&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;105&lt;/td&gt;
      &lt;td&gt;0.972649&lt;/td&gt;
      &lt;td&gt;1.588080&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;0.974650&lt;/td&gt;
      &lt;td&gt;1.835901&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;107&lt;/td&gt;
      &lt;td&gt;0.973514&lt;/td&gt;
      &lt;td&gt;1.870666&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;108&lt;/td&gt;
      &lt;td&gt;0.972411&lt;/td&gt;
      &lt;td&gt;1.652206&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;0.974086&lt;/td&gt;
      &lt;td&gt;1.278639&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;110&lt;/td&gt;
      &lt;td&gt;0.974933&lt;/td&gt;
      &lt;td&gt;1.040625&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;111&lt;/td&gt;
      &lt;td&gt;0.972952&lt;/td&gt;
      &lt;td&gt;1.021651&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;112&lt;/td&gt;
      &lt;td&gt;0.971806&lt;/td&gt;
      &lt;td&gt;1.343572&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;113&lt;/td&gt;
      &lt;td&gt;0.969928&lt;/td&gt;
      &lt;td&gt;1.387259&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;114&lt;/td&gt;
      &lt;td&gt;0.967772&lt;/td&gt;
      &lt;td&gt;1.570803&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;115&lt;/td&gt;
      &lt;td&gt;0.965366&lt;/td&gt;
      &lt;td&gt;1.621146&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;116&lt;/td&gt;
      &lt;td&gt;0.962725&lt;/td&gt;
      &lt;td&gt;1.714004&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;117&lt;/td&gt;
      &lt;td&gt;0.960849&lt;/td&gt;
      &lt;td&gt;1.907067&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;118&lt;/td&gt;
      &lt;td&gt;0.957004&lt;/td&gt;
      &lt;td&gt;1.591835&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;119&lt;/td&gt;
      &lt;td&gt;0.958164&lt;/td&gt;
      &lt;td&gt;1.680010&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;0.958625&lt;/td&gt;
      &lt;td&gt;1.225325&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;121&lt;/td&gt;
      &lt;td&gt;0.956625&lt;/td&gt;
      &lt;td&gt;1.107982&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;122&lt;/td&gt;
      &lt;td&gt;0.957369&lt;/td&gt;
      &lt;td&gt;1.121521&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;123&lt;/td&gt;
      &lt;td&gt;0.955815&lt;/td&gt;
      &lt;td&gt;1.202939&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;124&lt;/td&gt;
      &lt;td&gt;0.954944&lt;/td&gt;
      &lt;td&gt;1.234500&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;125&lt;/td&gt;
      &lt;td&gt;0.954373&lt;/td&gt;
      &lt;td&gt;1.474302&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;126&lt;/td&gt;
      &lt;td&gt;0.951846&lt;/td&gt;
      &lt;td&gt;1.589271&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;127&lt;/td&gt;
      &lt;td&gt;0.951891&lt;/td&gt;
      &lt;td&gt;1.673985&lt;/td&gt;
      &lt;td&gt;0.566667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;0.953131&lt;/td&gt;
      &lt;td&gt;1.567316&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;129&lt;/td&gt;
      &lt;td&gt;0.953709&lt;/td&gt;
      &lt;td&gt;1.088511&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;0.953542&lt;/td&gt;
      &lt;td&gt;1.128953&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;131&lt;/td&gt;
      &lt;td&gt;0.952610&lt;/td&gt;
      &lt;td&gt;1.575795&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;132&lt;/td&gt;
      &lt;td&gt;0.953830&lt;/td&gt;
      &lt;td&gt;1.743010&lt;/td&gt;
      &lt;td&gt;0.533333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;133&lt;/td&gt;
      &lt;td&gt;0.951794&lt;/td&gt;
      &lt;td&gt;1.571326&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;134&lt;/td&gt;
      &lt;td&gt;0.949696&lt;/td&gt;
      &lt;td&gt;1.577728&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;135&lt;/td&gt;
      &lt;td&gt;0.952297&lt;/td&gt;
      &lt;td&gt;1.815940&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;0.952972&lt;/td&gt;
      &lt;td&gt;2.064868&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;0.955628&lt;/td&gt;
      &lt;td&gt;2.435957&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;138&lt;/td&gt;
      &lt;td&gt;0.954675&lt;/td&gt;
      &lt;td&gt;2.641927&lt;/td&gt;
      &lt;td&gt;0.400000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;139&lt;/td&gt;
      &lt;td&gt;0.954418&lt;/td&gt;
      &lt;td&gt;2.548305&lt;/td&gt;
      &lt;td&gt;0.433333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;140&lt;/td&gt;
      &lt;td&gt;0.955395&lt;/td&gt;
      &lt;td&gt;1.842673&lt;/td&gt;
      &lt;td&gt;0.466667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;141&lt;/td&gt;
      &lt;td&gt;0.955617&lt;/td&gt;
      &lt;td&gt;1.097640&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;142&lt;/td&gt;
      &lt;td&gt;0.954719&lt;/td&gt;
      &lt;td&gt;0.925584&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;0.956634&lt;/td&gt;
      &lt;td&gt;0.877834&lt;/td&gt;
      &lt;td&gt;0.733333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;144&lt;/td&gt;
      &lt;td&gt;0.954160&lt;/td&gt;
      &lt;td&gt;0.841679&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;0.954152&lt;/td&gt;
      &lt;td&gt;0.808143&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;146&lt;/td&gt;
      &lt;td&gt;0.954123&lt;/td&gt;
      &lt;td&gt;0.787732&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;147&lt;/td&gt;
      &lt;td&gt;0.951483&lt;/td&gt;
      &lt;td&gt;0.767450&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;148&lt;/td&gt;
      &lt;td&gt;0.949662&lt;/td&gt;
      &lt;td&gt;0.753072&lt;/td&gt;
      &lt;td&gt;0.900000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;149&lt;/td&gt;
      &lt;td&gt;0.947428&lt;/td&gt;
      &lt;td&gt;0.766489&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;0.948786&lt;/td&gt;
      &lt;td&gt;0.804269&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;151&lt;/td&gt;
      &lt;td&gt;0.946424&lt;/td&gt;
      &lt;td&gt;0.854882&lt;/td&gt;
      &lt;td&gt;0.700000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;152&lt;/td&gt;
      &lt;td&gt;0.947040&lt;/td&gt;
      &lt;td&gt;0.908327&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;153&lt;/td&gt;
      &lt;td&gt;0.945913&lt;/td&gt;
      &lt;td&gt;0.951015&lt;/td&gt;
      &lt;td&gt;0.666667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;0.945124&lt;/td&gt;
      &lt;td&gt;1.022153&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;155&lt;/td&gt;
      &lt;td&gt;0.943171&lt;/td&gt;
      &lt;td&gt;1.066825&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;156&lt;/td&gt;
      &lt;td&gt;0.942373&lt;/td&gt;
      &lt;td&gt;1.054384&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;157&lt;/td&gt;
      &lt;td&gt;0.940294&lt;/td&gt;
      &lt;td&gt;0.997566&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;0.940491&lt;/td&gt;
      &lt;td&gt;0.971229&lt;/td&gt;
      &lt;td&gt;0.633333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;159&lt;/td&gt;
      &lt;td&gt;0.939682&lt;/td&gt;
      &lt;td&gt;0.846206&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;0.939346&lt;/td&gt;
      &lt;td&gt;0.764268&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;161&lt;/td&gt;
      &lt;td&gt;0.937229&lt;/td&gt;
      &lt;td&gt;0.754534&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;0.933547&lt;/td&gt;
      &lt;td&gt;0.787042&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;163&lt;/td&gt;
      &lt;td&gt;0.933203&lt;/td&gt;
      &lt;td&gt;0.857130&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;164&lt;/td&gt;
      &lt;td&gt;0.933637&lt;/td&gt;
      &lt;td&gt;0.915972&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;165&lt;/td&gt;
      &lt;td&gt;0.931348&lt;/td&gt;
      &lt;td&gt;0.919065&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;166&lt;/td&gt;
      &lt;td&gt;0.931428&lt;/td&gt;
      &lt;td&gt;0.859337&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;167&lt;/td&gt;
      &lt;td&gt;0.929779&lt;/td&gt;
      &lt;td&gt;0.789867&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;168&lt;/td&gt;
      &lt;td&gt;0.928110&lt;/td&gt;
      &lt;td&gt;0.753117&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;169&lt;/td&gt;
      &lt;td&gt;0.926101&lt;/td&gt;
      &lt;td&gt;0.738458&lt;/td&gt;
      &lt;td&gt;0.866667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;170&lt;/td&gt;
      &lt;td&gt;0.925353&lt;/td&gt;
      &lt;td&gt;0.755080&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;171&lt;/td&gt;
      &lt;td&gt;0.926029&lt;/td&gt;
      &lt;td&gt;0.771436&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;172&lt;/td&gt;
      &lt;td&gt;0.925250&lt;/td&gt;
      &lt;td&gt;0.785918&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;0.924132&lt;/td&gt;
      &lt;td&gt;0.790192&lt;/td&gt;
      &lt;td&gt;0.766667&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;174&lt;/td&gt;
      &lt;td&gt;0.924556&lt;/td&gt;
      &lt;td&gt;0.791276&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;175&lt;/td&gt;
      &lt;td&gt;0.923391&lt;/td&gt;
      &lt;td&gt;0.790005&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;176&lt;/td&gt;
      &lt;td&gt;0.921544&lt;/td&gt;
      &lt;td&gt;0.790712&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;177&lt;/td&gt;
      &lt;td&gt;0.919461&lt;/td&gt;
      &lt;td&gt;0.794095&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;178&lt;/td&gt;
      &lt;td&gt;0.917881&lt;/td&gt;
      &lt;td&gt;0.796023&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;179&lt;/td&gt;
      &lt;td&gt;0.917527&lt;/td&gt;
      &lt;td&gt;0.795494&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;180&lt;/td&gt;
      &lt;td&gt;0.915659&lt;/td&gt;
      &lt;td&gt;0.784916&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;181&lt;/td&gt;
      &lt;td&gt;0.915729&lt;/td&gt;
      &lt;td&gt;0.777742&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;0.914645&lt;/td&gt;
      &lt;td&gt;0.770701&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;183&lt;/td&gt;
      &lt;td&gt;0.913537&lt;/td&gt;
      &lt;td&gt;0.767288&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;184&lt;/td&gt;
      &lt;td&gt;0.912305&lt;/td&gt;
      &lt;td&gt;0.764935&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;185&lt;/td&gt;
      &lt;td&gt;0.910081&lt;/td&gt;
      &lt;td&gt;0.762620&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;186&lt;/td&gt;
      &lt;td&gt;0.908561&lt;/td&gt;
      &lt;td&gt;0.763817&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;187&lt;/td&gt;
      &lt;td&gt;0.909015&lt;/td&gt;
      &lt;td&gt;0.764751&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;188&lt;/td&gt;
      &lt;td&gt;0.908268&lt;/td&gt;
      &lt;td&gt;0.764663&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;189&lt;/td&gt;
      &lt;td&gt;0.907292&lt;/td&gt;
      &lt;td&gt;0.765498&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;190&lt;/td&gt;
      &lt;td&gt;0.905085&lt;/td&gt;
      &lt;td&gt;0.766115&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;191&lt;/td&gt;
      &lt;td&gt;0.904604&lt;/td&gt;
      &lt;td&gt;0.768526&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192&lt;/td&gt;
      &lt;td&gt;0.904123&lt;/td&gt;
      &lt;td&gt;0.769853&lt;/td&gt;
      &lt;td&gt;0.833333&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;193&lt;/td&gt;
      &lt;td&gt;0.903383&lt;/td&gt;
      &lt;td&gt;0.774133&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;194&lt;/td&gt;
      &lt;td&gt;0.901851&lt;/td&gt;
      &lt;td&gt;0.778949&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;195&lt;/td&gt;
      &lt;td&gt;0.901167&lt;/td&gt;
      &lt;td&gt;0.782591&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;196&lt;/td&gt;
      &lt;td&gt;0.900324&lt;/td&gt;
      &lt;td&gt;0.784429&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;197&lt;/td&gt;
      &lt;td&gt;0.898247&lt;/td&gt;
      &lt;td&gt;0.786330&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;198&lt;/td&gt;
      &lt;td&gt;0.897429&lt;/td&gt;
      &lt;td&gt;0.791879&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;199&lt;/td&gt;
      &lt;td&gt;0.897475&lt;/td&gt;
      &lt;td&gt;0.795262&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;00:02&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;


In this case, the scheduled approach didn't improve performance.

This is all for now! I hope you find this as useful as I have.



&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="Time Series Classification"></category><category term="Machine Learning"></category><category term="timeseriesAI"></category><category term="Time Series Classification"></category><category term="fastai_timeseries"></category><category term="data augmentation"></category></entry><entry><title>Time Series Clustering and Classification using sequence-to-sequence modeling</title><link href="https://mmadkour.xyz%5Cposts/2019/10/sequence-to-sequence,%20Time%20Series%20Classification/" rel="alternate"></link><published>2019-10-12T13:01:00-04:00</published><updated>2019-10-12T13:01:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2019-10-12:/2019/10/sequence-to-sequence, Time Series Classification/</id><summary type="html">&lt;p&gt;What I want to do is build a model for sequence-to-sequence type prediction on the Dow Jones Industrial Average (DJI). However, rather than treat this as a regression problem, I want to discretize the problem, so that what I am predicting is one of a set number of possible “types …&lt;/p&gt;</summary><content type="html">&lt;p&gt;What I want to do is build a model for sequence-to-sequence type prediction on the Dow Jones Industrial Average (DJI). However, rather than treat this as a regression problem, I want to discretize the problem, so that what I am predicting is one of a set number of possible “types” of predictions. Using SAX and PAA, I can take the closing prices of the DJI on 50 consecutive days. I do this by using PAA to reduce the window of 50 points to 3 points, and use the letters ‘a’ and ‘b’ (below mean, above mean) to describe this windows as a three letter word such as ‘aab’ or ‘aba’. Since I am only using ‘a’ and ‘b’, I have 8 possibilities, though only 6 show up in the data (from 1970–present). Here’s how I did this: first, I used the &lt;a href="https://github.com/manu-mannattil/nolitsa"&gt;nolitsa&lt;/a&gt; library to do some simple moving average smoothing on the data. Then I created the 50 time step windows with a stride of 1 (so lots of overlapping) using the &lt;a href="https://pypi.org/project/pyentrp/"&gt;pyentrp&lt;/a&gt;. Finally, I used saxpy to do PAA (reducing 50 to 3) and then SAX to create symbolic representation using 2 letters.&lt;/p&gt;
&lt;p&gt;Data can be found in the the Kaggle competition: &lt;a href="https://www.kaggle.com/szrlee/stock-time-series-20050101-to-20171231"&gt;DJIA 30 Stock Time Series&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pyentrp&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;entropy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;ent&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;saxpy.znorm&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;znorm&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;saxpy.paa&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;paa&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;saxpy.sax&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ts_to_string&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;saxpy.alphabet&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cuts_for_asize&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt; 
&lt;span class="n"&gt;dow_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ent&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;util_pattern_space&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hist_sma&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lag&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dow_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dow_df&lt;/span&gt;&lt;span class="p"&gt;[:]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dow_df&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
    &lt;span class="n"&gt;dat_znorm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;znorm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dow_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,:])&lt;/span&gt;
    &lt;span class="n"&gt;dat_paa&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;paa&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dat_znorm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#three letter words&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ts_to_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dat_paa&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cuts_for_asize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# 2 let alphabet&lt;/span&gt;
    &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a href="https://jmotif.github.io/sax-vsm_site/morea/algorithm/SAX.html"&gt;Symbolic Aggregate Approximation (SAX)&lt;/a&gt; is a way of discretizing a time series so that it can be represented with a sequence of alphabetical letters, forming a “word”. &lt;a href="https://jmotif.github.io/sax-vsm_site/morea/algorithm/PAA.html"&gt;Piecewise Aggregate Approximation (PAA)&lt;/a&gt; shortens the time series.&lt;/p&gt;
&lt;p&gt;I used a standard Bidirectional LSTM with one layer and then a Dense/Softmax layer and a sequence of anything from 3–10 timesteps to make the prediction of the next step.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Bidirectional&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_initializer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;he_normal&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;return_sequences&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;False&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                           &lt;span class="n"&gt;input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_timesteps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Bidirectional&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;return_sequences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;                     
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Adam&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;001&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;acc&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;With early stopping, you can get around 84% F1-score, so that’s not too bad, though the sequence itself is not that varied. Of the 6 “labels” you will find that it stays this way for quite a number of steps (at least more than 10) before changing into another label. When you look at the predictions and the ground-truth, you will find that the transitions are always off — that’s where the model makes a bunch of mistakes. It tends to “figure out” the change 1 or 2 steps after it happens in ground-truth.&lt;/p&gt;
&lt;p&gt;Next, I decided to use the tslearn package to cluster the 50 time step windows; using the Euclidean metric (the fastest one by a long shot). I wanted to see what I would get if I demanded 6 clusters.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;km&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TimeSeriesKMeans&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_clusters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="k"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;km&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is what came out:
&lt;img alt="png" src="/images/1_I2etnM2Qm9ifnDFUG2INeg.png"&gt;&lt;/p&gt;
&lt;p&gt;There is some level of resemblance between the ‘words’ and the ‘clusters’. If you were just dealing with clusters; you could either train a model to learn the sequence of clusters, or else just create a classification model that takes maybe 20–30 points of your current window, and classify with one of the 6 labels so that you had some idea of where it might go in the near future.
Lastly, I’ll just say that it would be interesting to see what would happen if you either wanted more clusters or if you changed the time period…and also what would happen if you used a stride &amp;gt; 1, thereby downsampling and using less of the data. Maybe some other time.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The Deep Learning models are very powerful solutions to a wide range of Data Science projects. However, even these powerful solutions can't show good results if used naively and without additional efforts to make a proper preparation of the data. The more work we spend to help our models, the better results they will show.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/&lt;/p&gt;</content><category term="Time Series Classification"></category><category term="sequence-to-sequence"></category><category term="Time Series Classification"></category></entry><entry><title>In-depth EDA and K-Means Clustering</title><link href="https://mmadkour.xyz%5Cposts/2019/10/Machine%20Learning,%20Clustering,%20Kmeans/" rel="alternate"></link><published>2019-10-11T13:01:00-04:00</published><updated>2019-10-11T13:01:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2019-10-11:/2019/10/Machine Learning, Clustering, Kmeans/</id><summary type="html">&lt;p&gt;Our world population is expected to grow from 7.3 billion today to 9.7 billion in the year 2050. Finding solutions for feeding the growing world population has become a hot topic for food and agriculture organizations, entrepreneurs and philanthropists. These solutions range from changing the way we grow …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Our world population is expected to grow from 7.3 billion today to 9.7 billion in the year 2050. Finding solutions for feeding the growing world population has become a hot topic for food and agriculture organizations, entrepreneurs and philanthropists. These solutions range from changing the way we grow our food to changing the way we eat. To make things harder, the world's climate is changing and it is both affecting and affected by the way we grow our food – agriculture. This dataset provides an insight on our worldwide food production - focusing on a comparison between food produced for human consumption and feed produced for animals.&lt;/p&gt;
&lt;p&gt;The Food and Agriculture Organization of the United Nations provides free access to food and agriculture data for over 245 countries and territories, from the year 1961 to the most recent update (depends on the dataset). One dataset from the FAO's database is the Food Balance Sheets. It presents a comprehensive picture of the pattern of a country's food supply during a specified reference period, the last time an update was loaded to the FAO database was in 2013. The food balance sheet shows for each food item the sources of supply and its utilization. This chunk of the dataset is focused on two utilizations of each food item available:&lt;/p&gt;
&lt;p&gt;Food - refers to the total amount of the food item available as human food during the reference period.
Feed - refers to the quantity of the food item available for feeding to the livestock and poultry during the reference period.
Dataset's attributes:&lt;/p&gt;
&lt;p&gt;Area code - Country name abbreviation
Area - County name
Item - Food item
Element - Food or Feed
Latitude - geographic coordinate that specifies the north–south position of a point on the Earth's surface
Longitude - geographic coordinate that specifies the east-west position of a point on the Earth's surface
Production per year - Amount of food item produced in 1000 tonnes&lt;/p&gt;
&lt;p&gt;This is a simple exploratory notebook that heavily expolits pandas and seaborn&lt;/p&gt;
&lt;p&gt;The dataset and the notebook can be found at this kaggle competition: https://www.kaggle.com/mmadkour/in-depth-eda-and-k-means-clustering&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Importing libraries&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sns&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="c1"&gt;# importing data&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;../input/FAO.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ISO-8859-1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;chained_assignment&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's see what the data looks like...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Area Abbreviation&lt;/th&gt;
      &lt;th&gt;Area Code&lt;/th&gt;
      &lt;th&gt;Area&lt;/th&gt;
      &lt;th&gt;Item Code&lt;/th&gt;
      &lt;th&gt;Item&lt;/th&gt;
      &lt;th&gt;Element Code&lt;/th&gt;
      &lt;th&gt;Element&lt;/th&gt;
      &lt;th&gt;Unit&lt;/th&gt;
      &lt;th&gt;latitude&lt;/th&gt;
      &lt;th&gt;longitude&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;Y2004&lt;/th&gt;
      &lt;th&gt;Y2005&lt;/th&gt;
      &lt;th&gt;Y2006&lt;/th&gt;
      &lt;th&gt;Y2007&lt;/th&gt;
      &lt;th&gt;Y2008&lt;/th&gt;
      &lt;th&gt;Y2009&lt;/th&gt;
      &lt;th&gt;Y2010&lt;/th&gt;
      &lt;th&gt;Y2011&lt;/th&gt;
      &lt;th&gt;Y2012&lt;/th&gt;
      &lt;th&gt;Y2013&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;AFG&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2511&lt;/td&gt;
      &lt;td&gt;Wheat and products&lt;/td&gt;
      &lt;td&gt;5142&lt;/td&gt;
      &lt;td&gt;Food&lt;/td&gt;
      &lt;td&gt;1000 tonnes&lt;/td&gt;
      &lt;td&gt;33.94&lt;/td&gt;
      &lt;td&gt;67.71&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;3249.0&lt;/td&gt;
      &lt;td&gt;3486.0&lt;/td&gt;
      &lt;td&gt;3704.0&lt;/td&gt;
      &lt;td&gt;4164.0&lt;/td&gt;
      &lt;td&gt;4252.0&lt;/td&gt;
      &lt;td&gt;4538.0&lt;/td&gt;
      &lt;td&gt;4605.0&lt;/td&gt;
      &lt;td&gt;4711.0&lt;/td&gt;
      &lt;td&gt;4810&lt;/td&gt;
      &lt;td&gt;4895&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;AFG&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2805&lt;/td&gt;
      &lt;td&gt;Rice (Milled Equivalent)&lt;/td&gt;
      &lt;td&gt;5142&lt;/td&gt;
      &lt;td&gt;Food&lt;/td&gt;
      &lt;td&gt;1000 tonnes&lt;/td&gt;
      &lt;td&gt;33.94&lt;/td&gt;
      &lt;td&gt;67.71&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;419.0&lt;/td&gt;
      &lt;td&gt;445.0&lt;/td&gt;
      &lt;td&gt;546.0&lt;/td&gt;
      &lt;td&gt;455.0&lt;/td&gt;
      &lt;td&gt;490.0&lt;/td&gt;
      &lt;td&gt;415.0&lt;/td&gt;
      &lt;td&gt;442.0&lt;/td&gt;
      &lt;td&gt;476.0&lt;/td&gt;
      &lt;td&gt;425&lt;/td&gt;
      &lt;td&gt;422&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;AFG&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2513&lt;/td&gt;
      &lt;td&gt;Barley and products&lt;/td&gt;
      &lt;td&gt;5521&lt;/td&gt;
      &lt;td&gt;Feed&lt;/td&gt;
      &lt;td&gt;1000 tonnes&lt;/td&gt;
      &lt;td&gt;33.94&lt;/td&gt;
      &lt;td&gt;67.71&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;58.0&lt;/td&gt;
      &lt;td&gt;236.0&lt;/td&gt;
      &lt;td&gt;262.0&lt;/td&gt;
      &lt;td&gt;263.0&lt;/td&gt;
      &lt;td&gt;230.0&lt;/td&gt;
      &lt;td&gt;379.0&lt;/td&gt;
      &lt;td&gt;315.0&lt;/td&gt;
      &lt;td&gt;203.0&lt;/td&gt;
      &lt;td&gt;367&lt;/td&gt;
      &lt;td&gt;360&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;AFG&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2513&lt;/td&gt;
      &lt;td&gt;Barley and products&lt;/td&gt;
      &lt;td&gt;5142&lt;/td&gt;
      &lt;td&gt;Food&lt;/td&gt;
      &lt;td&gt;1000 tonnes&lt;/td&gt;
      &lt;td&gt;33.94&lt;/td&gt;
      &lt;td&gt;67.71&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;185.0&lt;/td&gt;
      &lt;td&gt;43.0&lt;/td&gt;
      &lt;td&gt;44.0&lt;/td&gt;
      &lt;td&gt;48.0&lt;/td&gt;
      &lt;td&gt;62.0&lt;/td&gt;
      &lt;td&gt;55.0&lt;/td&gt;
      &lt;td&gt;60.0&lt;/td&gt;
      &lt;td&gt;72.0&lt;/td&gt;
      &lt;td&gt;78&lt;/td&gt;
      &lt;td&gt;89&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;AFG&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2514&lt;/td&gt;
      &lt;td&gt;Maize and products&lt;/td&gt;
      &lt;td&gt;5521&lt;/td&gt;
      &lt;td&gt;Feed&lt;/td&gt;
      &lt;td&gt;1000 tonnes&lt;/td&gt;
      &lt;td&gt;33.94&lt;/td&gt;
      &lt;td&gt;67.71&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;120.0&lt;/td&gt;
      &lt;td&gt;208.0&lt;/td&gt;
      &lt;td&gt;233.0&lt;/td&gt;
      &lt;td&gt;249.0&lt;/td&gt;
      &lt;td&gt;247.0&lt;/td&gt;
      &lt;td&gt;195.0&lt;/td&gt;
      &lt;td&gt;178.0&lt;/td&gt;
      &lt;td&gt;191.0&lt;/td&gt;
      &lt;td&gt;200&lt;/td&gt;
      &lt;td&gt;200&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 63 columns&lt;/p&gt;
&lt;/div&gt;

&lt;h1&gt;Plot for annual produce of different countries with quantity in y-axis and years in x-axis&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;area_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Area&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;year_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ar&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;area_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;yearly_produce&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;year_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;yearly_produce&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yr&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Area&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;ar&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yearly_produce&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;53&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;tuple&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;year_list&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;rotation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bbox_to_anchor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.02&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;102&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ncol&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;expand&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;borderaxespad&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;p.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_5_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Clearly, China, India and US stand out here. So, these are the countries with most food and feed production.&lt;/p&gt;
&lt;p&gt;Now, let's have a close look at their food and feed data&lt;/p&gt;
&lt;h1&gt;Food and feed plot for the whole dataset&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;factorplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_7_0.png"&gt;&lt;/p&gt;
&lt;p&gt;So, there is a huge difference in food and feed production. Now, we have obvious assumptions about the following plots after looking at this huge difference.&lt;/p&gt;
&lt;h1&gt;Food and feed plot for the largest producers(India, USA, China)&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;factorplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Area&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Area&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;India&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Area&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;China, mainland&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Area&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;United States of America&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hue&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aspect&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axisgrid&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FacetGrid&lt;/span&gt; &lt;span class="k"&gt;at&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x7fe39e56a5f8&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_9_1.png"&gt;&lt;/p&gt;
&lt;p&gt;Though, there is a huge difference between feed and food production, these countries' total production and their ranks depend on feed production.&lt;/p&gt;
&lt;p&gt;Now, we create a dataframe with countries as index and their annual produce as columns from 1961 to 2013.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;new_df_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ar&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;area_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;yearly_produce&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;year_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;yearly_produce&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yr&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Area&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;ar&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;new_df_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ar&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yearly_produce&lt;/span&gt;
&lt;span class="n"&gt;new_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_df_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Afghanistan&lt;/th&gt;
      &lt;th&gt;Albania&lt;/th&gt;
      &lt;th&gt;Algeria&lt;/th&gt;
      &lt;th&gt;Angola&lt;/th&gt;
      &lt;th&gt;Antigua and Barbuda&lt;/th&gt;
      &lt;th&gt;Argentina&lt;/th&gt;
      &lt;th&gt;Armenia&lt;/th&gt;
      &lt;th&gt;Australia&lt;/th&gt;
      &lt;th&gt;Austria&lt;/th&gt;
      &lt;th&gt;Azerbaijan&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;United Republic of Tanzania&lt;/th&gt;
      &lt;th&gt;United States of America&lt;/th&gt;
      &lt;th&gt;Uruguay&lt;/th&gt;
      &lt;th&gt;Uzbekistan&lt;/th&gt;
      &lt;th&gt;Vanuatu&lt;/th&gt;
      &lt;th&gt;Venezuela (Bolivarian Republic of)&lt;/th&gt;
      &lt;th&gt;Viet Nam&lt;/th&gt;
      &lt;th&gt;Yemen&lt;/th&gt;
      &lt;th&gt;Zambia&lt;/th&gt;
      &lt;th&gt;Zimbabwe&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;9481.0&lt;/td&gt;
      &lt;td&gt;1706.0&lt;/td&gt;
      &lt;td&gt;7488.0&lt;/td&gt;
      &lt;td&gt;4834.0&lt;/td&gt;
      &lt;td&gt;92.0&lt;/td&gt;
      &lt;td&gt;43402.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;25795.0&lt;/td&gt;
      &lt;td&gt;22542.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;12367.0&lt;/td&gt;
      &lt;td&gt;559347.0&lt;/td&gt;
      &lt;td&gt;4631.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;97.0&lt;/td&gt;
      &lt;td&gt;9523.0&lt;/td&gt;
      &lt;td&gt;23856.0&lt;/td&gt;
      &lt;td&gt;2982.0&lt;/td&gt;
      &lt;td&gt;2976.0&lt;/td&gt;
      &lt;td&gt;3260.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9414.0&lt;/td&gt;
      &lt;td&gt;1749.0&lt;/td&gt;
      &lt;td&gt;7235.0&lt;/td&gt;
      &lt;td&gt;4775.0&lt;/td&gt;
      &lt;td&gt;94.0&lt;/td&gt;
      &lt;td&gt;40784.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;27618.0&lt;/td&gt;
      &lt;td&gt;22627.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;12810.0&lt;/td&gt;
      &lt;td&gt;556319.0&lt;/td&gt;
      &lt;td&gt;4448.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;101.0&lt;/td&gt;
      &lt;td&gt;9369.0&lt;/td&gt;
      &lt;td&gt;25220.0&lt;/td&gt;
      &lt;td&gt;3038.0&lt;/td&gt;
      &lt;td&gt;3057.0&lt;/td&gt;
      &lt;td&gt;3503.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;9194.0&lt;/td&gt;
      &lt;td&gt;1767.0&lt;/td&gt;
      &lt;td&gt;6861.0&lt;/td&gt;
      &lt;td&gt;5240.0&lt;/td&gt;
      &lt;td&gt;105.0&lt;/td&gt;
      &lt;td&gt;40219.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;28902.0&lt;/td&gt;
      &lt;td&gt;23637.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;13109.0&lt;/td&gt;
      &lt;td&gt;552630.0&lt;/td&gt;
      &lt;td&gt;4682.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;103.0&lt;/td&gt;
      &lt;td&gt;9788.0&lt;/td&gt;
      &lt;td&gt;26053.0&lt;/td&gt;
      &lt;td&gt;3147.0&lt;/td&gt;
      &lt;td&gt;3069.0&lt;/td&gt;
      &lt;td&gt;3479.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;10170.0&lt;/td&gt;
      &lt;td&gt;1889.0&lt;/td&gt;
      &lt;td&gt;7255.0&lt;/td&gt;
      &lt;td&gt;5286.0&lt;/td&gt;
      &lt;td&gt;95.0&lt;/td&gt;
      &lt;td&gt;41638.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;29107.0&lt;/td&gt;
      &lt;td&gt;24099.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;12965.0&lt;/td&gt;
      &lt;td&gt;555677.0&lt;/td&gt;
      &lt;td&gt;4723.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;102.0&lt;/td&gt;
      &lt;td&gt;10539.0&lt;/td&gt;
      &lt;td&gt;26377.0&lt;/td&gt;
      &lt;td&gt;3224.0&lt;/td&gt;
      &lt;td&gt;3121.0&lt;/td&gt;
      &lt;td&gt;3738.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;10473.0&lt;/td&gt;
      &lt;td&gt;1884.0&lt;/td&gt;
      &lt;td&gt;7509.0&lt;/td&gt;
      &lt;td&gt;5527.0&lt;/td&gt;
      &lt;td&gt;84.0&lt;/td&gt;
      &lt;td&gt;44936.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;28961.0&lt;/td&gt;
      &lt;td&gt;22664.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;13742.0&lt;/td&gt;
      &lt;td&gt;589288.0&lt;/td&gt;
      &lt;td&gt;4581.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;107.0&lt;/td&gt;
      &lt;td&gt;10641.0&lt;/td&gt;
      &lt;td&gt;26961.0&lt;/td&gt;
      &lt;td&gt;3328.0&lt;/td&gt;
      &lt;td&gt;3236.0&lt;/td&gt;
      &lt;td&gt;3940.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 174 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Now, this is not perfect so we transpose this dataframe and add column names.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;new_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;year_list&lt;/span&gt;

&lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Y1961&lt;/th&gt;
      &lt;th&gt;Y1962&lt;/th&gt;
      &lt;th&gt;Y1963&lt;/th&gt;
      &lt;th&gt;Y1964&lt;/th&gt;
      &lt;th&gt;Y1965&lt;/th&gt;
      &lt;th&gt;Y1966&lt;/th&gt;
      &lt;th&gt;Y1967&lt;/th&gt;
      &lt;th&gt;Y1968&lt;/th&gt;
      &lt;th&gt;Y1969&lt;/th&gt;
      &lt;th&gt;Y1970&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;Y2004&lt;/th&gt;
      &lt;th&gt;Y2005&lt;/th&gt;
      &lt;th&gt;Y2006&lt;/th&gt;
      &lt;th&gt;Y2007&lt;/th&gt;
      &lt;th&gt;Y2008&lt;/th&gt;
      &lt;th&gt;Y2009&lt;/th&gt;
      &lt;th&gt;Y2010&lt;/th&gt;
      &lt;th&gt;Y2011&lt;/th&gt;
      &lt;th&gt;Y2012&lt;/th&gt;
      &lt;th&gt;Y2013&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;9481.0&lt;/td&gt;
      &lt;td&gt;9414.0&lt;/td&gt;
      &lt;td&gt;9194.0&lt;/td&gt;
      &lt;td&gt;10170.0&lt;/td&gt;
      &lt;td&gt;10473.0&lt;/td&gt;
      &lt;td&gt;10169.0&lt;/td&gt;
      &lt;td&gt;11289.0&lt;/td&gt;
      &lt;td&gt;11508.0&lt;/td&gt;
      &lt;td&gt;11815.0&lt;/td&gt;
      &lt;td&gt;10454.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;16542.0&lt;/td&gt;
      &lt;td&gt;17658.0&lt;/td&gt;
      &lt;td&gt;18317.0&lt;/td&gt;
      &lt;td&gt;19248.0&lt;/td&gt;
      &lt;td&gt;19381.0&lt;/td&gt;
      &lt;td&gt;20661.0&lt;/td&gt;
      &lt;td&gt;21030.0&lt;/td&gt;
      &lt;td&gt;21100.0&lt;/td&gt;
      &lt;td&gt;22706.0&lt;/td&gt;
      &lt;td&gt;23007.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;1706.0&lt;/td&gt;
      &lt;td&gt;1749.0&lt;/td&gt;
      &lt;td&gt;1767.0&lt;/td&gt;
      &lt;td&gt;1889.0&lt;/td&gt;
      &lt;td&gt;1884.0&lt;/td&gt;
      &lt;td&gt;1995.0&lt;/td&gt;
      &lt;td&gt;2046.0&lt;/td&gt;
      &lt;td&gt;2169.0&lt;/td&gt;
      &lt;td&gt;2230.0&lt;/td&gt;
      &lt;td&gt;2395.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;6637.0&lt;/td&gt;
      &lt;td&gt;6719.0&lt;/td&gt;
      &lt;td&gt;6911.0&lt;/td&gt;
      &lt;td&gt;6744.0&lt;/td&gt;
      &lt;td&gt;7168.0&lt;/td&gt;
      &lt;td&gt;7316.0&lt;/td&gt;
      &lt;td&gt;7907.0&lt;/td&gt;
      &lt;td&gt;8114.0&lt;/td&gt;
      &lt;td&gt;8221.0&lt;/td&gt;
      &lt;td&gt;8271.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;7488.0&lt;/td&gt;
      &lt;td&gt;7235.0&lt;/td&gt;
      &lt;td&gt;6861.0&lt;/td&gt;
      &lt;td&gt;7255.0&lt;/td&gt;
      &lt;td&gt;7509.0&lt;/td&gt;
      &lt;td&gt;7536.0&lt;/td&gt;
      &lt;td&gt;7986.0&lt;/td&gt;
      &lt;td&gt;8839.0&lt;/td&gt;
      &lt;td&gt;9003.0&lt;/td&gt;
      &lt;td&gt;9355.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;48619.0&lt;/td&gt;
      &lt;td&gt;49562.0&lt;/td&gt;
      &lt;td&gt;51067.0&lt;/td&gt;
      &lt;td&gt;49933.0&lt;/td&gt;
      &lt;td&gt;50916.0&lt;/td&gt;
      &lt;td&gt;57505.0&lt;/td&gt;
      &lt;td&gt;60071.0&lt;/td&gt;
      &lt;td&gt;65852.0&lt;/td&gt;
      &lt;td&gt;69365.0&lt;/td&gt;
      &lt;td&gt;72161.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Angola&lt;/td&gt;
      &lt;td&gt;4834.0&lt;/td&gt;
      &lt;td&gt;4775.0&lt;/td&gt;
      &lt;td&gt;5240.0&lt;/td&gt;
      &lt;td&gt;5286.0&lt;/td&gt;
      &lt;td&gt;5527.0&lt;/td&gt;
      &lt;td&gt;5677.0&lt;/td&gt;
      &lt;td&gt;5833.0&lt;/td&gt;
      &lt;td&gt;5685.0&lt;/td&gt;
      &lt;td&gt;6219.0&lt;/td&gt;
      &lt;td&gt;6460.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;25541.0&lt;/td&gt;
      &lt;td&gt;26696.0&lt;/td&gt;
      &lt;td&gt;28247.0&lt;/td&gt;
      &lt;td&gt;29877.0&lt;/td&gt;
      &lt;td&gt;32053.0&lt;/td&gt;
      &lt;td&gt;36985.0&lt;/td&gt;
      &lt;td&gt;38400.0&lt;/td&gt;
      &lt;td&gt;40573.0&lt;/td&gt;
      &lt;td&gt;38064.0&lt;/td&gt;
      &lt;td&gt;48639.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Antigua and Barbuda&lt;/td&gt;
      &lt;td&gt;92.0&lt;/td&gt;
      &lt;td&gt;94.0&lt;/td&gt;
      &lt;td&gt;105.0&lt;/td&gt;
      &lt;td&gt;95.0&lt;/td&gt;
      &lt;td&gt;84.0&lt;/td&gt;
      &lt;td&gt;73.0&lt;/td&gt;
      &lt;td&gt;64.0&lt;/td&gt;
      &lt;td&gt;59.0&lt;/td&gt;
      &lt;td&gt;68.0&lt;/td&gt;
      &lt;td&gt;77.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;92.0&lt;/td&gt;
      &lt;td&gt;115.0&lt;/td&gt;
      &lt;td&gt;110.0&lt;/td&gt;
      &lt;td&gt;122.0&lt;/td&gt;
      &lt;td&gt;115.0&lt;/td&gt;
      &lt;td&gt;114.0&lt;/td&gt;
      &lt;td&gt;115.0&lt;/td&gt;
      &lt;td&gt;118.0&lt;/td&gt;
      &lt;td&gt;113.0&lt;/td&gt;
      &lt;td&gt;119.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 53 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Perfect! Now, we will do some feature engineering.&lt;/p&gt;
&lt;h1&gt;First, a new column which indicates mean produce of each state over the given years. Second, a ranking column which ranks countries on the basis of mean produce.&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;mean_produce&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;174&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;mean_produce&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Mean_Produce&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mean_produce&lt;/span&gt;

&lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Rank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Mean_Produce&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rank&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ascending&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Y1961&lt;/th&gt;
      &lt;th&gt;Y1962&lt;/th&gt;
      &lt;th&gt;Y1963&lt;/th&gt;
      &lt;th&gt;Y1964&lt;/th&gt;
      &lt;th&gt;Y1965&lt;/th&gt;
      &lt;th&gt;Y1966&lt;/th&gt;
      &lt;th&gt;Y1967&lt;/th&gt;
      &lt;th&gt;Y1968&lt;/th&gt;
      &lt;th&gt;Y1969&lt;/th&gt;
      &lt;th&gt;Y1970&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;Y2006&lt;/th&gt;
      &lt;th&gt;Y2007&lt;/th&gt;
      &lt;th&gt;Y2008&lt;/th&gt;
      &lt;th&gt;Y2009&lt;/th&gt;
      &lt;th&gt;Y2010&lt;/th&gt;
      &lt;th&gt;Y2011&lt;/th&gt;
      &lt;th&gt;Y2012&lt;/th&gt;
      &lt;th&gt;Y2013&lt;/th&gt;
      &lt;th&gt;Mean_Produce&lt;/th&gt;
      &lt;th&gt;Rank&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;9481.0&lt;/td&gt;
      &lt;td&gt;9414.0&lt;/td&gt;
      &lt;td&gt;9194.0&lt;/td&gt;
      &lt;td&gt;10170.0&lt;/td&gt;
      &lt;td&gt;10473.0&lt;/td&gt;
      &lt;td&gt;10169.0&lt;/td&gt;
      &lt;td&gt;11289.0&lt;/td&gt;
      &lt;td&gt;11508.0&lt;/td&gt;
      &lt;td&gt;11815.0&lt;/td&gt;
      &lt;td&gt;10454.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;18317.0&lt;/td&gt;
      &lt;td&gt;19248.0&lt;/td&gt;
      &lt;td&gt;19381.0&lt;/td&gt;
      &lt;td&gt;20661.0&lt;/td&gt;
      &lt;td&gt;21030.0&lt;/td&gt;
      &lt;td&gt;21100.0&lt;/td&gt;
      &lt;td&gt;22706.0&lt;/td&gt;
      &lt;td&gt;23007.0&lt;/td&gt;
      &lt;td&gt;13003.056604&lt;/td&gt;
      &lt;td&gt;69.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;1706.0&lt;/td&gt;
      &lt;td&gt;1749.0&lt;/td&gt;
      &lt;td&gt;1767.0&lt;/td&gt;
      &lt;td&gt;1889.0&lt;/td&gt;
      &lt;td&gt;1884.0&lt;/td&gt;
      &lt;td&gt;1995.0&lt;/td&gt;
      &lt;td&gt;2046.0&lt;/td&gt;
      &lt;td&gt;2169.0&lt;/td&gt;
      &lt;td&gt;2230.0&lt;/td&gt;
      &lt;td&gt;2395.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;6911.0&lt;/td&gt;
      &lt;td&gt;6744.0&lt;/td&gt;
      &lt;td&gt;7168.0&lt;/td&gt;
      &lt;td&gt;7316.0&lt;/td&gt;
      &lt;td&gt;7907.0&lt;/td&gt;
      &lt;td&gt;8114.0&lt;/td&gt;
      &lt;td&gt;8221.0&lt;/td&gt;
      &lt;td&gt;8271.0&lt;/td&gt;
      &lt;td&gt;4475.509434&lt;/td&gt;
      &lt;td&gt;104.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;7488.0&lt;/td&gt;
      &lt;td&gt;7235.0&lt;/td&gt;
      &lt;td&gt;6861.0&lt;/td&gt;
      &lt;td&gt;7255.0&lt;/td&gt;
      &lt;td&gt;7509.0&lt;/td&gt;
      &lt;td&gt;7536.0&lt;/td&gt;
      &lt;td&gt;7986.0&lt;/td&gt;
      &lt;td&gt;8839.0&lt;/td&gt;
      &lt;td&gt;9003.0&lt;/td&gt;
      &lt;td&gt;9355.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;51067.0&lt;/td&gt;
      &lt;td&gt;49933.0&lt;/td&gt;
      &lt;td&gt;50916.0&lt;/td&gt;
      &lt;td&gt;57505.0&lt;/td&gt;
      &lt;td&gt;60071.0&lt;/td&gt;
      &lt;td&gt;65852.0&lt;/td&gt;
      &lt;td&gt;69365.0&lt;/td&gt;
      &lt;td&gt;72161.0&lt;/td&gt;
      &lt;td&gt;28879.490566&lt;/td&gt;
      &lt;td&gt;38.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Angola&lt;/td&gt;
      &lt;td&gt;4834.0&lt;/td&gt;
      &lt;td&gt;4775.0&lt;/td&gt;
      &lt;td&gt;5240.0&lt;/td&gt;
      &lt;td&gt;5286.0&lt;/td&gt;
      &lt;td&gt;5527.0&lt;/td&gt;
      &lt;td&gt;5677.0&lt;/td&gt;
      &lt;td&gt;5833.0&lt;/td&gt;
      &lt;td&gt;5685.0&lt;/td&gt;
      &lt;td&gt;6219.0&lt;/td&gt;
      &lt;td&gt;6460.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;28247.0&lt;/td&gt;
      &lt;td&gt;29877.0&lt;/td&gt;
      &lt;td&gt;32053.0&lt;/td&gt;
      &lt;td&gt;36985.0&lt;/td&gt;
      &lt;td&gt;38400.0&lt;/td&gt;
      &lt;td&gt;40573.0&lt;/td&gt;
      &lt;td&gt;38064.0&lt;/td&gt;
      &lt;td&gt;48639.0&lt;/td&gt;
      &lt;td&gt;13321.056604&lt;/td&gt;
      &lt;td&gt;68.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Antigua and Barbuda&lt;/td&gt;
      &lt;td&gt;92.0&lt;/td&gt;
      &lt;td&gt;94.0&lt;/td&gt;
      &lt;td&gt;105.0&lt;/td&gt;
      &lt;td&gt;95.0&lt;/td&gt;
      &lt;td&gt;84.0&lt;/td&gt;
      &lt;td&gt;73.0&lt;/td&gt;
      &lt;td&gt;64.0&lt;/td&gt;
      &lt;td&gt;59.0&lt;/td&gt;
      &lt;td&gt;68.0&lt;/td&gt;
      &lt;td&gt;77.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;110.0&lt;/td&gt;
      &lt;td&gt;122.0&lt;/td&gt;
      &lt;td&gt;115.0&lt;/td&gt;
      &lt;td&gt;114.0&lt;/td&gt;
      &lt;td&gt;115.0&lt;/td&gt;
      &lt;td&gt;118.0&lt;/td&gt;
      &lt;td&gt;113.0&lt;/td&gt;
      &lt;td&gt;119.0&lt;/td&gt;
      &lt;td&gt;83.886792&lt;/td&gt;
      &lt;td&gt;172.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 55 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Now, we create another dataframe with items and their total production each year from 1961 to 2013&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;item_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="n"&gt;item_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item_Name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;item_list&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;yr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;year_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;item_produce&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;item_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;item_produce&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yr&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yr&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;item_produce&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Item_Name&lt;/th&gt;
      &lt;th&gt;Y1961&lt;/th&gt;
      &lt;th&gt;Y1962&lt;/th&gt;
      &lt;th&gt;Y1963&lt;/th&gt;
      &lt;th&gt;Y1964&lt;/th&gt;
      &lt;th&gt;Y1965&lt;/th&gt;
      &lt;th&gt;Y1966&lt;/th&gt;
      &lt;th&gt;Y1967&lt;/th&gt;
      &lt;th&gt;Y1968&lt;/th&gt;
      &lt;th&gt;Y1969&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;Y2004&lt;/th&gt;
      &lt;th&gt;Y2005&lt;/th&gt;
      &lt;th&gt;Y2006&lt;/th&gt;
      &lt;th&gt;Y2007&lt;/th&gt;
      &lt;th&gt;Y2008&lt;/th&gt;
      &lt;th&gt;Y2009&lt;/th&gt;
      &lt;th&gt;Y2010&lt;/th&gt;
      &lt;th&gt;Y2011&lt;/th&gt;
      &lt;th&gt;Y2012&lt;/th&gt;
      &lt;th&gt;Y2013&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Wheat and products&lt;/td&gt;
      &lt;td&gt;138829.0&lt;/td&gt;
      &lt;td&gt;144643.0&lt;/td&gt;
      &lt;td&gt;147325.0&lt;/td&gt;
      &lt;td&gt;156273.0&lt;/td&gt;
      &lt;td&gt;168822.0&lt;/td&gt;
      &lt;td&gt;169832.0&lt;/td&gt;
      &lt;td&gt;171469.0&lt;/td&gt;
      &lt;td&gt;179530.0&lt;/td&gt;
      &lt;td&gt;189658.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;527394.0&lt;/td&gt;
      &lt;td&gt;532263.0&lt;/td&gt;
      &lt;td&gt;537279.0&lt;/td&gt;
      &lt;td&gt;529271.0&lt;/td&gt;
      &lt;td&gt;562239.0&lt;/td&gt;
      &lt;td&gt;557245.0&lt;/td&gt;
      &lt;td&gt;549926.0&lt;/td&gt;
      &lt;td&gt;578179.0&lt;/td&gt;
      &lt;td&gt;576597&lt;/td&gt;
      &lt;td&gt;587492&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Rice (Milled Equivalent)&lt;/td&gt;
      &lt;td&gt;122700.0&lt;/td&gt;
      &lt;td&gt;131842.0&lt;/td&gt;
      &lt;td&gt;139507.0&lt;/td&gt;
      &lt;td&gt;148304.0&lt;/td&gt;
      &lt;td&gt;150056.0&lt;/td&gt;
      &lt;td&gt;155583.0&lt;/td&gt;
      &lt;td&gt;158587.0&lt;/td&gt;
      &lt;td&gt;164614.0&lt;/td&gt;
      &lt;td&gt;167922.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;361107.0&lt;/td&gt;
      &lt;td&gt;366025.0&lt;/td&gt;
      &lt;td&gt;372629.0&lt;/td&gt;
      &lt;td&gt;378698.0&lt;/td&gt;
      &lt;td&gt;389708.0&lt;/td&gt;
      &lt;td&gt;394221.0&lt;/td&gt;
      &lt;td&gt;398559.0&lt;/td&gt;
      &lt;td&gt;404152.0&lt;/td&gt;
      &lt;td&gt;406787&lt;/td&gt;
      &lt;td&gt;410880&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Barley and products&lt;/td&gt;
      &lt;td&gt;46180.0&lt;/td&gt;
      &lt;td&gt;48915.0&lt;/td&gt;
      &lt;td&gt;51642.0&lt;/td&gt;
      &lt;td&gt;54184.0&lt;/td&gt;
      &lt;td&gt;54945.0&lt;/td&gt;
      &lt;td&gt;55463.0&lt;/td&gt;
      &lt;td&gt;56424.0&lt;/td&gt;
      &lt;td&gt;60455.0&lt;/td&gt;
      &lt;td&gt;65501.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;102055.0&lt;/td&gt;
      &lt;td&gt;97185.0&lt;/td&gt;
      &lt;td&gt;100981.0&lt;/td&gt;
      &lt;td&gt;93310.0&lt;/td&gt;
      &lt;td&gt;98209.0&lt;/td&gt;
      &lt;td&gt;99135.0&lt;/td&gt;
      &lt;td&gt;92563.0&lt;/td&gt;
      &lt;td&gt;92570.0&lt;/td&gt;
      &lt;td&gt;88766&lt;/td&gt;
      &lt;td&gt;99452&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Maize and products&lt;/td&gt;
      &lt;td&gt;168039.0&lt;/td&gt;
      &lt;td&gt;168305.0&lt;/td&gt;
      &lt;td&gt;172905.0&lt;/td&gt;
      &lt;td&gt;175468.0&lt;/td&gt;
      &lt;td&gt;190304.0&lt;/td&gt;
      &lt;td&gt;200860.0&lt;/td&gt;
      &lt;td&gt;213050.0&lt;/td&gt;
      &lt;td&gt;215613.0&lt;/td&gt;
      &lt;td&gt;221953.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;545024.0&lt;/td&gt;
      &lt;td&gt;549036.0&lt;/td&gt;
      &lt;td&gt;543280.0&lt;/td&gt;
      &lt;td&gt;573892.0&lt;/td&gt;
      &lt;td&gt;592231.0&lt;/td&gt;
      &lt;td&gt;557940.0&lt;/td&gt;
      &lt;td&gt;584337.0&lt;/td&gt;
      &lt;td&gt;603297.0&lt;/td&gt;
      &lt;td&gt;608730&lt;/td&gt;
      &lt;td&gt;671300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Millet and products&lt;/td&gt;
      &lt;td&gt;19075.0&lt;/td&gt;
      &lt;td&gt;19019.0&lt;/td&gt;
      &lt;td&gt;19740.0&lt;/td&gt;
      &lt;td&gt;20353.0&lt;/td&gt;
      &lt;td&gt;18377.0&lt;/td&gt;
      &lt;td&gt;20860.0&lt;/td&gt;
      &lt;td&gt;22997.0&lt;/td&gt;
      &lt;td&gt;21785.0&lt;/td&gt;
      &lt;td&gt;23966.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;25789.0&lt;/td&gt;
      &lt;td&gt;25496.0&lt;/td&gt;
      &lt;td&gt;25997.0&lt;/td&gt;
      &lt;td&gt;26750.0&lt;/td&gt;
      &lt;td&gt;26373.0&lt;/td&gt;
      &lt;td&gt;24575.0&lt;/td&gt;
      &lt;td&gt;27039.0&lt;/td&gt;
      &lt;td&gt;25740.0&lt;/td&gt;
      &lt;td&gt;26105&lt;/td&gt;
      &lt;td&gt;26346&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 54 columns&lt;/p&gt;
&lt;/div&gt;

&lt;h1&gt;Some more feature engineering&lt;/h1&gt;
&lt;p&gt;This time, we will use the new features to get some good conclusions.&lt;/p&gt;
&lt;h1&gt;1. Total amount of item produced from 1961 to 2013&lt;/h1&gt;
&lt;h1&gt;2. Providing a rank to the items to know the most produced item&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sum_col&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;115&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;sum_col&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Sum&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sum_col&lt;/span&gt;
&lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Production_Rank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Sum&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rank&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ascending&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Item_Name&lt;/th&gt;
      &lt;th&gt;Y1961&lt;/th&gt;
      &lt;th&gt;Y1962&lt;/th&gt;
      &lt;th&gt;Y1963&lt;/th&gt;
      &lt;th&gt;Y1964&lt;/th&gt;
      &lt;th&gt;Y1965&lt;/th&gt;
      &lt;th&gt;Y1966&lt;/th&gt;
      &lt;th&gt;Y1967&lt;/th&gt;
      &lt;th&gt;Y1968&lt;/th&gt;
      &lt;th&gt;Y1969&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;Y2006&lt;/th&gt;
      &lt;th&gt;Y2007&lt;/th&gt;
      &lt;th&gt;Y2008&lt;/th&gt;
      &lt;th&gt;Y2009&lt;/th&gt;
      &lt;th&gt;Y2010&lt;/th&gt;
      &lt;th&gt;Y2011&lt;/th&gt;
      &lt;th&gt;Y2012&lt;/th&gt;
      &lt;th&gt;Y2013&lt;/th&gt;
      &lt;th&gt;Sum&lt;/th&gt;
      &lt;th&gt;Production_Rank&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Wheat and products&lt;/td&gt;
      &lt;td&gt;138829.0&lt;/td&gt;
      &lt;td&gt;144643.0&lt;/td&gt;
      &lt;td&gt;147325.0&lt;/td&gt;
      &lt;td&gt;156273.0&lt;/td&gt;
      &lt;td&gt;168822.0&lt;/td&gt;
      &lt;td&gt;169832.0&lt;/td&gt;
      &lt;td&gt;171469.0&lt;/td&gt;
      &lt;td&gt;179530.0&lt;/td&gt;
      &lt;td&gt;189658.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;537279.0&lt;/td&gt;
      &lt;td&gt;529271.0&lt;/td&gt;
      &lt;td&gt;562239.0&lt;/td&gt;
      &lt;td&gt;557245.0&lt;/td&gt;
      &lt;td&gt;549926.0&lt;/td&gt;
      &lt;td&gt;578179.0&lt;/td&gt;
      &lt;td&gt;576597&lt;/td&gt;
      &lt;td&gt;587492&lt;/td&gt;
      &lt;td&gt;19194671.0&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Rice (Milled Equivalent)&lt;/td&gt;
      &lt;td&gt;122700.0&lt;/td&gt;
      &lt;td&gt;131842.0&lt;/td&gt;
      &lt;td&gt;139507.0&lt;/td&gt;
      &lt;td&gt;148304.0&lt;/td&gt;
      &lt;td&gt;150056.0&lt;/td&gt;
      &lt;td&gt;155583.0&lt;/td&gt;
      &lt;td&gt;158587.0&lt;/td&gt;
      &lt;td&gt;164614.0&lt;/td&gt;
      &lt;td&gt;167922.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;372629.0&lt;/td&gt;
      &lt;td&gt;378698.0&lt;/td&gt;
      &lt;td&gt;389708.0&lt;/td&gt;
      &lt;td&gt;394221.0&lt;/td&gt;
      &lt;td&gt;398559.0&lt;/td&gt;
      &lt;td&gt;404152.0&lt;/td&gt;
      &lt;td&gt;406787&lt;/td&gt;
      &lt;td&gt;410880&lt;/td&gt;
      &lt;td&gt;14475448.0&lt;/td&gt;
      &lt;td&gt;8.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Barley and products&lt;/td&gt;
      &lt;td&gt;46180.0&lt;/td&gt;
      &lt;td&gt;48915.0&lt;/td&gt;
      &lt;td&gt;51642.0&lt;/td&gt;
      &lt;td&gt;54184.0&lt;/td&gt;
      &lt;td&gt;54945.0&lt;/td&gt;
      &lt;td&gt;55463.0&lt;/td&gt;
      &lt;td&gt;56424.0&lt;/td&gt;
      &lt;td&gt;60455.0&lt;/td&gt;
      &lt;td&gt;65501.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;100981.0&lt;/td&gt;
      &lt;td&gt;93310.0&lt;/td&gt;
      &lt;td&gt;98209.0&lt;/td&gt;
      &lt;td&gt;99135.0&lt;/td&gt;
      &lt;td&gt;92563.0&lt;/td&gt;
      &lt;td&gt;92570.0&lt;/td&gt;
      &lt;td&gt;88766&lt;/td&gt;
      &lt;td&gt;99452&lt;/td&gt;
      &lt;td&gt;4442742.0&lt;/td&gt;
      &lt;td&gt;20.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Maize and products&lt;/td&gt;
      &lt;td&gt;168039.0&lt;/td&gt;
      &lt;td&gt;168305.0&lt;/td&gt;
      &lt;td&gt;172905.0&lt;/td&gt;
      &lt;td&gt;175468.0&lt;/td&gt;
      &lt;td&gt;190304.0&lt;/td&gt;
      &lt;td&gt;200860.0&lt;/td&gt;
      &lt;td&gt;213050.0&lt;/td&gt;
      &lt;td&gt;215613.0&lt;/td&gt;
      &lt;td&gt;221953.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;543280.0&lt;/td&gt;
      &lt;td&gt;573892.0&lt;/td&gt;
      &lt;td&gt;592231.0&lt;/td&gt;
      &lt;td&gt;557940.0&lt;/td&gt;
      &lt;td&gt;584337.0&lt;/td&gt;
      &lt;td&gt;603297.0&lt;/td&gt;
      &lt;td&gt;608730&lt;/td&gt;
      &lt;td&gt;671300&lt;/td&gt;
      &lt;td&gt;19960640.0&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Millet and products&lt;/td&gt;
      &lt;td&gt;19075.0&lt;/td&gt;
      &lt;td&gt;19019.0&lt;/td&gt;
      &lt;td&gt;19740.0&lt;/td&gt;
      &lt;td&gt;20353.0&lt;/td&gt;
      &lt;td&gt;18377.0&lt;/td&gt;
      &lt;td&gt;20860.0&lt;/td&gt;
      &lt;td&gt;22997.0&lt;/td&gt;
      &lt;td&gt;21785.0&lt;/td&gt;
      &lt;td&gt;23966.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;25997.0&lt;/td&gt;
      &lt;td&gt;26750.0&lt;/td&gt;
      &lt;td&gt;26373.0&lt;/td&gt;
      &lt;td&gt;24575.0&lt;/td&gt;
      &lt;td&gt;27039.0&lt;/td&gt;
      &lt;td&gt;25740.0&lt;/td&gt;
      &lt;td&gt;26105&lt;/td&gt;
      &lt;td&gt;26346&lt;/td&gt;
      &lt;td&gt;1225400.0&lt;/td&gt;
      &lt;td&gt;38.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 56 columns&lt;/p&gt;
&lt;/div&gt;

&lt;h1&gt;Now, we find the most produced food items in the last half-century&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item_Name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Production_Rank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;11.0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_values&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;56&lt;/span&gt;    &lt;span class="n"&gt;Cereals&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="k"&gt;Excluding&lt;/span&gt; &lt;span class="n"&gt;Beer&lt;/span&gt;
&lt;span class="mi"&gt;65&lt;/span&gt;     &lt;span class="n"&gt;Fruits&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="k"&gt;Excluding&lt;/span&gt; &lt;span class="n"&gt;Wine&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;           &lt;span class="n"&gt;Maize&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;products&lt;/span&gt;
&lt;span class="mi"&gt;53&lt;/span&gt;     &lt;span class="n"&gt;Milk&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="k"&gt;Excluding&lt;/span&gt; &lt;span class="n"&gt;Butter&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;        &lt;span class="n"&gt;Potatoes&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;products&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;     &lt;span class="n"&gt;Rice&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Milled&lt;/span&gt; &lt;span class="n"&gt;Equivalent&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;57&lt;/span&gt;               &lt;span class="n"&gt;Starchy&lt;/span&gt; &lt;span class="n"&gt;Roots&lt;/span&gt;
&lt;span class="mi"&gt;64&lt;/span&gt;                  &lt;span class="n"&gt;Vegetables&lt;/span&gt;
&lt;span class="mi"&gt;27&lt;/span&gt;           &lt;span class="n"&gt;Vegetables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Other&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt;           &lt;span class="n"&gt;Wheat&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;products&lt;/span&gt;
&lt;span class="n"&gt;Name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Item_Name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;object&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So, cereals, fruits and maize are the most produced items in the last 50 years&lt;/p&gt;
&lt;h1&gt;Food and feed plot for most produced items&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;factorplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Item&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Wheat and products&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Rice (Milled Equivalent)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Maize and products&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Potatoes and products&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Vegetables, Other&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Milk - Excluding Butter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Cereals - Excluding Beer&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Starchy Roots&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Vegetables&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Item&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Fruits - Excluding Wine&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hue&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Element&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aspect&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_25_0.png"&gt;&lt;/p&gt;
&lt;h1&gt;Now, we plot a heatmap of correlation of produce in difference years&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;year_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;heatmap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;year_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_subplots&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AxesSubplot&lt;/span&gt; &lt;span class="k"&gt;at&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x7fe3a58530b8&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_27_1.png"&gt;&lt;/p&gt;
&lt;p&gt;So, we gather that a given year's production is more similar to its immediate previous and immediate following years.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;col&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;row&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Y1968&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Y1961&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Y1968&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Y1963&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Y1968&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Y1986&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax4&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Y1968&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Y2013&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jointplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y1968&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y1961&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;reg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jointplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y1968&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y1963&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;reg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jointplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y1968&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y1986&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;reg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jointplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y1968&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y2013&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;reg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_29_0.png"&gt;&lt;/p&gt;
&lt;h1&gt;Heatmap of production of food items over years&lt;/h1&gt;
&lt;p&gt;This will detect the items whose production has drastically increased over the years&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;new_item_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Item_Name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Sum&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Production_Rank&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;heatmap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_item_df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_yticklabels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Item_Name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_31_00.png"&gt;&lt;/p&gt;
&lt;p&gt;There is considerable growth in production of Palmkernel oil, Meat/Aquatic animals, ricebran oil, cottonseed, seafood, offals, roots, poultry meat, mutton, bear, cocoa, coffee and soyabean oil.
There has been exceptional growth in production of onions, cream, sugar crops, treenuts, butter/ghee and to some extent starchy roots.&lt;/p&gt;
&lt;p&gt;Now, we look at clustering.&lt;/p&gt;
&lt;h1&gt;What is clustering?&lt;/h1&gt;
&lt;p&gt;Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). It is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, bioinformatics, data compression, and computer graphics.&lt;/p&gt;
&lt;h1&gt;Today, we will form clusters to classify countries based on productivity scale&lt;/h1&gt;
&lt;p&gt;For this, we will use k-means clustering algorithm.&lt;/p&gt;
&lt;h1&gt;K-means clustering&lt;/h1&gt;
&lt;p&gt;(Source &lt;a href="https://en.wikipedia.org/wiki/K-means_clustering#Standard_algorithm"&gt;Wikipedia&lt;/a&gt; )
&lt;img alt="http://gdurl.com/5BbP" src="http://gdurl.com/5BbP"&gt;&lt;/p&gt;
&lt;p&gt;This is the data we will use.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Y1961&lt;/th&gt;
      &lt;th&gt;Y1962&lt;/th&gt;
      &lt;th&gt;Y1963&lt;/th&gt;
      &lt;th&gt;Y1964&lt;/th&gt;
      &lt;th&gt;Y1965&lt;/th&gt;
      &lt;th&gt;Y1966&lt;/th&gt;
      &lt;th&gt;Y1967&lt;/th&gt;
      &lt;th&gt;Y1968&lt;/th&gt;
      &lt;th&gt;Y1969&lt;/th&gt;
      &lt;th&gt;Y1970&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;Y2006&lt;/th&gt;
      &lt;th&gt;Y2007&lt;/th&gt;
      &lt;th&gt;Y2008&lt;/th&gt;
      &lt;th&gt;Y2009&lt;/th&gt;
      &lt;th&gt;Y2010&lt;/th&gt;
      &lt;th&gt;Y2011&lt;/th&gt;
      &lt;th&gt;Y2012&lt;/th&gt;
      &lt;th&gt;Y2013&lt;/th&gt;
      &lt;th&gt;Mean_Produce&lt;/th&gt;
      &lt;th&gt;Rank&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;9481.0&lt;/td&gt;
      &lt;td&gt;9414.0&lt;/td&gt;
      &lt;td&gt;9194.0&lt;/td&gt;
      &lt;td&gt;10170.0&lt;/td&gt;
      &lt;td&gt;10473.0&lt;/td&gt;
      &lt;td&gt;10169.0&lt;/td&gt;
      &lt;td&gt;11289.0&lt;/td&gt;
      &lt;td&gt;11508.0&lt;/td&gt;
      &lt;td&gt;11815.0&lt;/td&gt;
      &lt;td&gt;10454.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;18317.0&lt;/td&gt;
      &lt;td&gt;19248.0&lt;/td&gt;
      &lt;td&gt;19381.0&lt;/td&gt;
      &lt;td&gt;20661.0&lt;/td&gt;
      &lt;td&gt;21030.0&lt;/td&gt;
      &lt;td&gt;21100.0&lt;/td&gt;
      &lt;td&gt;22706.0&lt;/td&gt;
      &lt;td&gt;23007.0&lt;/td&gt;
      &lt;td&gt;13003.056604&lt;/td&gt;
      &lt;td&gt;69.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;1706.0&lt;/td&gt;
      &lt;td&gt;1749.0&lt;/td&gt;
      &lt;td&gt;1767.0&lt;/td&gt;
      &lt;td&gt;1889.0&lt;/td&gt;
      &lt;td&gt;1884.0&lt;/td&gt;
      &lt;td&gt;1995.0&lt;/td&gt;
      &lt;td&gt;2046.0&lt;/td&gt;
      &lt;td&gt;2169.0&lt;/td&gt;
      &lt;td&gt;2230.0&lt;/td&gt;
      &lt;td&gt;2395.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;6911.0&lt;/td&gt;
      &lt;td&gt;6744.0&lt;/td&gt;
      &lt;td&gt;7168.0&lt;/td&gt;
      &lt;td&gt;7316.0&lt;/td&gt;
      &lt;td&gt;7907.0&lt;/td&gt;
      &lt;td&gt;8114.0&lt;/td&gt;
      &lt;td&gt;8221.0&lt;/td&gt;
      &lt;td&gt;8271.0&lt;/td&gt;
      &lt;td&gt;4475.509434&lt;/td&gt;
      &lt;td&gt;104.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;7488.0&lt;/td&gt;
      &lt;td&gt;7235.0&lt;/td&gt;
      &lt;td&gt;6861.0&lt;/td&gt;
      &lt;td&gt;7255.0&lt;/td&gt;
      &lt;td&gt;7509.0&lt;/td&gt;
      &lt;td&gt;7536.0&lt;/td&gt;
      &lt;td&gt;7986.0&lt;/td&gt;
      &lt;td&gt;8839.0&lt;/td&gt;
      &lt;td&gt;9003.0&lt;/td&gt;
      &lt;td&gt;9355.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;51067.0&lt;/td&gt;
      &lt;td&gt;49933.0&lt;/td&gt;
      &lt;td&gt;50916.0&lt;/td&gt;
      &lt;td&gt;57505.0&lt;/td&gt;
      &lt;td&gt;60071.0&lt;/td&gt;
      &lt;td&gt;65852.0&lt;/td&gt;
      &lt;td&gt;69365.0&lt;/td&gt;
      &lt;td&gt;72161.0&lt;/td&gt;
      &lt;td&gt;28879.490566&lt;/td&gt;
      &lt;td&gt;38.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Angola&lt;/td&gt;
      &lt;td&gt;4834.0&lt;/td&gt;
      &lt;td&gt;4775.0&lt;/td&gt;
      &lt;td&gt;5240.0&lt;/td&gt;
      &lt;td&gt;5286.0&lt;/td&gt;
      &lt;td&gt;5527.0&lt;/td&gt;
      &lt;td&gt;5677.0&lt;/td&gt;
      &lt;td&gt;5833.0&lt;/td&gt;
      &lt;td&gt;5685.0&lt;/td&gt;
      &lt;td&gt;6219.0&lt;/td&gt;
      &lt;td&gt;6460.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;28247.0&lt;/td&gt;
      &lt;td&gt;29877.0&lt;/td&gt;
      &lt;td&gt;32053.0&lt;/td&gt;
      &lt;td&gt;36985.0&lt;/td&gt;
      &lt;td&gt;38400.0&lt;/td&gt;
      &lt;td&gt;40573.0&lt;/td&gt;
      &lt;td&gt;38064.0&lt;/td&gt;
      &lt;td&gt;48639.0&lt;/td&gt;
      &lt;td&gt;13321.056604&lt;/td&gt;
      &lt;td&gt;68.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Antigua and Barbuda&lt;/td&gt;
      &lt;td&gt;92.0&lt;/td&gt;
      &lt;td&gt;94.0&lt;/td&gt;
      &lt;td&gt;105.0&lt;/td&gt;
      &lt;td&gt;95.0&lt;/td&gt;
      &lt;td&gt;84.0&lt;/td&gt;
      &lt;td&gt;73.0&lt;/td&gt;
      &lt;td&gt;64.0&lt;/td&gt;
      &lt;td&gt;59.0&lt;/td&gt;
      &lt;td&gt;68.0&lt;/td&gt;
      &lt;td&gt;77.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;110.0&lt;/td&gt;
      &lt;td&gt;122.0&lt;/td&gt;
      &lt;td&gt;115.0&lt;/td&gt;
      &lt;td&gt;114.0&lt;/td&gt;
      &lt;td&gt;115.0&lt;/td&gt;
      &lt;td&gt;118.0&lt;/td&gt;
      &lt;td&gt;113.0&lt;/td&gt;
      &lt;td&gt;119.0&lt;/td&gt;
      &lt;td&gt;83.886792&lt;/td&gt;
      &lt;td&gt;172.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 55 columns&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert_objects&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;convert_numeric&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;year_list&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;---------------------------------------------------------------------------&lt;/span&gt;

&lt;span class="nv"&gt;AttributeError&lt;/span&gt;                            &lt;span class="nv"&gt;Traceback&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;most&lt;/span&gt; &lt;span class="nv"&gt;recent&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="nl"&gt;last&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nv"&gt;ipython&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;input&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ebc6771564a7&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nv"&gt;module&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="mi"&gt;2&lt;/span&gt; 
      &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="nv"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;DataFrame&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;X&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;----&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="nv"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;X&lt;/span&gt;.&lt;span class="nv"&gt;convert_objects&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;convert_numeric&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;True&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
      &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="nv"&gt;X&lt;/span&gt;.&lt;span class="nv"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;year_list&lt;/span&gt;


&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;opt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;conda&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;python3&lt;/span&gt;.&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;site&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;core&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;generic&lt;/span&gt;.&lt;span class="nv"&gt;py&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;__getattr__&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;self&lt;/span&gt;, &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
   &lt;span class="mi"&gt;5177&lt;/span&gt;             &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;self&lt;/span&gt;.&lt;span class="nv"&gt;_info_axis&lt;/span&gt;.&lt;span class="nv"&gt;_can_hold_identifiers_and_holds_name&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
   &lt;span class="mi"&gt;5178&lt;/span&gt;                 &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;self&lt;/span&gt;[&lt;span class="nv"&gt;name&lt;/span&gt;]
&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;5179&lt;/span&gt;             &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;object&lt;/span&gt;.&lt;span class="nv"&gt;__getattribute__&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;self&lt;/span&gt;, &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
   &lt;span class="mi"&gt;5180&lt;/span&gt; 
   &lt;span class="mi"&gt;5181&lt;/span&gt;     &lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;__setattr__&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;self&lt;/span&gt;, &lt;span class="nv"&gt;name&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:


&lt;span class="nv"&gt;AttributeError&lt;/span&gt;: &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;DataFrame&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; &lt;span class="nv"&gt;object&lt;/span&gt; &lt;span class="nv"&gt;has&lt;/span&gt; &lt;span class="nv"&gt;no&lt;/span&gt; &lt;span class="nv"&gt;attribute&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;convert_objects&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Elbow method to select number of clusters&lt;/h1&gt;
&lt;p&gt;This method looks at the percentage of variance explained as a function of the number of clusters: One should choose a number of clusters so that adding another cluster doesn't give much better modeling of the data. More precisely, if one plots the percentage of variance explained by the clusters against the number of clusters, the first clusters will add much information (explain a lot of variance), but at some point the marginal gain will drop, giving an angle in the graph. The number of clusters is chosen at this point, hence the "elbow criterion". This "elbow" cannot always be unambiguously identified. Percentage of variance explained is the ratio of the between-group variance to the total variance, also known as an F-test. A slight variation of this method plots the curvature of the within group variance.&lt;/p&gt;
&lt;h1&gt;Basically, number of clusters = the x-axis value of the point that is the corner of the "elbow"(the plot looks often looks like an elbow)&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cluster&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KMeans&lt;/span&gt;
&lt;span class="n"&gt;wcss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;kmeans&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KMeans&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_clusters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;k-means++&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;max_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n_init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;kmeans&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;wcss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kmeans&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inertia_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;wcss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;The Elbow Method&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Number of clusters&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;WCSS&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As the elbow corner coincides with x=2, we will have to form &lt;strong&gt;2 clusters&lt;/strong&gt;. Personally, I would have liked to select 3 to 4 clusters. But trust me, only selecting 2 clusters can lead to best results.
Now, we apply k-means algorithm.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;kmeans&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KMeans&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_clusters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;k-means++&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;max_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n_init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="n"&gt;y_kmeans&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kmeans&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, let's visualize the results.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y_kmeans&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y_kmeans&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;red&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Others&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y_kmeans&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y_kmeans&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;blue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;China(mainland),USA,India&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kmeans&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cluster_centers_&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;kmeans&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cluster_centers_&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;yellow&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Centroids&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Clusters of countries by Productivity&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So, the blue cluster represents China(Mainland), USA and India while the red cluster represents all the other countries.
This result was highly probable. Just take a look at the plot of cell 3 above. See how China, USA and India stand out. That has been observed here in clustering too.&lt;/p&gt;
&lt;p&gt;You should try this algorithm for 3 or 4 clusters. Looking at the distribution, you will realise why 2 clusters is the best choice for the given data&lt;/p&gt;
&lt;p&gt;This is not the end! More is yet to come.&lt;/p&gt;</content><category term="Machine Learning, EDA"></category><category term="Machine Learning"></category><category term="Clustering"></category><category term="Kmeans"></category></entry><entry><title>Type 2 Diabetes - Risk Predictions</title><link href="https://mmadkour.xyz%5Cposts/2019/07/Machine%20Learning,%20July%202019,%20Risk%20prediction/" rel="alternate"></link><published>2019-07-12T13:01:00-04:00</published><updated>2019-07-12T13:01:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2019-07-12:/2019/07/Machine Learning, July 2019, Risk prediction/</id><summary type="html">&lt;p&gt;Type 2 diabetes is a chronic condition that affects the way the body metabolizes sugar (glucose). With type 2 diabetes, the body either resists the effects of insulin (a hormone that regulates the movement of sugar into cells) or it doesn't produce enough insulin to maintain normal glucose levels. Type …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Type 2 diabetes is a chronic condition that affects the way the body metabolizes sugar (glucose). With type 2 diabetes, the body either resists the effects of insulin (a hormone that regulates the movement of sugar into cells) or it doesn't produce enough insulin to maintain normal glucose levels. Type 2 diabetes occurs more commonly in middle-aged and elderly people. Uncontrolled it can cause all sorts of very bad things: infections, damaged kidneys, vision loss and blindness, amputations and many more. So, there is no question that type 2 diabetes needs to be taken seriously and treated. Type 2 diabetes is usually diagnosed using the &lt;strong&gt;glycated hemoglobin (A1C)&lt;/strong&gt; test. This blood test indicates the average blood sugar level for the past two to three months. Normal levels are below 5.7 percent, and a result between 5.7 and 6.4 percent is considered prediabetes. An A1C level of 6.5 percent or higher on two separate tests means you have diabetes.&lt;/p&gt;
&lt;p&gt;People who have diabetes need this test regularly to see if their levels are staying within range and if they need to adjust their diabetes medicines. To treat type 2 diabetes lifestyle changes are very effective, and the side effects of eating more healthfully and staying more active are positive ones. In this project I will try to predict A1C levels: no-diabetes, pre-diabetes and diabetes. I will transform the dataset from a regression task (A1C) into a multi-class classification task (3 A1C levels). Notebook of this article can be found in this link : https://github.com/mohcinemadkour/Type-2-Diabetes-Risk-Prediction&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/A1c_normal_to_high_ranges.png"&gt;&lt;/p&gt;
&lt;h3&gt;Diabetes Dataset&lt;/h3&gt;
&lt;p&gt;These data are courtesy of Dr John Schorling, Department of Medicine, University of Virginia School of Medicine which can be obtained from http://biostat.mc.vanderbilt.edu/DataSets.&lt;/p&gt;
&lt;p&gt;The data consist of &lt;strong&gt;19&lt;/strong&gt; variables on &lt;strong&gt;403&lt;/strong&gt; subjects from &lt;strong&gt;1046&lt;/strong&gt; subjects who were interviewed in a study to understand the prevalence of obesity, diabetes, and other cardiovascular risk factors in central Virginia for African Americans. According to Dr John Hong, Diabetes Mellitus Type II (adult onset diabetes) is associated most strongly with obesity. The waist/hip ratio may be a predictor in diabetes and heart disease. Type 2 Diabetes is also associated with hypertension - they may both be part of &lt;strong&gt;Metabolic Syndrome&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Metabolic syndrome&lt;/strong&gt; is a collection of risk factors that includes high blood pressure, high blood sugar, excess body fat around the waist, and abnormal cholesterol levels. The syndrome increases the chance of developing heart disease, stroke, and diabetes. Aside from a large waist circumference, most of the disorders associated with metabolic syndrome have no symptoms. Losing weight, exercise, and dietary changes can help prevent or reverse metabolic syndrome. According to a national health survey, more than 1 in 5 Americans has metabolic syndrome. The number of people with metabolic syndrome increases with age, affecting more than 40% of people in their 60s and 70s.&lt;/p&gt;
&lt;p&gt;The 403 subjects were the ones who were actually screened for diabetes. Glycosolated hemoglobin (A1C) &amp;gt; 7.0 is usually taken as a positive diagnosis of diabetes. &lt;/p&gt;
&lt;h3&gt;Description of Features:&lt;/h3&gt;
&lt;p&gt;There are 403 observations and 19 features in this dataset, maximum # NaNs:262.&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/anonymous2x.png"&gt;&lt;/p&gt;
&lt;h3&gt;Challenges&lt;/h3&gt;
&lt;p&gt;I was facing two challenegs with my dataset:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;relatively small number of observations &lt;/li&gt;
&lt;li&gt;imbalanced classes (A1C levels)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To overcome the issues with imbalanced data, I will use several techniques:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;f1 macro averaged score for performance metric&lt;/li&gt;
&lt;li&gt;cost-sensitive learning (penalize algorithms)&lt;/li&gt;
&lt;li&gt;SMOTE - Synthetic Minority Over-sampling Technique&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;and several machine learning algorithms:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;L_1-regularized Logistic Regression&lt;/li&gt;
&lt;li&gt;L_2-regularized Logistic Regression&lt;/li&gt;
&lt;li&gt;Support Vector Machine (SVM)&lt;/li&gt;
&lt;li&gt;Random Forest&lt;/li&gt;
&lt;li&gt;Gradient Boosting&lt;/li&gt;
&lt;li&gt;AdaBoost&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All together, I have trained 22 models.&lt;/p&gt;
&lt;h3&gt;Findings&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;From my limited sample I could not find any single condition that would alone increase the risk for type 2 diabetes.&lt;/li&gt;
&lt;li&gt;I found that several factors could impact risks for the person to be diagnosed with diabetes: age, high cholesterol ratio, high blood presure, increased weight... &lt;/li&gt;
&lt;li&gt;Even if you have all these conditions it does not mean you will have type 2 diabetes. This will make very difficult for my models to predict A1C levels.&lt;/li&gt;
&lt;li&gt;Due to imbalanced data, all models had problems with predicting minority classes: &lt;strong&gt;pre_diabetes&lt;/strong&gt; and &lt;strong&gt;diabetes&lt;/strong&gt;. They were mostly predicting the majority class, &lt;strong&gt;no_diabetes&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;At the end, I found that Random Forest algorithm with &lt;strong&gt;cost_sensitive learning&lt;/strong&gt; did the best with &lt;strong&gt;f1 macro score&lt;/strong&gt; of 0.56.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Exploratory Analysis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The feature names got changed to make more sense&lt;/li&gt;
&lt;li&gt;As I expected, there are 403 observations and 19 features in the data set.&lt;/li&gt;
&lt;li&gt;There are 16 numerical features and 3 categorical features. All data types are correct&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Unused Features&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To make dataframe easily readable I will remove unused features like &lt;strong&gt;id&lt;/strong&gt; and &lt;strong&gt;location&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The goal of this project is to predict ranges of A1C. From a quick look through my dataframe I could see that the postprandial time when labs were drawn varies. So, let's check its distribution.&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/o_output_24_1.png"&gt;&lt;/p&gt;
&lt;p&gt;Since the postprandial time when labs were drawn has very wide range, from 5 minutes to 26 hours, I could remove &lt;strong&gt;stab_glu&lt;/strong&gt; and &lt;strong&gt;time_ppn&lt;/strong&gt; features.&lt;/p&gt;
&lt;p&gt;The number of features has been decreased to 15.&lt;/p&gt;
&lt;h3&gt;Distributions of Numeric Features&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Plotting the histogram grid&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/output_31_0.png"&gt;&lt;/p&gt;
&lt;p&gt;All distributions look OK. Only for &lt;strong&gt;a1c&lt;/strong&gt; I could see many observations around 5% (healthy range). This might be an indication of imbalanced data classes once I transfer &lt;strong&gt;a1c&lt;/strong&gt; to 3 classes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Summary statistics for the numeric features&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/Screenshot_from_2020_02_23_00_13_09.png"&gt;&lt;/p&gt;
&lt;p&gt;From the summary statistics and the visualizations I can conclude that all features look OK. I do not see any extreme values for any feature.&lt;/p&gt;
&lt;p&gt;This time I can see from the plot and from grouping that average &lt;strong&gt;a1c&lt;/strong&gt; increases with body frame size.&lt;/p&gt;
&lt;p&gt;I will keep all outliers. They just represent high and, for some observations, extreme values of &lt;strong&gt;a1c&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;Correlations&lt;/h3&gt;
&lt;p&gt;Let's calculate correlations to take a look at the relationships between numeric features and other numeric features.&lt;/p&gt;
&lt;p&gt;I are going to sort features in order of their correlation with &lt;strong&gt;a1c&lt;/strong&gt;. This will make easier to see stronger correlations for &lt;strong&gt;a1c&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;It is not easy to digest this big dataframe.
Let's use Seaborn's &lt;strong&gt;.heatmap()&lt;/strong&gt; function to visualize the correlation grid.&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/output_56_0.png"&gt;&lt;/p&gt;
&lt;p&gt;I can see few obvious stronger correlations:
* &lt;strong&gt;weight&lt;/strong&gt; and &lt;strong&gt;waist&lt;/strong&gt; and &lt;strong&gt;hip&lt;/strong&gt;
* blood presure measurements
* cholesterol ratio and &lt;strong&gt;chol&lt;/strong&gt; and &lt;strong&gt;hdl&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;But there are only few week correlations with &lt;strong&gt;a1c&lt;/strong&gt;:
* &lt;strong&gt;chol_ratio&lt;/strong&gt;, &lt;strong&gt;age&lt;/strong&gt;, &lt;strong&gt;waist&lt;/strong&gt; ...&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/pairplot_health_risk.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/output_162_0.png"&gt;&lt;/p&gt;
&lt;p&gt;The above plot is showing us that age is one of the key factors for diabetes risk. The age median and mean for risk classes are separated, but the variance is so high. That means that I have to look at many other factors that could contribute to higher risks for diabetes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/output_164_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Similar to the previous plot, higher bmi could lead to diabetes risk increase. But the variance is high and there is no strong direct correlation for that.&lt;/p&gt;
&lt;p&gt;Let's now plot a bivariate segmentation for &lt;strong&gt;bmi&lt;/strong&gt; and &lt;strong&gt;age&lt;/strong&gt; segmented by &lt;strong&gt;health_risk&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="/images/output_166_0.png"&gt;&lt;/p&gt;
&lt;p&gt;From this chart I can see less &lt;strong&gt;diabetes&lt;/strong&gt; and &lt;strong&gt;pre_diabetes&lt;/strong&gt; observations and more &lt;strong&gt;no_diabetes&lt;/strong&gt; observations for lower &lt;strong&gt;age&lt;/strong&gt; and lower &lt;strong&gt;bmi&lt;/strong&gt;. &lt;/p&gt;
&lt;h2&gt;Algorithm Selection&lt;/h2&gt;
&lt;p&gt;I have transformed the original dataset to the &lt;strong&gt;multi-class classification task&lt;/strong&gt;.
The chosen algorithms are all known to work well in this kind of task:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;L_1-regularized Logistic Regression&lt;/li&gt;
&lt;li&gt;L_2-regularized Logistic Regression&lt;/li&gt;
&lt;li&gt;Support Vector Machine (SVM)&lt;/li&gt;
&lt;li&gt;Random Forest&lt;/li&gt;
&lt;li&gt;Gradient Boosting&lt;/li&gt;
&lt;li&gt;AdaBoost&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="png" src="/images/Screenshot_from_2020_02_23_00_53_39.png"&gt;&lt;/p&gt;
&lt;h2&gt;Insights &amp;amp; Analysis&lt;/h2&gt;
&lt;p&gt;My dataset was relatively small and imbalanced and I had to employ several techniques for handling imbalanced classes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;f1 macro averaged score for performance metric&lt;/li&gt;
&lt;li&gt;cost-sensitive learning (penalize algorithms)&lt;/li&gt;
&lt;li&gt;SMOTE - Synthetic Minority Over-sampling Technique&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I have used six machine learning algorithms: $L_1$ and $L_2$ regularized Logistic Regressions, SVM and three tree ensembles, Random Forest, Gradient Boost and AdaBoost.&lt;/p&gt;
&lt;p&gt;In total, I have trained 22 models.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plain models, without any of the above listed techniques, did prety bad with predicting minority classes. They mostly predicted the majority class. Because of that, their accuracy score was high, but f1-macro score was low. As expected, tree ensembles models, were performed slightly better.&lt;/li&gt;
&lt;li&gt;All three techniques listed above, made a positive difference. Again, tree ensemble models produced better performance.&lt;/li&gt;
&lt;li&gt;I could not find one single health condition that could alone increase the risk of being diagnosed with type 2 diabetes.&lt;/li&gt;
&lt;li&gt;It looks that they are working differently for different people.&lt;/li&gt;
&lt;li&gt;From my limited sample, I could conclude that the most contributing factors were age, cholesterol ratio and waist cirumference.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Winning model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Random Forest model with cost-sensitive learning have produced the best performance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;prety good on the majority class - recall=0.83&lt;/li&gt;
&lt;li&gt;on the diabetes class not so bad - recall=0.58&lt;/li&gt;
&lt;li&gt;not so good on the smallest, pre-diabetes, class - recall=0.29&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;It is interesting to note the following regarding predicting pre-diabetes:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there were only 7 labels in the test set&lt;/li&gt;
&lt;li&gt;recall=0.29 means 2 successfully predicted labels and in addition to my winning model, only 3 models had this score: Gradient Boost, Random Forest and SVM all with SMOTE &lt;/li&gt;
&lt;li&gt;only 2 models succeded in 3 positive prediction, recall=0.43. Surprisingly, that was $L_2$-regularized Logistic Regression with SMOTE and cost-sensitive learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Possible Improvements and Expansions&lt;/h2&gt;
&lt;p&gt;These are some of possible improvements/expansions for this project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Acquire a bigger dataset so that the smallest class will have more than 7 points in the test set. And maybe, a bigger sample could produce different relationships among the features.&lt;/li&gt;
&lt;li&gt;Additional hyperparameters tuning on few best performing models&lt;/li&gt;
&lt;li&gt;Perform additional feature selection and dimensionality reduction (PCA)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/questions/50245684/using-smote-with-gridsearchcv-in-scikit-learn"&gt;Using Smote with Gridsearchcv in Scikit-learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics"&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/eikedehling/exploring-class-imbalance-resampling-and-weights"&gt;Exploring class imbalance, resampling and weights&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.geeksforgeeks.org/multiclass-classification-using-scikit-learn/"&gt;Multiclass classification using scikit-learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ritchieng.com/machine-learning-evaluate-classification-model/"&gt;Evaluating a Classification Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://elitedatascience.com/imbalanced-classes"&gt;How to Handle Imbalanced Classes in Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18"&gt;Dealing with Imbalanced Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/a-deep-dive-into-imbalanced-data-over-sampling-f1167ed74b5"&gt;A Deep Dive Into Imbalanced Data: Over-Sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.webmd.com/diabetes/guide/glycated-hemoglobin-test-hba1c?print=true"&gt;Hemoglobin A1c (HbA1c) Test for Diabetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mayoclinic.org/diseases-conditions/type-2-diabetes/diagnosis-treatment/drc-20351199"&gt;Type 2 diabetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.health.harvard.edu/blog/rethinking-a1c-goals-for-type-2-diabetes-2018032613452"&gt;Rethinking A1c goals for type 2 diabetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cdc.gov/healthyweight/assessing/bmi/adult_bmi/index.html#Interpreted"&gt;About Adult BMI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.medicalnewstoday.com/articles/319439.php"&gt;Why is the hip-waist ratio important?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://universityhealthnews.com/daily/heart-health/cholesterol-ratio-more-important-than-total-cholesterol-or-ldl-cholesterol/"&gt;What Is Cholesterol Ratio?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.healthline.com/health/blood-pressure-chart"&gt;Hypertension Chart - Understanding Your Blood Pressure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.webmd.com/diabetes/news/20050310/waist-size-predicts-diabetes-risk?print=true"&gt;Waist Size Predicts Diabetes Risk&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="Machine Learning, July 2019, Risk prediction"></category><category term="Machine Learning"></category><category term="July 2019"></category><category term="Risk prediction"></category></entry><entry><title>Modeling Time Series Data with Recurrent Neural Networks in Keras</title><link href="https://mmadkour.xyz%5Cposts/2018/12/LSTM,%20KERAS/" rel="alternate"></link><published>2018-12-12T13:01:00-05:00</published><updated>2018-12-12T13:01:00-05:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2018-12-12:/2018/12/LSTM, KERAS/</id><summary type="html">&lt;p&gt;Electronic Health Records (EHRs) contain a wealth of patient medical information that can: save valuable time when an emergency arises; eliminate unnecesary treatment and tests; prevent potentially life-threatening mistakes; and, can improve the overall quality of care a patient receives when seeking medical assistance.  Children's Hospital Los Angeles (CHLA) wanted …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Electronic Health Records (EHRs) contain a wealth of patient medical information that can: save valuable time when an emergency arises; eliminate unnecesary treatment and tests; prevent potentially life-threatening mistakes; and, can improve the overall quality of care a patient receives when seeking medical assistance.  Children's Hospital Los Angeles (CHLA) wanted to know if the records could be mined to yield early warning signs of patients that may require extra care or an indication of the severity of a patient's illness.  In this lab we have access to the work and results of CHLA's applied use of deep neural networks on EHRs belonging to roughly 5,000 pediatric ICU patients.&lt;/p&gt;
&lt;p&gt;We will use deep learning techniques to provide medical professionals an analytic framework to predict patient mortality at any time of interest. Such a solution provides essential feedback to clinicians when trying to assess the impact of treatment decisions or raise early warning signs to flag at risk patients in a busy hospital care setting.  &lt;/p&gt;
&lt;p&gt;In this lab we will use the python library &lt;a href="http://pandas.pydata.org"&gt;&lt;code&gt;pandas&lt;/code&gt;&lt;/a&gt; to manage the dataset provided in &lt;a href="https://en.wikipedia.org/wiki/Hierarchical_Data_Format"&gt;HDF5&lt;/a&gt; format and deep learning library &lt;a href="https://keras.io"&gt;&lt;code&gt;Keras&lt;/code&gt;&lt;/a&gt; to build recurrent neural networks (&lt;a href="https://en.wikipedia.org/wiki/Recurrent_neural_network"&gt;RNN&lt;/a&gt;).  In particular, this lab will construct a special kind of deep recurrent neural network that is called a long-short term memory network (&lt;a href="https://en.wikipedia.org/wiki/Long_short-term_memory"&gt;LSTM&lt;/a&gt;). Finally, we will compare the performance of this LSTM approach to standard mortality indices such as PIM2 and PRISM3 as well as contrast alternative solutions using more traditional machine learning methods like logistic regression.&lt;/p&gt;
&lt;h2&gt;Process&lt;/h2&gt;
&lt;p&gt;We will go through the following steps in this lab to show you the work CHLA performed.  These steps are meant as an example of the steps that you may take when applying deep neural networks to your data.  As such, their steps do not represent an absolute or mechanical approach to using deep neural networks - every project will vary in approach.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Setup&lt;ul&gt;
&lt;li&gt;Configure Theano options&lt;/li&gt;
&lt;li&gt;Import Numpy, Pandas and Matplotlib&lt;/li&gt;
&lt;li&gt;Define folders which contain training / testing datasets&lt;/li&gt;
&lt;li&gt;Load data using Pandas API&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data preparation&lt;ul&gt;
&lt;li&gt;Data review&lt;/li&gt;
&lt;li&gt;Data normalization&lt;/li&gt;
&lt;li&gt;Filling data gaps&lt;/li&gt;
&lt;li&gt;Data sequencing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Architect LSTM network using Keras and Theano&lt;/li&gt;
&lt;li&gt;Build the model (feed data into network for training)&lt;/li&gt;
&lt;li&gt;Evaluate model using validation (test) data&lt;/li&gt;
&lt;li&gt;Visualize results&lt;/li&gt;
&lt;li&gt;Compare baseline to PRISM3 and PIM2&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;The first thing we do is import libraries into our Python workspace.  We import the usual suspects such as NumPy for numerical calculations, pandas for data management, Matplotlib for visualizations, and Keras for building LSTM networks.  More on these in a bit ...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# configure Theano options&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;THEANO_FLAGS&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;mode=FAST_RUN,device=gpu,floatX=float32&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;          
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;              
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;  
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;

&lt;span class="c1"&gt;# configure notebook to display plots&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next we define a folder which contains both training and testing datasets stored in HDF5 format. Using this folder we define file paths inputs (X) and their associated labels (y).  &lt;a href="http://www.hdfgroup.org/"&gt;HDF5&lt;/a&gt; stands for hierarchical data format version number 5.  The HDF format is designed specifically to store and organize large amounts of scientific data and was originally designed by &lt;a href="https://en.wikipedia.org/wiki/National_Center_for_Supercomputing_Applications"&gt;National Center for Supercomputing Applications&lt;/a&gt;.  Common file extensions include &lt;code&gt;.hdf&lt;/code&gt;, &lt;code&gt;.hdf5&lt;/code&gt;, or simply &lt;code&gt;.h5&lt;/code&gt;.  The HDF format has become very popular and is well maintained.  As a result, HDF5 is a flexible and robust format having API support in most languages and library compatibilty with Windows, OS X and Linux. It is important to note that HDF is a binary format and hence lacks the human readable transparency of text based CSV files.  However, HDF file format is much faster in performance, efficient in storage size, and scales well from small proof of concept ideas to &lt;a href="https://www.hdfgroup.org/eos_vignette/"&gt;very large operational projects&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# set up user paths&lt;/span&gt;
&lt;span class="n"&gt;data_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/dli/data/hx_series&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;csv_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/dli/tasks/task1/task/csv&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;# training data inputs: x and targets: y&lt;/span&gt;
&lt;span class="n"&gt;x_train_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;X_train.hdf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_train_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;y_train.hdf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# validation data inputs: x and targest: y&lt;/span&gt;
&lt;span class="n"&gt;x_valid_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;X_test.hdf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_valid_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;y_test.hdf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally, we load the data using &lt;code&gt;pandas&lt;/code&gt; API for reading in HDF files.  Python with pandas is used in a wide variety of academic and commercial domains, including Finance, Neuroscience, Economics, Statistics, Advertising, Web Analytics, and more. The pandas library is an open source, BSD-licensed project providing easy-to-use data structures and analysis tools for the Python programming language. The pandas library features a fast and efficient DataFrame object for data manipulation with integrated indexing as well as tools for reading and writing data between in-memory data structures and different formats such as CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format. Check out the &lt;a href="http://pandas.pydata.org"&gt;pandas documentation&lt;/a&gt; for more info.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_hdf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_hdf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;X_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_hdf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_valid_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_hdf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_valid_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;The Data&lt;/h3&gt;
&lt;p&gt;This electronic health records (EHR) database contains medical treatments and histories of patients collected over time. The EHRs used here consists of 10 years worth of patient data in the Pediatric Intensive Care Unit (PICU) at Children's Hospital Los Angeles, curated by the virtual PICU (&lt;a href="http://vpicu.net"&gt;vPICU&lt;/a&gt;) team. This dataset contains 76,693 observations over 5,000 unique patient encounters.  &lt;/p&gt;
&lt;p&gt;&lt;img style="float: right;" src="/images/ehr.svg" width="450" height="300"&gt;
This data is an irregular time series of measurements taken over the course of a patient's stay in the PICU. Time between measurements can vary from minutes to hours. A simplified diagram of the data can be seen on the right. Measurements include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Statics&lt;/strong&gt; &lt;em&gt;(e.g. gender, age, weight)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vitals&lt;/strong&gt; &lt;em&gt;(e.g. heart rate, respiratory rate)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Labs&lt;/strong&gt; &lt;em&gt;(e.g. glucose, creatinine)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interventions&lt;/strong&gt; &lt;em&gt;(e.g. intubation, O2)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Drugs&lt;/strong&gt; &lt;em&gt;(e.g. dopamine, epinephrine)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One thing to note is that in addition to the non-uniform sampling, not all measurements were taken for all patients.
If we just have a look at the training data, it's clear that we have a collection of patient encounters with a set of variables observed at different times during each encounter.  But again, not all variables are measured at each epoch (row entry).
Finally, the label (y) for each patient encounter is the ultimate result of alive (1) or not alive (0). 
Let's take a look at the data.&lt;/p&gt;
&lt;p&gt;Notice here that there are 265 variables / columns in total.  We could also ask directly using &lt;code&gt;len(X_train.columns)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The data imported by pandas is a multi-index dataframe where index level 0 is the unique patient encounter identifier 
and index level 1 is the time of each measurement in units of hours since first measurement. To demonstrate how these dataframes are manipulated, we can select various encounters and extract specific variables, for example:&lt;/p&gt;
&lt;p&gt;Note that the mean number of observations per encounter, (given by &lt;code&gt;np.mean(nobs)&lt;/code&gt;), is 223 and the median count is 94.
Can we do a similar analysis to determine the observation timespan over all patient encounters?&lt;/p&gt;
&lt;p&gt;Finally, to get a look at a variable for a particular patient encounter simply extract that variable from an encounter and plot it using the &lt;code&gt;pandas&lt;/code&gt; plot function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Heart rate (bpm)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Heart rate (bpm)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hours since first encounter&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we've loaded and visualized the data, we'll prepare it to train our model.&lt;/p&gt;
&lt;h3&gt;Data Normalization&lt;/h3&gt;
&lt;p&gt;We normalize each observed feature / variable by subtracting its mean and dividing the result by the standard deviation.  &lt;/p&gt;
&lt;p&gt;Why?&lt;/p&gt;
&lt;p&gt;We want small variations in one variable to be treated with the same emphasis as HUGE variations of another. Keep in mind that the network just sees a bunch of numbers - it doesn't actually "know" anything about predictors, factors, variables, obervations and so on and so forth. Emperically, normalization seems to facilitate training but this kind of normalization is probably not appropriate for multimodal data (or non-Gaussian data in general).&lt;/p&gt;
&lt;p&gt;Let's find the distribution of these variables:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# create file path for csv file with metadata about variables&lt;/span&gt;
&lt;span class="n"&gt;metadata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;csv_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ehr_features.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# read in variables from csv file (using pandas) since each varable there is tagged with a category&lt;/span&gt;
&lt;span class="n"&gt;variables&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# next, select only variables of a particular category for normalization&lt;/span&gt;
&lt;span class="n"&gt;normvars&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Interventions&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Labs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Vitals&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;

&lt;span class="c1"&gt;# finally, iterate over each variable in both training and validation data&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;vId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dat&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;normvars&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterrows&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;dat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;dat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;std&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;1e-12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;std&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;1e-12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Filling Data Gaps&lt;/h3&gt;
&lt;p&gt;Finally, having normalized the data we still need to fill in all the data gaps since not every variable was observed at each epoch of the patient encounter.  Filling in the gaps of missing data is a very active area of research and there is currently no standard practice for time series analysis using deep learning.  For this tutorial, we will simply forward fill existing measurements for each patient, and fill any variable entries with no previous measurement to 0 as illustrated below.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/imputation_diagram.svg" width="800" height="200"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# first select variables which will be filled in&lt;/span&gt;
&lt;span class="n"&gt;fillvars&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Vitals&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Labs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;

&lt;span class="c1"&gt;# next forward fill any missing values with more recently observed value&lt;/span&gt;
&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;fillvars&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="n"&gt;fillvars&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffill&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;fillvars&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="n"&gt;fillvars&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffill&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# finally, fill in any still missing values with 0 (i.e. values that could not be filled forward)&lt;/span&gt;
&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Quickly, lets have a look at the "Heart rate" variable after data normalization and missing values have been filled in.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Heart rate (bpm)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Normalized and FFill&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Heart rate (bpm)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hours since first encounter&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Also, try dumping the X_train vector to the screen again and you will see that all those NaN values have been filled in with zeros.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Data Sequencing&lt;/h3&gt;
&lt;p&gt;The final data preparation task is to pad every patient encounter so that all encounters have the same number of observations. Note from the histogram that there are many encounters with less than 100 observation vectors. Therefore we are going to zero pad each encounter (i.e. insert rows of zeros).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sequence&lt;/span&gt;

&lt;span class="c1"&gt;# max number of sequence length&lt;/span&gt;
&lt;span class="n"&gt;maxlen&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;

&lt;span class="c1"&gt;# get a list of unique patient encounter IDs&lt;/span&gt;
&lt;span class="n"&gt;teId&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;levels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;veId&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;levels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# pad every patient sequence with 0s to be the same length, &lt;/span&gt;
&lt;span class="c1"&gt;# then transforms the list of sequences to one numpy array&lt;/span&gt;
&lt;span class="c1"&gt;# this is for efficient minibatching and GPU computations &lt;/span&gt;
&lt;span class="n"&gt;X_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patient&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;patient&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;teId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patient&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;patient&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;teId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;X_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sequence&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;post&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;truncating&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;post&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sequence&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;post&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;truncating&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;post&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# repeat for the validation data&lt;/span&gt;

&lt;span class="n"&gt;X_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patient&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;patient&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;veId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patient&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;patient&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;veId&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;X_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sequence&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;post&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;truncating&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;post&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sequence&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;post&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;truncating&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;post&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Okay, a lot just happened here:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We converted the &lt;code&gt;pandas&lt;/code&gt; data frame into a Python &lt;code&gt;list&lt;/code&gt; which contained lists of values (a list of list of values).  &lt;/li&gt;
&lt;li&gt;Using  &lt;code&gt;keras.preprocessing.sequence.pad_sequences&lt;/code&gt; we converted the value lists into a &lt;code&gt;numpy.array&lt;/code&gt; of type &lt;code&gt;float32&lt;/code&gt; having a maximum length of 500.  &lt;/li&gt;
&lt;li&gt;If the patient encounter didn't have 500 encounters (most don't, see previous histogram) then we apply &lt;code&gt;padding='post'&lt;/code&gt; which says to pad with zeros.  That is add extra rows (observation vectors) of all zeros.&lt;/li&gt;
&lt;li&gt;The option &lt;code&gt;truncating='post'&lt;/code&gt; just says if there are more than 500 observations then take the first 500 and drop everything after.  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Together, this says: &lt;em&gt;force patient encounter records of dimension 500x265 and use zero padding to inflate the size if needed&lt;/em&gt;.  We could do something similar in &lt;code&gt;pandas&lt;/code&gt; but not with only a single command.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# print the shape of the array which will be used by the network&lt;/span&gt;
&lt;span class="c1"&gt;# the shape is of the form (# of encounters, length of sequence, # of features)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;X_train shape: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt; | y_train shape: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;X_valid shape: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt; | y_valid shape: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that the type of X_train has changed to &lt;code&gt;numpy.ndarray&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we can plot the full patient encounter as a matrix plot.  Try a few times to get a feel for what the charts look like.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# figure out how many encounters we have&lt;/span&gt;
&lt;span class="n"&gt;numencnt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# choose a random patient encounter to plot&lt;/span&gt;
&lt;span class="n"&gt;ix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="c1"&gt;#Try a few different index values between 0 and 4999&lt;/span&gt;

&lt;span class="c1"&gt;# plot a matrix of observation values&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pcolor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="p"&gt;,:,:]))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;variable&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;time/epoch&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;265&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;colorbar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Keep in mind here that these data are zero padded by &lt;code&gt;sequence.pad_sequences&lt;/code&gt;.  Try a few different index values between 0 and 4999 to get a feel for what the matrix plots look like. These matricies are what will be fed as input into the LSTM model for training. Notice that we can plot a variable in a similar fashion by selecting along the third axis instead of the first axis. This provides a view of a particular variable over all patient encounters. Give it a try!&lt;/p&gt;
&lt;h2&gt;Recurrent Neural Network Models&lt;/h2&gt;
&lt;p&gt;The recurrent neural network (&lt;a href="https://en.wikipedia.org/wiki/Recurrent_neural_network"&gt;RNN&lt;/a&gt;) is effectively a traditional feed-forward network with feedback.  In a traditional feed-forward network all inputs are considered independent.  However, the input to an RNNs also includes the previous output state.  This allows RNNs to model very complex sequences of input and it can be shown that RNNs are, in fact, &lt;a href="https://en.wikipedia.org/wiki/Turing_completeness"&gt;Turing complete&lt;/a&gt; (see &lt;a href="http://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf"&gt;here&lt;/a&gt;).
&lt;img src="/images/rnn.jpg" width="500"&gt;
&lt;p style="text-align: center;"&gt;&lt;em&gt;image credit: wildml.com&lt;/em&gt;&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;In theory RNNs can make use of information in arbitrarily long sequences, but in practice they are limited to looking back only a few steps due to what is called the &lt;a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem"&gt;&lt;em&gt;vanishing gradient&lt;/em&gt;&lt;/a&gt; problem.  In essence, during the traning process, as errors are backpropagated through time, inputs from previous time steps get exponentially down weighted and are eventually driven to zero (i.e. vanish).  &lt;/p&gt;
&lt;p&gt;There is a variant of the RNN called the &lt;a href="https://en.wikipedia.org/wiki/Long_short-term_memory"&gt;Long Short Term Memory (LSTM)&lt;/a&gt; network published by &lt;a href="http://www.bioinf.jku.at/publications/older/2604.pdf"&gt;Hochreiter &amp;amp; Schmidhuber&lt;/a&gt; in 1997. LSTMs do not have vanishing gradient problems.  LSTM is normally augmented by recurrent gates called &lt;a href="http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf"&gt;forget gates&lt;/a&gt;. As mentioned, a defining feature of the LSTM is that it prevents backpropagated errors from vanishing (or exploding) and instead allow errors to flow backwards through unlimited numbers of "virtual layers" unfolded in time. That is, the LSTM can learn "&lt;a href="https://arxiv.org/abs/1404.7828"&gt;very deep&lt;/a&gt;" tasks that require memories of events that happened thousands or even millions of discrete time steps ago. Problem-specific LSTM-like topologies can be &lt;a href="http://link.springer.com/chapter/10.1007/978-3-642-04277-5_76"&gt;evolved&lt;/a&gt; and can work even when signals contain long delays or have a mix of low and high frequency components.&lt;/p&gt;
&lt;p&gt;We will now construct a RNN in order to ingest the data and make a prediction at each timestep of the patient's probability of survival. The image below shows an abstract representation of the model to be constructed using &lt;code&gt;Keras&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/drted_rnn.svg" width="800"&gt;&lt;/p&gt;
&lt;p&gt;At each time step the measurements recorded will be used as input and a probability of survival prediction will be generated. It is important to note that this enables a real time monitor of the patient's probability of survival and insight into the patient's trajectory.&lt;/p&gt;
&lt;h3&gt;Constructing LSTM Network with Keras&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://keras.io"&gt;Keras&lt;/a&gt; is a minimalist but modular neural networks library written in Python.   &lt;code&gt;Keras&lt;/code&gt; is capable of running on top of either the &lt;a href="https://www.tensorflow.org"&gt;TensorFlow&lt;/a&gt; or &lt;a href="http://deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt; frameworks.  Here we are interested in using Theano as it excels at RNNs in general and LSTM in particular.  Note that some frameworks such as &lt;a href="http://caffe.berkeleyvision.org"&gt;Caffe&lt;/a&gt; do not support RNNs.  Keras was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.  The &lt;code&gt;Keras&lt;/code&gt; library allows for easy and fast prototyping of solutions and supports both convolutional networks and recurrent networks, as well as combinations of the two.  Furthermore, &lt;code&gt;Keras&lt;/code&gt; supports arbitrary connectivity schemes (including multi-input and multi-output training).
Finally, &lt;code&gt;Keras&lt;/code&gt; runs on either CPU or GPU and is compatible with Python 2.7-3.5.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.layers&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TimeDistributed&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Masking&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.optimizers&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RMSprop&lt;/span&gt;

&lt;span class="c1"&gt;# Note: building model using Keras Functional API (version &amp;gt; 1.0)&lt;/span&gt;

&lt;span class="c1"&gt;# construct inputs&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;input&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Masking&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;input_masked&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# stack LSTMs&lt;/span&gt;
&lt;span class="n"&gt;lstm_kwargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;dropout_W&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;dropout_U&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;return_sequences&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;consume_less&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;gpu&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;lstm1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lstm1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;lstm_kwargs&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# output: sigmoid layer&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TimeDistributed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;output&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;lstm1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# compile model&lt;/span&gt;
&lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RMSprop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.005&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# print layer shapes and model parameters&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Decisions made while architecting the model&lt;/h3&gt;
&lt;p&gt;We created a single LSTM.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Binary cross entropy loss function&lt;/em&gt; is used because it is the theoretically optimal cost function for a binary classification problem (in this case, mortality). However, occasionally the Mean Squared Error (MSE) cost function is used since it tends to be a bit more stable numerically.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Dropout W&lt;/em&gt; is used because it randomly drops elements of the input vector (It drops the same elements of the vector for every time step of the sequence). This forces the network to leverage information contained in potentially covariate variables (for instance – for a particular sample Heart Rate may be ‘dropped’, but a combination of systolic/diastolic blood pressure and breathing rate may provide a reasonable proxy).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Dropout U&lt;/em&gt; is used for similar reasons to traditional dropout in CNNs. It forces the network to utilize all of the hidden nodes such that too much information is not contained in a single hidden unit. In practice this tends to lead to more stable networks.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;RMSprop&lt;/em&gt; optimizer is selected because it is a good general optimizer for LSTMs.  See &lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/"&gt;here&lt;/a&gt; for more details.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;LR=0.005&lt;/em&gt; is selected in order to find a reasonable local minimum within a small number of epochs for time consideration.  Typically one would likely use an even smaller LR and allow the network to take smaller ‘learning steps’ but that choice requires more training rounds to converge (i.e. slower training).&lt;/p&gt;
&lt;p&gt;As always with neural networks, there was some amount of hyper-parameter tuning.  It is important to keep in mind that this network has not been optimally tuned.  A handful of reasonable default values were chosen to create a state-of-the-art mortality predictor in the least amount of GPU cycles possible (for tutorial purposes).&lt;/p&gt;
&lt;p&gt;Read the &lt;a href="https://keras.io/layers/core/"&gt;docs&lt;/a&gt; for more information on core layers in &lt;code&gt;Keras&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Now, lets feed some data into the network for training. We use a batch size of 128 which means that we update parameters every 128 images.  For demonstration purposes we will use only 5 training epochs, which means that we run through the data 5 times.  Finally, the verbose option just says to produce status / summary information during the training.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# this will take a while...&lt;/span&gt;
&lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_epoch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Evaluate Model &amp;amp; Compare with Baselines&lt;/h3&gt;
&lt;p&gt;Our first task in evaluating the model performance is to predict mortality using the hold out dataset (i.e. validation data).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# generate RNN results on holdout validation set&lt;/span&gt;
&lt;span class="n"&gt;preds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice that size of the predictions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;preds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That is, we have 2,690 patient encounters for testing, and at each of the observations the model predicts survivability.  Lets plot some predictions!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# figure out how many encounters we have&lt;/span&gt;
&lt;span class="n"&gt;numencnt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# choose a random patient encounter to plot&lt;/span&gt;
&lt;span class="n"&gt;ix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;numencnt&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# create axis side by side&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# plot the obs chart for patient encounter&lt;/span&gt;
&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pcolor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,:]))&lt;/span&gt;
&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;265&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# plot the patient survivability prediction&lt;/span&gt;
&lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;preds&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Comparison against baselines: PRISM3 and PIM2.&lt;/h2&gt;
&lt;p&gt;Both PIM2 and PRISM3 are scoring systems for ICU and surgical patients.  Models that predict the risk of death of groups of patients admitted to intensive care are available for adult, pediatric and neonatal intensive care. By adjusting for differences in severity of illness and diagnosis, these models can be used to compare the standard of care between units and within units over time. They can also be used to compare different methods of organising intensive care. Estimating mortality risk is also an important component of comparing groups of patients in research trials.  &lt;/p&gt;
&lt;p&gt;The Pediatric Index of Mortality (PIM) was originally developed as a simple model that requires variables collected at the time of admission to intensive care. The original PIM was developed predominantly in Australian units; in the first report only one of the eight units was actually available in the United Kingdom. The PIM2 is a revised mortality index using a more recent data set from 14 intensive care units, eight in Australia, four in the UK, and two in New Zealand. In the analysis for PIM2, 20,787 patient admissions of children less than 16 years of age were included. Since PIM2 estimates mortality risk from data readily available at the time of ICU admission it is therefore suitable for continuous monitoring of the quality of paediatric intensive care. PIM2 uses the first value of each variable measured within the period from the time of first contact to one hour after arrival in the ICU.  If information is missing (e.g. Base Excess is not measured) PIM2 records zero, except for systolic blood pressure, which should be recorded as 120. All consecutive admissions are included.  See &lt;a href="https://www.ncbi.nlm.nih.gov/pubmed/12541154"&gt;Slater et al.&lt;/a&gt; for full details.&lt;/p&gt;
&lt;p&gt;Similarly, the Pediatric Risk of Mortality (&lt;a href="http://www.ncbi.nlm.nih.gov/pubmed/3048900"&gt;PRISM&lt;/a&gt;) score was originally developed around 1988 from the Physiologic Stability Index (&lt;a href="http://www.ncbi.nlm.nih.gov/pubmed/6728571"&gt;PSI&lt;/a&gt;) to reduce the number of variables required for pediatric ICU mortality risk assessment, from 34 (in the PSI) to 14 and to obtain an objective weighting of the remaining variables.  Here &lt;a href="http://www.jpeds.com/article/S0022-3476(97)70065-9/abstract"&gt;PRISM3&lt;/a&gt; is an updated version of the scoring system published in 1996 which has several improvements over the original model. However, it is only available under licence and is not widely used outside of the United States.  The PRISM3 score has 17 physiologic variables subdivided into 26 ranges. The variables determined most predictive of mortality were minimum systolic blood pressure, abnormal pupillary reflexes, and stupor/coma.&lt;/p&gt;
&lt;p&gt;First, we'd compute &lt;a href="http://gim.unmc.edu/dxtests/roc2.htm"&gt;ROC&lt;/a&gt; information for the predictions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;auc&lt;/span&gt;

&lt;span class="c1"&gt;# get 0/1 binary lable for each patient encounter&lt;/span&gt;
&lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y_valid&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

&lt;span class="c1"&gt;# get the last prediction in [0,1] for the patient&lt;/span&gt;
&lt;span class="n"&gt;prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;preds&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# compute ROC curve for predictions&lt;/span&gt;
&lt;span class="n"&gt;rnn_roc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;prediction&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# compute the area under the curve of prediction ROC&lt;/span&gt;
&lt;span class="n"&gt;rnn_auc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;auc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rnn_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;rnn_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next we'd extract precompute PIM2 and PRISM3 estimates from CSV file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# scores for baselines PRISM3 and PIM2 were aggregated and stored in `data/pim2prism3.csv`.&lt;/span&gt;
&lt;span class="c1"&gt;# load the scores and then compute the ROC curves and AUC&lt;/span&gt;
&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;csv_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pim2prism3.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# get the mortality reponse for each patient&lt;/span&gt;
&lt;span class="n"&gt;mortrep&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mortalityResponse&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;

&lt;span class="c1"&gt;# generate ROC curves for each index&lt;/span&gt;
&lt;span class="n"&gt;pim2_roc&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mortrep&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;PIM2&amp;#39;&lt;/span&gt;  &lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;prism3_roc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mortrep&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;PRISM3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;# compute the area under the curve for each index&lt;/span&gt;
&lt;span class="n"&gt;pim2_auc&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;auc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;  &lt;span class="n"&gt;pim2_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;   &lt;span class="n"&gt;pim2_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;prism3_auc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;auc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prism3_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;prism3_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's now plot these ROC curves against our RNN for comparison.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# plot rocs &amp;amp; display AUCs&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;line_kwargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;linewidth&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;alpha&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prism3_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;prism3_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;prism3: &lt;/span&gt;&lt;span class="si"&gt;%0.3f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;prism3_auc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;#4A86E8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;line_kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pim2_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;pim2_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;pim2: &lt;/span&gt;&lt;span class="si"&gt;%0.3f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;pim2_auc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;#FF9900&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;line_kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rnn_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;rnn_roc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;rnn: &lt;/span&gt;&lt;span class="si"&gt;%0.3f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;rnn_auc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;#6AA84F&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;line_kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lower right&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.05&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.05&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.75&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yticks&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.75&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;False Positive Rate&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;True Positive Rate&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Severity of Illness ROC Curves&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.25&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tight_layout&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice how good this is considering we only did a few rounds of training!&lt;/p&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;RNNs provide a method to quickly extract clinically significant information and insights from available EHR data.&lt;/p&gt;
&lt;p&gt;The amount of data, model complexity, number of features, and number of epochs have been reduced in this tutorial to  reduce computational burden.  The examples below display the performance of a fully trained RNN on a larger dataset.  They also show the performance of PIM2 and PRISM3, two standard scoring systems,  as well as the performance of a logistic regression model and a multi-layer perceptron (MLP).  &lt;/p&gt;
&lt;p&gt;The temporally dynamic nature of the RNN enables it to extract more information from the underlying EHR than an MLP.  The MLP's complexity is similar to the RNN's, but the former is limited to instantaneous information.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/RNN_performance.svg" width="500" height="500"&gt;&lt;/p&gt;
&lt;p&gt;Below shows the temporal trajectory of the fully trained RNN's probability of survival predictions. The capability to provide a prediction at any timestep of interest provides valuable feedback to a clinician working to asses the impact of treatment decisions.   &lt;/p&gt;
&lt;p&gt;&lt;img src="/images/MortalityThroughTime.svg" width="500" height="500"&gt;&lt;/p&gt;
&lt;h2&gt;Discovery Requires Experimentation&lt;/h2&gt;
&lt;p&gt;Here are a few ideas for how to 'turn knobs' and 'push buttons'.  How do these modifications effect training and performance w.r.t PIM2 and PRISM3?
- Go and add a second and third LSTM layer to the network.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Change the number of layers and the number of neurons in those layers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How about changing some of the meta parameters in the network configuration like dropout or learning rate etc.?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Question] How about trying a CNN?  That is, does the RNN / LSTM model out perform a vanilla CNN model?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Something to think about] Does this dataset suffer from too few negative / fatality cases?  ICU survivability is 96%.  How might this affect training?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Hands On&lt;/h2&gt;
&lt;p&gt;The notebook and presentation of this article can be found in : https://github.com/mohcinemadkour/Modelling-Time-Series-Data-with-Keras&lt;/p&gt;</content><category term="Time Series Classification"></category><category term="LSTM"></category><category term="KERAS"></category></entry><entry><title>End to End ETL process using CSV files and MySQL database</title><link href="https://mmadkour.xyz%5Cposts/2018/10/Using%20only%20Python%20ETL%20a%20set%20of%20CSV%20files%20to%20a%20native%20MySQL%20database%20from%20end%20to%20end2/" rel="alternate"></link><published>2018-10-07T16:00:00-04:00</published><updated>2018-10-07T16:00:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2018-10-07:/2018/10/Using only Python ETL a set of CSV files to a native MySQL database from end to end2/</id><summary type="html">&lt;p&gt;This post explains an end to end process to move data from simple CSV files to a database server, in my case MySQL but you can do some tiny changes to have it work in any SQL language. I put the schema of the [database I generated from this code …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This post explains an end to end process to move data from simple CSV files to a database server, in my case MySQL but you can do some tiny changes to have it work in any SQL language. I put the schema of the [database I generated from this code] (http://mohcinemadkour.github.io/DBSchema/) using schemaSPy. This is a 20 Gegabytes database I have cleaned and generated. I found this code also very useful wehn moving the database from development to production environments. I made this code in a modular format so the functions can be used if needed such as data_type function which detect the type of the column data and cast it to a python data type &lt;/p&gt;
&lt;h2&gt;Some notes&lt;/h2&gt;
&lt;p&gt;Usually when I need to upload a CSV I will use Periscope
 Data's CSV functionality. It's fast, easy, allows me to join the data with all my databases, and automatically casts types and load the data. Sometimes, however, I like to interact directly with a MySQL cluster—usually for complex data transformations and modeling in Python. When interacting directly with a database, it can be a pain to write a create table statement and load your data. When the table is wide, you have two choices while writing your create table—spend the time to figure out the correct data types, or lazily import everything as text and deal with the type casting in SQL. The first is slow, and the second will get you in trouble down the road.&lt;/p&gt;
&lt;p&gt;Here I show an example of this case when I upload 20 Gega of EHR data in a CSV format which are daunting 100+ columns wide. I wanted to load the data into MySQL server and rather than be generous in my data types, I wanted to use the proper columns. I decided to speed up the load process by writing a Python script, which turned into a fun exercise in data type detection and automated data loading to database.&lt;/p&gt;
&lt;h2&gt;Check-list before start&lt;/h2&gt;
&lt;p&gt;First of all ... couple of things to check:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check your database is created and you have the required information (host name, database name, user, password)&lt;/li&gt;
&lt;li&gt;Names of columns can not have spaces&lt;/li&gt;
&lt;li&gt;Names of files will be the name of tables in the database&lt;/li&gt;
&lt;li&gt;The tables will be Droped if already exist&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Import libraries and provide path to data and information for connection&lt;/h2&gt;
&lt;p&gt;The first step is to load our data, import our libraries, and load the data into a CSV reader object. The csv library will be used to iterate over the data, and the ast library will be used to determine data type.&lt;/p&gt;
&lt;p&gt;We will also use a few lists. "Longest" will be a list of the longest values in character length to specify varchar column capacity, "headers" will be a list of the column names, and "type_list" will be the updating list of column types as we iterate over our data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;mysql.connector&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;mysql.connector&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;csv&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;listdir&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;os.path&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;isfile&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;join&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;itertools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;csv&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;ast&lt;/span&gt; 
&lt;span class="c1"&gt;#import psycopg2&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;print_function&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Path and list of files I wanted to create the database from&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#mypath=&amp;quot;/home/mohcine/Databox/Data/SortedData/left/new/&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;mypath&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Your path to where the CSV files are located&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;onlyfiles&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;listdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mypath&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;isfile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mypath&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;onlyfiles&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Database info&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Your creadential of the database&lt;/span&gt;
&lt;span class="n"&gt;myhost&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;mydatabase&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;myuser&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;mypassword&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Find the Data Type&lt;/h2&gt;
&lt;p&gt;Once we have our data, we need to find the data type for each row. This means we need to evaluate every value and cast to the most restrictive option, from decimalized numbers to integers, and from integers to strings.&lt;/p&gt;
&lt;p&gt;The function dataType does this. First, it evaluates to see if the value is text or a number, and then for the appropriate type of number if needed. This function consumes both the new data, and the current best type to evaluate against. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;dataType&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;current_type&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# Evaluates numbers to an appropriate type, and strings an error&lt;/span&gt;
        &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;literal_eval&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;varchar&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;SyntaxError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;varchar&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;long&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;long&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_type&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;float&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;varchar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="c1"&gt;# Use smallest possible int type&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;32768&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;32767&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_type&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;int&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;bigint&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;smallint&amp;#39;&lt;/span&gt;
            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2147483648&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2147483647&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_type&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bigint&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;int&amp;#39;&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;bigint&amp;#39;&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_type&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;varchar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;decimal&amp;#39;&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;varchar&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Create tables&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;onlyfiles&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;#Create table from the generated statement      &lt;/span&gt;
    &lt;span class="n"&gt;fo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mypath&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;reader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fo&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;longest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;type_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="c1"&gt;# iterate over the rows in our CSV, call our function above, and populate our lists&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;        
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;longest&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;type_list&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
                &lt;span class="c1"&gt;# NA is the csv null value&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;type_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;varchar&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;NA&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;pass&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;var_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataType&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;type_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                    &lt;span class="n"&gt;type_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;var_type&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;longest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                    &lt;span class="n"&gt;longest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;fo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# And use our lists to write the SQL statement.&lt;/span&gt;

    &lt;span class="n"&gt;statement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;DROP TABLE IF EXISTS &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;myhost&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;database&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mydatabase&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;myuser&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mypassword&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_connected&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt; 
            &lt;span class="n"&gt;cursor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;statement&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;commit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;finally&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# Make sure data is committed to the database&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;commit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;statement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;CREATE TABLE &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39; (&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;type_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;varchar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;statement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;statement&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{} varchar({}),&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;longest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;statement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;statement&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{} {}&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;type_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;statement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;statement&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;);&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;statement&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;#Create table from the generated statement  &lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;myhost&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;database&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mydatabase&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;myuser&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mypassword&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_connected&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt; 
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;connected&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;cursor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;statement&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;commit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;finally&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# Make sure data is committed to the database&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;commit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Load Data from local csv files&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;onlyfiles&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;#print f&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mypath&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;csv_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;csv_reader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictReader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;csv_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;line_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;csv_reader&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line_count&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;cln&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;csv_reader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;line_count&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="n"&gt;inserts&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;cln&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;inserts&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;inserts&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;],)&lt;/span&gt;
            &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inserts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;#print len(cln)&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;cal&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;cln&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;(&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;(&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;,&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cln&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
            &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;,&amp;quot;&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cln&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
            &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;)&amp;quot;&lt;/span&gt;  
            &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;)&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;myhost&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;database&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mydatabase&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;myuser&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mypassword&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_connected&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;       
            &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;INSERT INTO &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;VALUES&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;
            &lt;span class="n"&gt;cursor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;commit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;finally&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# Make sure data is committed to the database&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;commit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Check tables&lt;/h2&gt;
&lt;p&gt;Checking if the number of rows in the CVS files are matching the count of tables' rows in the database&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;onlyfiles&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mypath&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;csvlines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;lineNum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;csvlines&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;lineNum&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;The csv file {} has {} rows and {} columns &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mypath&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="Database"></category><category term="MySQL"></category><category term="Database"></category><category term="Load data"></category><category term="CSV"></category></entry><entry><title>Deep Reinforcement Learning</title><link href="https://mmadkour.xyz%5Cposts/2018/06/Deep%20Reinforcement%20Learning/" rel="alternate"></link><published>2018-06-14T13:01:00-04:00</published><updated>2018-06-14T13:01:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2018-06-14:/2018/06/Deep Reinforcement Learning/</id><summary type="html">&lt;p&gt;Today, we will explore Reinforcement Learning – a goal-oriented learning based on interaction with environment. Reinforcement Learning is said to be the hope of true artificial intelligence. And it is rightly said so, because the potential that Reinforcement Learning possesses is immense.
Reinforcement learning refers to goal-oriented algorithms, which learn how …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today, we will explore Reinforcement Learning – a goal-oriented learning based on interaction with environment. Reinforcement Learning is said to be the hope of true artificial intelligence. And it is rightly said so, because the potential that Reinforcement Learning possesses is immense.
Reinforcement learning refers to goal-oriented algorithms, which learn how to attain a complex objective (goal) or maximize along a particular dimension over many steps; for example, maximize the points won in a game over many moves. They can start from a blank slate, and under the right conditions they achieve superhuman performance. Like a child incentivized by spankings and candy, these algorithms are penalized when they make the wrong decisions and rewarded when they make the right ones – this is reinforcement.&lt;/p&gt;
&lt;h1&gt;Introduction to reinforcement learning&lt;/h1&gt;
&lt;h2&gt;The learning paradigm&lt;/h2&gt;
&lt;p&gt;The RL is kind of learning by doing, with no supervisor, but only a reward signal. The Feedback is  delayed and not instantaneous. In this kind of learning the time really matters and the agent’s actions affect the subsequent data it receives
A reward Rt is a scalar feedback signal, It indicates how well agent is doing at step t. The agent’s job is to maximise cumulative reward. Reinforcement learning is based on the reward hypothesis, which states that all goals can be described by the &lt;strong&gt;Maximisation of expected cumulative reward&lt;/strong&gt;. 
Examples of Rewards can be +ve reward for following desired trajectory and −ve reward for crashing.
The goal is to select actions to maximise total future reward. The actions may have long term consequences, and the reward may be delayed. Sometimes It may be better to sacrifice immediate reward to gain more long-term reward
Examples are numerous. For example a financial investment (may take months to mature), and Refuelling a helicopter (might prevent a crash in several hours)
Two fundamental problems in sequential decision making 
&lt;img alt="supervised vs rl" src="/images/dsrl.png"&gt;&lt;/p&gt;
&lt;h2&gt;Sequential Decision Making&lt;/h2&gt;
&lt;p&gt;The reinforcement learning id a Sequential Decision Making process. In general there is two types of environmnets: Fully Observable Environments which is recommended for Markov decision process in where the Agent state about the environmnet is identical with the environment state and with the information state; and the Partially Observable Environments in which the Partially Markov decision process can be applied. In this environment, the agent indirectly observes environment. The Agent must construct its own state representation whcih includes complete history, beliefs of environment state. The Recurrent neural network can be used in this case.&lt;/p&gt;
&lt;h2&gt;Components of an RL Agent&lt;/h2&gt;
&lt;p&gt;An RL agent may include one or more of these components: Policy: agent’s behaviour function, Value function: how good is each state and/or action, and Model: agent’s representation of the environment. The &lt;strong&gt;Policy&lt;/strong&gt; is the agent’s behaviour. It is a map from state to action, e.g. We have two types : Deterministic policy: a = π(s) and Stochastic policy: π(a|s) = P[At = a|St = s]. The &lt;strong&gt;Value Function&lt;/strong&gt; is a prediction of future reward. It is used to evaluate the goodness/badness of states And therefore to select between actions, e.g.]:&lt;strong&gt;vπ(s)&lt;/strong&gt; = Eπ [Rt+1 + γRt+2 + γ2 Rt+3 + ... | St = s]. &lt;strong&gt;The model&lt;/strong&gt; predicts what the environment will do next. The P predicts the next state, and the R predicts the next (immediate) reward.
Pss'= P[St+1 = s | St = s, At = a], Ras = E [Rt+1 |St = s, At = a]&lt;/p&gt;
&lt;h1&gt;Types of reinforcement learning algorithms&lt;/h1&gt;
&lt;p&gt;RL algorithms that satisfy the &lt;em&gt;Markov property&lt;/em&gt; are called the &lt;em&gt;Markov Decision Processes (MDP)&lt;/em&gt;. The Markov property assumes that the current state is independent of the path that leads to that particular state. 
&lt;img alt="Markovian environments and Non Markovian environments" src="/images/markov.png"&gt;
Hence, in Markovian problems a memoryless property of a stochastic process is assumed. In practice it means that the probability distribution of the future states depends only on the current state and not on the sequence of events that preceded. This is a useful property for stochastic processes as it allows for analysing the future by setting the present
&lt;img alt="State Transition from state s to state s'" src="/images/fig1_rl.png"&gt;
An MDPs consist of state (s), action (a) sets and given any state and action to be taken, a transition probability function of each possible next state (s’) illustrated in figure 1. In addition, each taken action to arrive to the next state is rewarded giving each of all possible actions a reward value
depending on the type of action. Each visited state is accredited by a value given to it according to a &lt;strong&gt;value function V(s)&lt;/strong&gt; which represents how good it is for an agent to be in a given state. The value of a state s under a policy π is then denoted as Vπ(s) which in theory denotes the expected return when starting in state s and following a sequence of states to be visited according to the order defined in π thereafter. When this theorem is applied to a model-free control problem, the &lt;strong&gt;state-value function&lt;/strong&gt; may
not suffice as it does not show what action was taken for the state value to be acquired. Therefore, a similar function has been introduced representing an estimation of the value of each possible action in a state. This is described as the &lt;strong&gt;action-value function&lt;/strong&gt; for policy π Qπ(s,a). Figure 2 illustrates an example of the relationship between the action-value function and the state-value function. In 2.a. the action-values are shown for each direction of the propagation, North, East, South, and West respectively. &lt;strong&gt;The state value function represents then the highest action-value possible in that state which is the action North in the example&lt;/strong&gt;.&lt;img alt="1a 1b" src="/images/rl_fig2.png"&gt;&lt;/p&gt;
&lt;p&gt;The optimal policy is denoted as the superscript asterisk to the action-value-function Q(s,a) and state value-function V(s). Formally, the optimal value function is then given by:
&lt;img alt="Eq1" src="/images/eq1.png"&gt;
Where Q*(s,a) is given by:
&lt;img alt="Eq2" src="/images/eq2.png"&gt;
Herein, T(s, a, s’) is the transition probability to the next state s’ given state s and action a. γ presents the discount factor which is usually smaller than 1 and is used to discount for earlier values in order to assign
higher values for sooner rewards. This is necessary to converge the algorithm.
Substituting equation 3 in 2 gives the Bellman equation:
&lt;img alt="Eq3" src="/images/eq3.png"&gt;
These updates will be appended to the states that were visited resulting (after a significant number of iterations) in state values showing how good to be in that state. In order to be able to choose between the states to select a policy, &lt;strong&gt;as many states as possible need to be visited&lt;/strong&gt; in order to converge to an accurate estimation of the state value. Acquiring the highest reward depends on these visited states and the reward accumulated. However, in order to discover more states and potentially higher rewards, the agent needs to take actions it has never taken before. This is referred to as the &lt;strong&gt;trade-off between exploitation and exploration&lt;/strong&gt;. This trade-off could be achieved by setting a variable denoted as Epsilon (ε) which gives the extent of exploration versus exploitation. A fully exploiting policy is referred to as an
epsilon-greedy policy and holds a value of 0 for ε. Correspondingly, a fully exploring policy gives a value of 1 to ε and is referred to as an epsilon-soft policy. The learning can therefore be tuned between these two extremes in order to allow for convergence towards an optimal value by occasionally exploring new states and actions.&lt;/p&gt;
&lt;h2&gt;Categorisies of RL agents&lt;/h2&gt;
&lt;p&gt;Reinforcement learning is like trial-and-error learning. The agent should discover a good policy from its experiences of the environment and Without losing too much reward along the way. The &lt;strong&gt;Exploration&lt;/strong&gt; finds more information about the environment. The &lt;strong&gt;Exploitation&lt;/strong&gt; exploits known information to maximise reward. It is usually important to explore as well as exploit.
An agent can evaluate the future Given a policy (&lt;strong&gt;Prediction&lt;/strong&gt;) or optimise the future and find the best policy (&lt;strong&gt;Control&lt;/strong&gt;)
There is five types of agents: &lt;strong&gt;Value Based&lt;/strong&gt; No Policy (Implicit)+ Value Function, &lt;strong&gt;Policy Based&lt;/strong&gt;: Policy + No Value Function, &lt;strong&gt;Actor Critic&lt;/strong&gt;: Policy+ Value Function, &lt;strong&gt;Model Free&lt;/strong&gt;: Policy and/or Value Function+ No Model
, &lt;strong&gt;Model Based&lt;/strong&gt;: Policy and/or Value Function+ Model
&lt;img alt="RL Agents" src="/images/RLAgents.png"&gt;&lt;/p&gt;
&lt;h2&gt;Classes of RL algorithms&lt;/h2&gt;
&lt;p&gt;RL knows three fundamental classes of methods for solving these learning problems: &lt;strong&gt;Dynamic Programming (DP)&lt;/strong&gt;, &lt;strong&gt;Monte Carlo methods&lt;/strong&gt;,  &lt;strong&gt;Temporal-difference learning&lt;/strong&gt;
Dependent on the problem at stake, each of these methods could be more suitable than the other. &lt;strong&gt;DP&lt;/strong&gt; methods are model-based and require therefore a complete and accurate model of the environment i.e. all the aforementioned functions of the environment need to be known to initiate learning. However,
the environment is not always defined prior to the learning process which poses a challenge to this method. This is where the two other &lt;strong&gt;model-free&lt;/strong&gt; learning methods come in handy. The &lt;strong&gt;Monte Carlo&lt;/strong&gt; algorithms only require an experience sample such as a data set in which the states, actions and rewards
of the (simulated) interaction with the environment. In comparison with DP methods, no model of the &lt;strong&gt;transition probability function&lt;/strong&gt; is required and neither the &lt;strong&gt;dynamics&lt;/strong&gt; of the environment. Monte Carlo algorithms solve the RL problem by &lt;strong&gt;averaging&lt;/strong&gt; sample return of each &lt;strong&gt;episode&lt;/strong&gt;. Only after the termination of an episode, that the value &lt;strong&gt;estimation&lt;/strong&gt; and &lt;strong&gt;policies&lt;/strong&gt; are updated. Hence, it is based on averages of complete returns of the value functions of each state. This class of algorithms does not exploit Markov property described before and is therefore more efficient in &lt;strong&gt;non-Markovian&lt;/strong&gt; environments. On the other hand, &lt;strong&gt;Temporal-Difference methods&lt;/strong&gt; do also not require a model of the environment but are like DP solving for incrementing &lt;strong&gt;step-by-step&lt;/strong&gt; rather than &lt;strong&gt;episode-by-episode&lt;/strong&gt;. Hence, TD methods exploit the &lt;strong&gt;Markovian property&lt;/strong&gt; and perform usually better in Markovian environments.
The choice between these two classes of model-free RL algorithms very much depends on the type of data set available. For continuous processes in which there are no fixed episodic transitions, &lt;strong&gt;Monte Carlo&lt;/strong&gt; methods may not be the optimal solution as they average the return only at the end of each episode. &lt;strong&gt;TD&lt;/strong&gt; algorithms might then be a better solution as they assign a reward incrementally over each state. This allows them to converge faster towards an optimal policy for large data sets with a large number state spaces.&lt;/p&gt;
&lt;h2&gt;Temporal-difference learning: On-policy and off-policy TD control&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;TD&lt;/strong&gt; algorithms comprise two important RL classes of algorithms divided in &lt;strong&gt;Off-Policy&lt;/strong&gt; and &lt;strong&gt;On-Policy&lt;/strong&gt; TD control algorithm classes. The difference between the two lays in the policy that is learned from the simulation or set of experiences (data). &lt;strong&gt;On-Policy TD control&lt;/strong&gt; algorithms are often referred to as &lt;strong&gt;SARSA algorithms&lt;/strong&gt; in which the letters refer to the sequence of State, Action, Reward associated with the state transition, next State, next Action. This sequence is followed in each &lt;strong&gt;time-step&lt;/strong&gt; and is used to update the &lt;strong&gt;action-value&lt;/strong&gt; of these two states according:
&lt;img alt="Eq4" src="/images/eq4.png"&gt;
Here, α represents the step-size parameter which functions as the exponentially moving average parameter. It is especially useful for &lt;strong&gt;non-stationary&lt;/strong&gt; environments for weighting recent rewards more heavily than long-past ones. This could also be illustrated by rearranging the above equation to:
&lt;img alt="Eq5" src="/images/eq5.png"&gt;
If α is a number smaller than one for non-stationary environments which indicates that recent updates weight more than previous ones. This transition happens after every nonterminal state. The Q (st+1 ,at+1 ) components of every terminal state is defined as zero. Hence, every terminal state has an update value of 0. &lt;strong&gt;SARSA&lt;/strong&gt; is called an on-policy algorithm because it updates the &lt;strong&gt;action-value-function&lt;/strong&gt; according to the &lt;strong&gt;policy&lt;/strong&gt; it is taking in every &lt;strong&gt;step&lt;/strong&gt;. Therefore, it takes the epsilon-policy into account in order to arrive the optimal policy for a certain problem. &lt;strong&gt;Off-policy&lt;/strong&gt; algorithms approximate the best possible policy even when that policy is not taken by the agent. Hence, &lt;strong&gt;Off-Policy&lt;/strong&gt; algorithms base the update of the &lt;strong&gt;state action-value&lt;/strong&gt; function on the assumption of &lt;strong&gt;optimal behaviour&lt;/strong&gt; without taking into account the &lt;strong&gt;epsilon policy&lt;/strong&gt; (the chance to take a negative action). The cliff figure shows a suitable example given by Sutton and Barto (1998) and which illustrates the policy outcome differences between the two types of TD algorithms &lt;img alt="Cliff)" src="/images/cliff.png"&gt;. The cliff represents states with high negative reward. Since &lt;strong&gt;SARSA&lt;/strong&gt; takes the &lt;strong&gt;epsilon policy&lt;/strong&gt; into account, it learns that at some instances a non-optimal action will be taken which results in a high negative reward. Hence, it will learn to take the safe path rather than the optimal path. &lt;strong&gt;Q-learning algorithms&lt;/strong&gt; on the other hand, will take the optimal path by which the highest total reward could be achieved. This is because it does not take the &lt;strong&gt;epsilon probability&lt;/strong&gt; into account of taking an extremely negative action. This class of algorithms is denoted by the following equation:
&lt;img alt="Eq6" src="/images/eq6.png"&gt;
This difference will inevitably influence the suitability for the type of application. &lt;/p&gt;
&lt;h1&gt;Markov Decision Processes&lt;/h1&gt;
&lt;p&gt;Markov decision processes formally describe an environment for reinforcement learning Where the environment is fully observable, i.e. The current state completely characterises the process.
&lt;img alt="MDP" src="/images/MDP.png"&gt;
Almost all RL problems can be formalised as MDPs, e.g.Optimal control primarily deals with continuous MDPs, Partially observable problems can be converted into MDPs, Bandits are MDPs with one state
The Markov Property states that "The future is independent of the past given the present” in other ways a state St is Markov if and only if
P [S t+1 | S t ] = P [S t+1 | S 1 , ..., S t ]
The state captures all relevant information from the history and once the state is known, the history may be thrown away. i.e. The state is a sufficient statistic of the future.&lt;/p&gt;
&lt;p&gt;For a Markov state s and successor state s' , the state transition
probability is defined by Pss' = P[St+1 = s'| St = s]. The State transition matrix P defines transition probabilities from all states s to all successor states s' &lt;img alt="State Transition Matrix" src="/images/State_Transition_Matrix.png"&gt;where each row of the matrix sums to 1&lt;/p&gt;
&lt;p&gt;A Markov process is a memoryless random process, i.e. a sequence
of random states S1 , S2 , ... with the Markov property. Otherwise it is a tuple &lt;S,P&gt; with S is a (finite) set of states, P is a state transition probability matrix, Pss'= P [S t+1 = s'| St = s]
&lt;img alt="Example" src="/images/markov_process.png"&gt;&lt;/p&gt;
&lt;p&gt;A Markov reward process is a Markov chain with values.
Definition: A Markov Reward Process is a tuple &lt;S, P, R, γ&gt;
S is a finite set of states
P is a state transition probability matrix,
P ss'= P [St+1 = s'| St = s]
R is a reward function, Rs = E [Rt+1 | St = s]
γ is a discount factor, γ ∈ [0, 1]&lt;/p&gt;
&lt;p&gt;The return Gt is the total discounted reward from time-step t.
G t = Rt+1 + γRt+2 + ...
The discount γ ∈ [0, 1] is the present value of future rewards
The value of receiving reward R after k + 1 time-steps is γkR.
This values immediate reward above delayed reward.
γ close to 0 leads to ”myopic” evaluation
γ close to 1 leads to ”far-sighted” evaluation&lt;/p&gt;
&lt;p&gt;Most Markov reward and decision processes are discounted:
* Mathematically convenient to discount rewards
* Avoids infinite returns in cyclic Markov processes
* Uncertainty about the future may not be fully represented
* If the reward is financial, immediate rewards may earn more
interest than delayed rewards
* Animal/human behaviour shows preference for immediate
reward
* It is sometimes possible to use undiscounted Markov reward
processes (i.e. γ = 1), e.g. if all sequences terminate.&lt;/p&gt;
&lt;p&gt;The value function v (s) gives the long-term value of state s
Definition : The state value function v (s) of an MRP is the expected return
starting from state s v (s) = E [G t | S t = s]
&lt;img alt="Value Function" src="/images/Value_Function.png"&gt;&lt;/p&gt;
&lt;h1&gt;Final Words&lt;/h1&gt;
&lt;p&gt;Reinforcement learning is extremely fun but hard topic. I am excited to learn more!&lt;/p&gt;</content><category term="Deep Learning"></category><category term="Deep Reinforcement Learning"></category></entry><entry><title>Analysing Model Perfromance from Receiver Operator Characteristic and Recall and Precision curves</title><link href="https://mmadkour.xyz%5Cposts/2018/06/Analysing%20Model%20Perfromance%20from%20ROC,%20and%20Recall%20and%20Precision%20curves/" rel="alternate"></link><published>2018-06-09T16:00:00-04:00</published><updated>2018-06-09T16:00:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2018-06-09:/2018/06/Analysing Model Perfromance from ROC, and Recall and Precision curves/</id><summary type="html">&lt;p&gt;ROC and PR curves are commonly used to present results for binary decision problems in machine learning. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. Each point of the ROC curve (i.e. threshold) corresponds to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;ROC and PR curves are commonly used to present results for binary decision problems in machine learning. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. Each point of the ROC curve (i.e. threshold) corresponds to specific values of sensitivity and specificity. The area under the ROC curve (AUC) is a summary measure of performance that indicates whether on average a true positive is ranked higher than a false positives. If model A has higher AUC than model B, model A is performing better on average, but there still could be specific areas of the ROC space where model B is better (i.e. thresholds for which sensitivity and specificity are higher for model B than A. However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more informative picture of an algorithm's performance. There is deep connection between ROC space and PR space, such that a curve dominates in ROC space if  and only if it dominates in PR space. The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision, x-axis, relates to a low false positive rate, and high recall, y-axis, relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).&lt;/p&gt;
&lt;h2&gt;Sensitivity (positive in disease)&lt;/h2&gt;
&lt;p&gt;Sensitivity is the ability of a test to correctly classify an individual as ′diseased′&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Sensitivity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="k"&gt;c&lt;/span&gt;
&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt; &lt;span class="n"&gt;positive&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="k"&gt;c&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt; &lt;span class="n"&gt;positive&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="k"&gt;false&lt;/span&gt; &lt;span class="n"&gt;negative&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Probability&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;being&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="n"&gt;positive&lt;/span&gt; &lt;span class="k"&gt;when&lt;/span&gt; &lt;span class="n"&gt;disease&lt;/span&gt; &lt;span class="n"&gt;present&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Specificity (negative in health)&lt;/h2&gt;
&lt;p&gt;The ability of a test to correctly classify an individual as disease- free is called the test′s specificity&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Specificity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;
&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt; &lt;span class="n"&gt;negative&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt; &lt;span class="n"&gt;negative&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="k"&gt;false&lt;/span&gt; &lt;span class="n"&gt;positive&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Probability&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;being&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="n"&gt;negative&lt;/span&gt; &lt;span class="k"&gt;when&lt;/span&gt; &lt;span class="n"&gt;disease&lt;/span&gt; &lt;span class="n"&gt;absent&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sensitivity and specificity are inversely proportional, meaning that as the sensitivity increases, the specificity decreases and vice versa.&lt;/p&gt;
&lt;h2&gt;Positive Predictive Value (PPV)&lt;/h2&gt;
&lt;p&gt;It is the percentage of patients with a positive test who actually have the disease. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;PPV&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;
&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt; &lt;span class="n"&gt;positive&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt; &lt;span class="n"&gt;positive&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="k"&gt;false&lt;/span&gt; &lt;span class="n"&gt;positive&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Probability&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;patient&lt;/span&gt; &lt;span class="k"&gt;having&lt;/span&gt; &lt;span class="n"&gt;disease&lt;/span&gt; &lt;span class="k"&gt;when&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;positive&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Negative Predictive Value (NPV)&lt;/h2&gt;
&lt;p&gt;It is the percentage of patients with a negative test who do not have the disease.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;NPV&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt;   &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;
&lt;span class="o"&gt;=&lt;/span&gt;   &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt; &lt;span class="n"&gt;negative&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;false&lt;/span&gt; &lt;span class="n"&gt;negative&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="k"&gt;true&lt;/span&gt; &lt;span class="n"&gt;negative&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;=&lt;/span&gt;   &lt;span class="n"&gt;Probability&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;patient&lt;/span&gt; &lt;span class="k"&gt;not&lt;/span&gt; &lt;span class="k"&gt;having&lt;/span&gt; &lt;span class="n"&gt;disease&lt;/span&gt; &lt;span class="k"&gt;when&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;negative&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Positive and negative predictive values are influenced by the prevalence of disease in the population that is being tested. If we  test in a high prevalence setting, it is more likely that persons who test positive truly have disease than if the test is performed in a population with low prevalence. So the PPV will increase with increasing prevalence and NPV decreases with increase in prevalence.&lt;/p&gt;
&lt;h2&gt;Methods to find the ‘optimal’ threshold point&lt;/h2&gt;
&lt;p&gt;Three criteria  are  used to  find  optimal  threshold point  from  ROC  curve.  These criteria are known as points on curve closest to the (0, 1), Youden index, and minimize cost criterion. First two methods give equal weight to sensitivity and specificity and impose no ethical, cost, and no prevalence  constraints.  The  third  criterion  considers  cost  which  mainly  includes financial  cost  for  correct  and  false  diagnosis,  cost  of  discomfort  to  person  caused  by treatment, and cost of further investigation when needed.  This method is rarely used in medical literature because it is difficult to estimate the respective costs and prevalence is often difficult to assess.&lt;/p&gt;
&lt;p&gt;Youden index  is  more  commonly  used  criterion  because  this  index  reflects  the  intension  to maximize the correct classification 
rate and is easy to calculate. It maximizes the vertical distance from line of equality to the point [x, y] as shown in Figure. The x represents (1-specificity) and y represents sensitivity.  In  other  words,  the  Youden  index  J  is  the  point on the ROC  curve  which  is farthest  from  line  of  equality  (diagonal  line).  The  main  aim of  Youden  index  is  to 
maximize the difference between TPR (sensitivity) and FPR (1 –specificty) and little algebra yields J = max[sensitivity+specificty].  The  value  of  J  for  continuous  test  can  be  located  by  doing  a  search  of plausible  values  where  sum  of  sensitivity  and  specificity  can be  maximum:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model_metric&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;thres&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;model_metric&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;yod_index&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;idxmax&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sometimes a second cutoff that is bigger than j but less than 1 is needed. This cutoff can be used to stratify the positively predicted values to moderate and high prediction for example(needed for risk prediction stratification). This cutoff can be calculated using the accuracy measurement using the following method:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cutoff2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cu&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cal_cutoff2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model_metric&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;with&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;cal_cutoff2&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;val&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;range&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="ss"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;abs&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;data&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;acc&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;].&lt;span class="nv"&gt;iloc&lt;/span&gt;[&lt;span class="nv"&gt;i&lt;/span&gt;]&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;data&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;acc&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;].&lt;span class="nv"&gt;iloc&lt;/span&gt;[&lt;span class="nv"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;]&lt;span class="ss"&gt;))&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;002&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
        &lt;span class="nv"&gt;val&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;data&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;thres&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;].&lt;span class="nv"&gt;iloc&lt;/span&gt;[&lt;span class="nv"&gt;i&lt;/span&gt;]
        &lt;span class="k"&gt;break&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;val&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The chart bellow illustrates the relationship between the different performance metrics ( prevalence is exluded) in an example of 4 estimators apllied on 4 -classes data&lt;img alt=" PPV and NPV  relationship" src="/images/NPV-PPV-Accracy-Youden.png"&gt;&lt;/p&gt;
&lt;h1&gt;Calculation of performance metrics&lt;/h1&gt;
&lt;p&gt;Here is the python code for the calculation of  performance metrics &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;calculate_metric&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;outcome&lt;/span&gt;, &lt;span class="nv"&gt;score&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;obser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;outcome&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;obser&lt;/span&gt;[[&lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt;, &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;enumerate&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;outcome&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; ]] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="c1"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;obser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; [&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;obser&lt;/span&gt;]
    &lt;span class="nv"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; [&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;score&lt;/span&gt;]
    &lt;span class="nv"&gt;prev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;obser&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;obser&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;,&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;thres&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;arange&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;01&lt;/span&gt;,&lt;span class="mi"&gt;1&lt;/span&gt;.&lt;span class="mi"&gt;01&lt;/span&gt;,&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;01&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;#&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;01&lt;/span&gt;,&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;98&lt;/span&gt;,&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;01&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;xval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;thres&lt;/span&gt;
    &lt;span class="nv"&gt;acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;ppv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;npv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;sen&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;spe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;yod&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;auc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;F1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt; 
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;l&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;range&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;:
        &lt;span class="nv"&gt;plotdata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;ROC_parameters&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;obser&lt;/span&gt;,&lt;span class="nv"&gt;score&lt;/span&gt;,&lt;span class="nv"&gt;thres&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;]&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;acc&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;plotdata&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;],&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;ppv&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;plotdata&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;],&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;npv&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;plotdata&lt;/span&gt;[&lt;span class="mi"&gt;2&lt;/span&gt;],&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;sen&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;plotdata&lt;/span&gt;[&lt;span class="mi"&gt;3&lt;/span&gt;],&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;spe&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;plotdata&lt;/span&gt;[&lt;span class="mi"&gt;4&lt;/span&gt;],&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;yod&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;plotdata&lt;/span&gt;[&lt;span class="mi"&gt;5&lt;/span&gt;],&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;recall&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;plotdata&lt;/span&gt;[&lt;span class="mi"&gt;6&lt;/span&gt;],&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;precision&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;plotdata&lt;/span&gt;[&lt;span class="mi"&gt;7&lt;/span&gt;],&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;F1&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;plotdata&lt;/span&gt;[&lt;span class="mi"&gt;8&lt;/span&gt;],&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
        &lt;span class="nv"&gt;auc&lt;/span&gt;[&lt;span class="nv"&gt;l&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;roc_auc_score&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;obser&lt;/span&gt;, &lt;span class="nv"&gt;score&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;prev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;round&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;obser&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;obser&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;,&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    #&lt;span class="nv"&gt;roc_vals&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;length&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;spe&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;,&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;DataFrame&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;range&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;,&lt;span class="mi"&gt;101&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;, &lt;span class="nv"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;[[&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;thres&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;acc&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;ppv&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;npv&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;specificity&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;sensitivity&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;yod_index&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;recall&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;precision&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;F1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;auc&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;]]&lt;span class="ss"&gt;)&lt;/span&gt;
    #&lt;span class="nv"&gt;roc_vals&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nv"&gt;dacolnames&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;roc_vals&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nv"&gt;c&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;thres&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;acc&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;ppv&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;npv&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;specificity&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;sensitivity&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;yod_index&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;auc&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;thres&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;]&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;thres&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;acc&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;]&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;acc&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;ppv&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;ppv&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;npv&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;npv&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;specificity&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;spe&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;sensitivity&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;sen&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;yod_index&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;yod&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;recall&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;recall&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;precision&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;precision&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;F1&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;F1&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;roc_vals&lt;/span&gt;[&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="s"&gt;auc&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;auc&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;roc_vals&lt;/span&gt;

&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;ROC_parameters&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;obser&lt;/span&gt;,&lt;span class="nv"&gt;score&lt;/span&gt;,&lt;span class="nv"&gt;thr&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    #&lt;span class="nv"&gt;print&lt;/span&gt; &lt;span class="nv"&gt;obser&lt;/span&gt;,&lt;span class="nv"&gt;score&lt;/span&gt;,&lt;span class="nv"&gt;thr&lt;/span&gt;
    &lt;span class="nv"&gt;temp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;zeros&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;score&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    #&lt;span class="nv"&gt;print&lt;/span&gt; &lt;span class="nv"&gt;thr&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;temp&lt;/span&gt;[[ &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt;, &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;enumerate&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;score&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="nv"&gt;thr&lt;/span&gt; ]]&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="nv"&gt;p_ind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;[ &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt;, &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;enumerate&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;obser&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; ]
    &lt;span class="nv"&gt;n_ind&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; [ &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt;, &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;enumerate&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;obser&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; ]
    &lt;span class="nv"&gt;TP&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;temp&lt;/span&gt;[&lt;span class="nv"&gt;p_ind&lt;/span&gt;]&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;FP&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;temp&lt;/span&gt;[&lt;span class="nv"&gt;n_ind&lt;/span&gt;]&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;TN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;temp&lt;/span&gt;[&lt;span class="nv"&gt;n_ind&lt;/span&gt;]&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;FN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;temp&lt;/span&gt;[&lt;span class="nv"&gt;p_ind&lt;/span&gt;]&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;)(&lt;/span&gt;&lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;TN&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;temp&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;recall&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="nv"&gt;precision&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
    #&lt;span class="nv"&gt;print&lt;/span&gt; &lt;span class="nv"&gt;TP&lt;/span&gt;,&lt;span class="nv"&gt;FP&lt;/span&gt;,&lt;span class="nv"&gt;TN&lt;/span&gt;,&lt;span class="nv"&gt;FN&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FP&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;:
        &lt;span class="nv"&gt;ppv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;)(&lt;/span&gt;&lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FP&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;:
        &lt;span class="nv"&gt;ppv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;NaN&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;TN&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FN&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;:
        &lt;span class="nv"&gt;npv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;)(&lt;/span&gt;&lt;span class="nv"&gt;TN&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;TN&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FN&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;:
        &lt;span class="nv"&gt;npv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;NaN&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FN&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;:
        &lt;span class="nv"&gt;sen&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;)(&lt;/span&gt;&lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FN&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;:
        &lt;span class="nv"&gt;sen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;NaN&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;TN&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FP&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;:
        &lt;span class="nv"&gt;spe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;)(&lt;/span&gt;&lt;span class="nv"&gt;TN&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;TN&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FP&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;:
        &lt;span class="nv"&gt;spe&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;NaN&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FN&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;:
        &lt;span class="nv"&gt;recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;)(&lt;/span&gt;&lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FN&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;:
        &lt;span class="nv"&gt;recall&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;NaN&lt;/span&gt;    
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FP&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;:
        &lt;span class="nv"&gt;precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;)(&lt;/span&gt;&lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;TP&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;FP&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;:
        &lt;span class="nv"&gt;precision&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;NaN&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;recall&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;precision&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;:         
        &lt;span class="nv"&gt;F1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;)((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nv"&gt;recall&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nv"&gt;precision&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;recall&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;precision&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;:
        &lt;span class="nv"&gt;F1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;NaN&lt;/span&gt;
    &lt;span class="nv"&gt;yod&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="ss"&gt;)(&lt;/span&gt;&lt;span class="nv"&gt;sen&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nv"&gt;spe&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;list&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;ppv&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;npv&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;sen&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;spe&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;yod&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;recall&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;precision&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;ls&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;F1&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;ls&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;calculating performance measurements and confidence intervals using Boostraping&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;calculate_metric_boostrap&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;outcome&lt;/span&gt;, &lt;span class="nv"&gt;score&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; []
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;p&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;range&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;,&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;score&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;:
        &lt;span class="nv"&gt;d&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;score&lt;/span&gt;[&lt;span class="nv"&gt;p&lt;/span&gt;]&lt;span class="ss"&gt;))&lt;/span&gt;
    &lt;span class="nv"&gt;score&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;Series&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;d&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;n_bootstraps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="nv"&gt;rng_seed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;42&lt;/span&gt;  # &lt;span class="nv"&gt;control&lt;/span&gt; &lt;span class="nv"&gt;reproducibility&lt;/span&gt;
    &lt;span class="nv"&gt;scores_table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; {} 
    &lt;span class="nv"&gt;rng&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="k"&gt;random&lt;/span&gt;.&lt;span class="nv"&gt;RandomState&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;rng_seed&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;range&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;n_bootstraps&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    # &lt;span class="nv"&gt;bootstrap&lt;/span&gt; &lt;span class="nv"&gt;by&lt;/span&gt; &lt;span class="nv"&gt;sampling&lt;/span&gt; &lt;span class="nv"&gt;with&lt;/span&gt; &lt;span class="nv"&gt;replacement&lt;/span&gt; &lt;span class="nv"&gt;on&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;prediction&lt;/span&gt; &lt;span class="nv"&gt;indices&lt;/span&gt;
        &lt;span class="nv"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;rng&lt;/span&gt;.&lt;span class="nv"&gt;random_integers&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;outcome&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;outcome&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;unique&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;outcome&lt;/span&gt;[&lt;span class="nv"&gt;indices&lt;/span&gt;]&lt;span class="ss"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;:
        # &lt;span class="nv"&gt;We&lt;/span&gt; &lt;span class="nv"&gt;need&lt;/span&gt; &lt;span class="nv"&gt;at&lt;/span&gt; &lt;span class="nv"&gt;least&lt;/span&gt; &lt;span class="nv"&gt;one&lt;/span&gt; &lt;span class="nv"&gt;positive&lt;/span&gt; &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;one&lt;/span&gt; &lt;span class="nv"&gt;negative&lt;/span&gt; &lt;span class="nv"&gt;sample&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;ROC&lt;/span&gt; &lt;span class="nv"&gt;AUC&lt;/span&gt;
        # &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;be&lt;/span&gt; &lt;span class="nv"&gt;defined&lt;/span&gt;: &lt;span class="nv"&gt;reject&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;sample&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;
        &lt;span class="nv"&gt;scores_table&lt;/span&gt;[&lt;span class="nv"&gt;i&lt;/span&gt;]&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;calculate_metric&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;outcome&lt;/span&gt;[&lt;span class="nv"&gt;indices&lt;/span&gt;], &lt;span class="nv"&gt;score&lt;/span&gt;[&lt;span class="nv"&gt;indices&lt;/span&gt;]&lt;span class="ss"&gt;)&lt;/span&gt;

    &lt;span class="nv"&gt;panel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;pd&lt;/span&gt;.&lt;span class="nv"&gt;Panel&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;scores_table&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;df&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;panel&lt;/span&gt;.&lt;span class="nv"&gt;mean&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;df&lt;/span&gt;,&lt;span class="nv"&gt;panel&lt;/span&gt;

&lt;span class="nv"&gt;def&lt;/span&gt; &lt;span class="nv"&gt;confidence_interval&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;panel&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;vector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; []
    &lt;span class="nv"&gt;confidence_lower&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;panel&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;].&lt;span class="nv"&gt;copy&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;
    &lt;span class="nv"&gt;confidence_upper&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;panel&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;].&lt;span class="nv"&gt;copy&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;
    &lt;span class="nv"&gt;nr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;panel&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;].&lt;span class="nv"&gt;axes&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;]&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;nc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;panel&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;].&lt;span class="nv"&gt;axes&lt;/span&gt;[&lt;span class="mi"&gt;1&lt;/span&gt;]&lt;span class="ss"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;ix&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt;  &lt;span class="nv"&gt;range&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;,&lt;span class="nv"&gt;nr&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;iy&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;range&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;,&lt;span class="nv"&gt;nc&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
            &lt;span class="nv"&gt;vector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; []
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;k&lt;/span&gt;, &lt;span class="nv"&gt;df&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;panel&lt;/span&gt;.&lt;span class="nv"&gt;iteritems&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;:
                &lt;span class="nv"&gt;vector&lt;/span&gt;.&lt;span class="nv"&gt;append&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;df&lt;/span&gt;.&lt;span class="nv"&gt;iloc&lt;/span&gt;[&lt;span class="nv"&gt;ix&lt;/span&gt;,&lt;span class="nv"&gt;iy&lt;/span&gt;]&lt;span class="ss"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;sorted_vector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;array&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;vector&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
            &lt;span class="nv"&gt;sorted_vector&lt;/span&gt;.&lt;span class="nv"&gt;sort&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;
            &lt;span class="nv"&gt;confidence_lower&lt;/span&gt;.&lt;span class="nv"&gt;iloc&lt;/span&gt;[&lt;span class="nv"&gt;ix&lt;/span&gt;,&lt;span class="nv"&gt;iy&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;sorted_vector&lt;/span&gt;[&lt;span class="nv"&gt;int&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;05&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;sorted_vector&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;]
            &lt;span class="nv"&gt;confidence_upper&lt;/span&gt;.&lt;span class="nv"&gt;iloc&lt;/span&gt;[&lt;span class="nv"&gt;ix&lt;/span&gt;,&lt;span class="nv"&gt;iy&lt;/span&gt;] &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;sorted_vector&lt;/span&gt;[&lt;span class="nv"&gt;int&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;95&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nv"&gt;len&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;sorted_vector&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;]
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nv"&gt;confidence_lower&lt;/span&gt;, &lt;span class="nv"&gt;confidence_upper&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The chart bellow illustrates ROC and PR curves for 4 different estimators applied on the same data&lt;img alt=" ROC" src="/images/ROC-PV1.png"&gt;&lt;img alt=" PR" src="/images/ROC-PV2.png"&gt;
The performances of the algorithms appear to be comparable in ROC space, however, in PR space we can see that Estimator 4 has a clear advantage over Estimator 3.&lt;/p&gt;
&lt;h1&gt;Assessing the Model&lt;/h1&gt;
&lt;p&gt;The chart bellow outlines the performance evaluation pipeline (except prevalence) in an example&lt;img alt=" performance evaluation pipeline" src="/images/MLPipe.jpg"&gt;&lt;/p&gt;
&lt;h1&gt;The bias-variance trade-off (Bias-variance dilemma)&lt;/h1&gt;
&lt;p&gt;Bias and variance are inherent properties of estimators and we usually have to select learning algorithms and hyperparameters so that both bias and variance are as low as possible. Another way to reduce the variance of a model is to use more training data. However, you should only collect more training data if the true function is too complex to be approximated by an estimator with a lower variance.
&lt;img alt=" bias-variance trade-off" src="/images/biasvariance.png"&gt;&lt;/p&gt;
&lt;h1&gt;Analyzing Model Variance and Bias&lt;/h1&gt;
&lt;p&gt;The two methods used here for analyzing how the model is performing with the data are Learning Curves and a Model Complexity plot.Learning curves give us an opportunity to diagnose bias and variance in supervised learning models. &lt;/p&gt;
&lt;h2&gt;Learning Curves&lt;/h2&gt;
&lt;p&gt;A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a &lt;strong&gt;variance error&lt;/strong&gt; or a &lt;strong&gt;bias error&lt;/strong&gt;. If both the validation score and the training score converge to a value that is &lt;strong&gt;too low&lt;/strong&gt; with increasing size of the training set, we will not benefit much from more training data. In the following plot you can see an example: naive Bayes roughly converges to a low score.
We will probably have to &lt;strong&gt;use an estimator&lt;/strong&gt; or a &lt;strong&gt;parametrization of the current estimator&lt;/strong&gt; that can learn more &lt;strong&gt;complex concepts&lt;/strong&gt; (i.e. has a lower bias). If the training score is much greater than the validation score for the maximum number of training samples (&lt;strong&gt;i.e. has a high variance&lt;/strong&gt;), adding more training samples will most likely increase generalization. In the following plot you can see that the SVM could benefit from more training examples.&lt;/p&gt;
&lt;h1&gt;Example of Scoring Learners and Cohort&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Cohort Definition&lt;/th&gt;
&lt;th&gt;Cohort Size&lt;/th&gt;
&lt;th&gt;CVD Percent in Cohort&lt;/th&gt;
&lt;th&gt;Covariates in Learner/Model&lt;/th&gt;
&lt;th&gt;Method Type&lt;/th&gt;
&lt;th&gt;Method Sensitivity&lt;/th&gt;
&lt;th&gt;Method PPV&lt;/th&gt;
&lt;th&gt;Balanced Accuracy&lt;/th&gt;
&lt;th&gt;Method Accuracy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ALL OF THEM (don't emulate&lt;/td&gt;
&lt;td&gt;369000&lt;/td&gt;
&lt;td&gt;0.80%&lt;/td&gt;
&lt;td&gt;"bmi&lt;/td&gt;
&lt;td&gt;numAge&lt;/td&gt;
&lt;td&gt;tchol&lt;/td&gt;
&lt;td&gt;sbp&lt;/td&gt;
&lt;td&gt;htn&lt;/td&gt;
&lt;td&gt;t2d"&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Age &amp;gt; 55&lt;/td&gt;
&lt;td&gt;122792&lt;/td&gt;
&lt;td&gt;22.60%&lt;/td&gt;
&lt;td&gt;"numAge&lt;/td&gt;
&lt;td&gt;tchol&lt;/td&gt;
&lt;td&gt;htn&lt;/td&gt;
&lt;td&gt;gender"&lt;/td&gt;
&lt;td&gt;Logit&lt;/td&gt;
&lt;td&gt;0.16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Age 20-40&lt;/td&gt;
&lt;td&gt;121130&lt;/td&gt;
&lt;td&gt;0.02%&lt;/td&gt;
&lt;td&gt;"tchol&lt;/td&gt;
&lt;td&gt;t2d&lt;/td&gt;
&lt;td&gt;smoking&lt;/td&gt;
&lt;td&gt;race"&lt;/td&gt;
&lt;td&gt;LDA&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;"htn == ""Y"""&lt;/td&gt;
&lt;td&gt;108510&lt;/td&gt;
&lt;td&gt;18.85%&lt;/td&gt;
&lt;td&gt;smoking&lt;/td&gt;
&lt;td&gt;Logit&lt;/td&gt;
&lt;td&gt;"""NA"""&lt;/td&gt;
&lt;td&gt;"""NA"""&lt;/td&gt;
&lt;td&gt;"""NA"" (is this weird?)"&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;"gender == ""F"" &amp;amp; numAge &amp;gt; 60"&lt;/td&gt;
&lt;td&gt;53929&lt;/td&gt;
&lt;td&gt;14.30%&lt;/td&gt;
&lt;td&gt;"tchol&lt;/td&gt;
&lt;td&gt;htn"&lt;/td&gt;
&lt;td&gt;Logit&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;NaN&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Age 30-45&lt;/td&gt;
&lt;td&gt;99930&lt;/td&gt;
&lt;td&gt;"numAge&lt;/td&gt;
&lt;td&gt;race&lt;/td&gt;
&lt;td&gt;htn&lt;/td&gt;
&lt;td&gt;gender&lt;/td&gt;
&lt;td&gt;smoking"&lt;/td&gt;
&lt;td&gt;Logit&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Age &amp;lt;= 40&lt;/td&gt;
&lt;td&gt;93980 train; 93981 test&lt;/td&gt;
&lt;td&gt;1.64%&lt;/td&gt;
&lt;td&gt;"numAge&lt;/td&gt;
&lt;td&gt;htn&lt;/td&gt;
&lt;td&gt;smoking&lt;/td&gt;
&lt;td&gt;treat&lt;/td&gt;
&lt;td&gt;t2d&lt;/td&gt;
&lt;td&gt;gender&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;"gender == ""M"" &amp;amp; numAge &amp;gt; 60"&lt;/td&gt;
&lt;td&gt;36853&lt;/td&gt;
&lt;td&gt;30.75%&lt;/td&gt;
&lt;td&gt;"tchol&lt;/td&gt;
&lt;td&gt;htn"&lt;/td&gt;
&lt;td&gt;Logit&lt;/td&gt;
&lt;td&gt;0.28&lt;/td&gt;
&lt;td&gt;0.51&lt;/td&gt;
&lt;td&gt;0.58&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GENETICS&lt;/td&gt;
&lt;td&gt;66100&lt;/td&gt;
&lt;td&gt;2.40%&lt;/td&gt;
&lt;td&gt;"tchol&lt;/td&gt;
&lt;td&gt;rs8055236&lt;/td&gt;
&lt;td&gt;htn&lt;/td&gt;
&lt;td&gt;t2d&lt;/td&gt;
&lt;td&gt;smoking"&lt;/td&gt;
&lt;td&gt;lda&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;age &amp;lt; 55 &amp;amp; age &amp;gt; 35&lt;/td&gt;
&lt;td&gt;379272&lt;/td&gt;
&lt;td&gt;5.30%&lt;/td&gt;
&lt;td&gt;cvd ~ tchol + htn + t2d + bmi + rs8055236&lt;/td&gt;
&lt;td&gt;logit&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;nan&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;age&amp;gt;55&lt;/td&gt;
&lt;td&gt;logit&lt;/td&gt;
&lt;td&gt;0.22&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.6&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GENETICS&lt;/td&gt;
&lt;td&gt;46217 train; 8157 test&lt;/td&gt;
&lt;td&gt;9.78%&lt;/td&gt;
&lt;td&gt;"cvd ~ numAge + htn + smoking&lt;/td&gt;
&lt;td&gt;+ treat + t2d + gender + bmi + tchol + sbp + rs10757278 + rs4665058 + rs8055236"&lt;/td&gt;
&lt;td&gt;SuperLearner&lt;/td&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;td&gt;0.369&lt;/td&gt;
&lt;td&gt;0.8394&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</content><category term="Statistical Analysis"></category><category term="ROC"></category><category term="AUROC"></category><category term="AUCPR"></category><category term="F1 Score"></category><category term="Recall"></category><category term="Precision"></category></entry><entry><title>Building Machine Learning models with Imbalanced data</title><link href="https://mmadkour.xyz%5Cposts/2017/10/Learning%20from%20unbalanced%20data/" rel="alternate"></link><published>2017-10-09T12:00:00-04:00</published><updated>2017-10-09T12:00:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2017-10-09:/2017/10/Learning from unbalanced data/</id><summary type="html">&lt;p&gt;In this blog post, I'll discuss a number of considerations and techniques for dealing with imbalanced data when training a machine learning model. The blog post will rely heavily on a sklearn contributor package called &lt;a href="https://imbalanced-learn.org/en/stable/index.html"&gt;imbalanced-learn&lt;/a&gt; to implement the discussed techniques.
Training a machine learning model on an imbalanced dataset …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this blog post, I'll discuss a number of considerations and techniques for dealing with imbalanced data when training a machine learning model. The blog post will rely heavily on a sklearn contributor package called &lt;a href="https://imbalanced-learn.org/en/stable/index.html"&gt;imbalanced-learn&lt;/a&gt; to implement the discussed techniques.
Training a machine learning model on an imbalanced dataset can introduce unique challenges to the learning problem. Imbalanced data typically refers to a classification problem where the number of observations per class is not equally distributed; often you'll have a large amount of data/observations for one class (referred to as the majority class), and much fewer observations for one or more other classes (referred to as the minority classes). For example, suppose you're building a classifier to classify a credit card transaction a fraudulent or authentic - you'll likely have 10,000 authentic transactions for every 1 fraudulent transaction, that's quite an imbalance!
To understand the challenges that a class imbalance imposes, let's consider two common ways we'll train a model: tree-based logical rules developed according to some splitting criterion, and parameterized models updated by gradient descent.
When building a tree-based model (such as a decision tree), our objective is to find logical rules which are capable of taking the full dataset and separating out the observations into their different classes. In other words, we'd like each split in the tree to increase the purity of observations such that the data is filtered into homogeneous groups. If we have a majority class present, the top of the decision tree is likely to learn splits which separate out the majority class into pure groups at the expense of learning rules which separate the minority class.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="majority minority class" src="/images/ImbalancedData/Screen-Shot-2018-02-12-at-10.06.36-PM.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For a more concrete example, here's a decision tree trained on the wine quality dataset used as an example later on in this post. The field value represents the number of observations for each class in a given node.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Tree" src="/images/ImbalancedData/download-1.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Similarly, if we're updating a parameterized model by gradient descent to minimize our loss function, we'll be spending most of our updates changing the parameter values in the direction which allow for correct classification of the majority class. In other words, many machine learning models are subject to a frequency bias in which they place more emphasis on learning from data observations which occur more commonly.&lt;/p&gt;
&lt;p&gt;It's worth noting that not all datasets are affected equally by class imbalance. Generally, for easy classification problems in which there's a clear separation in the data, class imbalance doesn't impede on the model's ability to learn effectively. However, datasets that are inherently more difficult to learn from see an amplification in the learning challenge when a class imbalance is introduced.&lt;/p&gt;
&lt;h1&gt;Metrics&lt;/h1&gt;
&lt;p&gt;When dealing with imbalanced data, standard classification metrics do not adequately represent your models performance. For example, suppose you are building a model which will look at a person's medical records and classify whether or not they are likely to have a rare disease. An accuracy of 99.5% might look great until you realize that it is correctly classifying the 99.5% of healthy people as "disease-free" and incorrectly classifying the 0.5% of people which do have the disease as healthy. I discussed this in my post on evaluating a machine learning model, but I'll provide a discussion here as well regarding useful metrics when dealing with imbalanced data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Precision&lt;/strong&gt; is defined as the fraction of relevant examples (true positives) among all of the examples which were predicted to belong in a certain class.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Precision" src="/images/ImbalancedData/M1.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Recall&lt;/strong&gt; is defined as the fraction of examples which were predicted to belong to a class with respect to all of the examples that truly belong in the class.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Recall" src="/images/ImbalancedData/M2.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The following graphic does a phenomenal job visualizing the difference between precision and recall.
&lt;div style="text-align:center" markdown="1"&gt;
&lt;img alt="the difference between precision and recall" src="/images/ImbalancedData/Precisionrecall.svg.png"&gt;
&lt;/div&gt;
&lt;a href="https://en.wikipedia.org/wiki/Precision_and_recall"&gt;Image credit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We can further combine these two metrics into a single value by calcuating the f-score as defined below.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Recall" src="/images/ImbalancedData/M3.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The β parameter allows us to control the tradeoff of importance between precision and recall. β&amp;lt;1 focuses more on precision while β&amp;gt;1&lt;/p&gt;
&lt;p&gt;focuses more on recall.&lt;/p&gt;
&lt;p&gt;Another common tool used to understand a model's performance is a Receiver Operating Characteristics (ROC) curve. An ROC curve visualizes an algorithm's ability to discriminate the positive class from the rest of the data. We'll do this by plotting the True Positive Rate against the False Positive Rate for varying prediction thresholds.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="TPR" src="/images/ImbalancedData/M4.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="FPR" src="/images/ImbalancedData/M5.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For classifiers which only produce factor outcomes (ie. directly output a class), there exists a fixed TPR and FPR for a trained model. However, other classifiers, such as logistic regression, are capable of giving a probabilistic output (ie. the chance that a given observation belongs to the positive class). For these classifiers, we can specify the probability threshold by which above that amount we'll predict the observation belongs to the positive class.
&lt;div style="text-align:center" markdown="1"&gt;
&lt;img alt="ROC" src="/images/ImbalancedData/Screen-Shot-2018-02-15-at-12.41.38-PM.png"&gt;
&lt;/div&gt;
[Image credit] (https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and [Image credit] (https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py)&lt;/p&gt;
&lt;p&gt;If we set a very low value for this probability threshold, we can increase our True Positive Rate as we'll be more likely to capture all of the positive observations. However, this can also introduce a number of false positive classifications, increasing our False Positive Rate. Intuitively, there exists a tradeoff between maximizing our True Positive Rate and minimizing our False Positive Rate. The ideal model would correctly identify all positive observations as belonging to the positive class (TPR=1) and would not incorrectly classify negative observations as belonging to the positive class (FPR=0).
&lt;div style="text-align:center" markdown="1"&gt;
&lt;img alt="tradeoff between maximizing our True Positive Rate and minimizing our False Positive Rate" src="/images/ImbalancedData/roc_cutoff-1.gif"&gt;
&lt;/div&gt;
This tradeoff can be visualized in this &lt;a href="http://www.navan.name/roc/"&gt;demonstration&lt;/a&gt; in which you can adjust the class distributions and classification threshold.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;area under the curve (AUC)&lt;/strong&gt; is a single-value metric for which attempts to summarize an ROC curve to evaluate the quality of a classifier. As the name implies, this metric approximates the area under the ROC curve for a given classifier. Recall that the ideal curve hugs the upper lefthand corner as closely as possible, giving us the ability to identify all true positives while avoiding false positives; this ideal model would have an AUC of 1. On the flipside, if your model was no better than a random guess, your TPR and FPR would increase in parallel to one another, corresponding with an AUC of 0.5.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;roc_auc_score&lt;/span&gt;
&lt;span class="n"&gt;preds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thresholds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;preds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pos_label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;auc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_auc_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;preds&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fpr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tpr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;navy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;--&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;random&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;AUC: {auc}&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;False positive rate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;True positive rate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Class weight&lt;/h1&gt;
&lt;p&gt;One of the simplest ways to address the class imbalance is to simply provide a weight for each class which places more emphasis on the minority classes such that the end result is a classifier which can learn equally from all classes.
To calculate the proper weights for each class, you can use the sklearn utility function shown in the example below.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.utils.class_weight&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;compute_class_weight&lt;/span&gt;
&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;compute_class_weight&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;balanced&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In a tree-based model where you're determining the optimal split according to some measure such as decreased entropy, you can simply scale the entropy component of each class by the corresponding weight such that you place more emphasis on the minority classes. As a reminder, the entropy of a node can be calculated as&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="eq" src="/images/ImbalancedData/M6.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;where pi is the fraction of data points within class i.&lt;/p&gt;
&lt;p&gt;In a gradient-based model, you can scale the calculated loss for each observation by the appropriate class weight such that you place more significance on the losses associated with minority classes. As a reminder, a common loss function for classification is the categorical cross entropy (which is very similar to the above equation, albeit with slight differences). This may be calculated as&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="eq" src="/images/ImbalancedData/M7.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;where yi represents the true class (typically a one-hot encoded vector) and y^i represents the predicted class distribution.&lt;/p&gt;
&lt;h1&gt;Oversampling&lt;/h1&gt;
&lt;p&gt;Another approach towards dealing with a class imbalance is to simply alter the dataset to remove such an imbalance. In this section, I'll discuss common techniques for oversampling the minority classes to increase the number of minority observations until we've reached a balanced dataset.&lt;/p&gt;
&lt;h2&gt;Random oversampling&lt;/h2&gt;
&lt;p&gt;The most naive method of oversampling is to randomly sample the minority classes and simply duplicate the sampled observations. With this technique, it's important to note that you're artificially reducing the variance of the dataset.&lt;/p&gt;
&lt;h2&gt;SMOTE&lt;/h2&gt;
&lt;p&gt;However, we can also use our existing dataset to synthetically generate new data points for the minority classes. Synthetic Minority Over-sampling Technique (SMOTE) is a technique that generates new observations by interpolating between observations in the original dataset.&lt;/p&gt;
&lt;p&gt;For a given observation x_i, a new (synthetic) observation is generated by interpolating between one of the k-nearest neighbors, x_zi.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="eq" src="/images/ImbalancedData/M9.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;where λ is a random number in the range [0,1]. This interpolation will create a sample on the line between xixi and x_zi.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="eq" src="/images/ImbalancedData/sphx_glr_plot_illustration_generation_sample_001.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href="http://contrib.scikit-learn.org/imbalanced-learn/stable/_images/sphx_glr_plot_illustration_generation_sample_0011.png"&gt;Image credit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This algorithm has three options for selecting which observations, xixi, to use in generating new data points.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;regular: No selection rules, randomly sample all possible xixi.&lt;/li&gt;
&lt;li&gt;borderline: Separates all possible xixi into three classes using the k nearest neighbors of each point.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;noise&lt;/em&gt;: all nearest-neighbors are from a different class than xixi&lt;/li&gt;
&lt;li&gt;&lt;em&gt;in danger&lt;/em&gt;: at least half of the nearest neighbors are of the same class as xixi&lt;/li&gt;
&lt;li&gt;&lt;em&gt;safe&lt;/em&gt;: all nearest neighbors are from the same class as xixi&lt;/li&gt;
&lt;li&gt;svm: Uses an SVM classifier to identify the support vectors (samples close to the decision boundary) and samples xixi from these points.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;ADASYN&lt;/h2&gt;
&lt;p&gt;Adaptive Synthetic (ADASYN) sampling works in a similar manner as SMOTE, however, the number of samples generated for a given xixi is proportional to the number of nearby samples which  &lt;strong&gt;do not&lt;/strong&gt;  belong to the same class as xixi. Thus, ADASYN tends to focus solely on outliers when generating new synthetic training examples.&lt;/p&gt;
&lt;h1&gt;Undersampling&lt;/h1&gt;
&lt;p&gt;Rather than oversampling the minority classes, it&amp;#39;s also possible to achieve class balance by &lt;em&gt;undersampling&lt;/em&gt; the majority class - essentially throwing away data to make it easier to learn characteristics about the minority classes.&lt;/p&gt;
&lt;h2&gt;Random undersampling&lt;/h2&gt;
&lt;p&gt;As with oversampling, a naive implementation would be to simply sample the majority class at random until reaching a similar number of observations as the minority classes. For example, if your majority class has 1,000 observations and you have a minority class with 20 observations, you would collect your training data for the majority class by randomly sampling 20 observations from the original 1,000. As you might expect, this could potentially result in removing key characteristics of the majority class.&lt;/p&gt;
&lt;h2&gt;Near miss&lt;/h2&gt;
&lt;p&gt;The general idea behind near miss is to only the sample the points from the majority class necessary to distinguish between other classes.&lt;/p&gt;
&lt;h3&gt;NearMiss-1&lt;/h3&gt;
&lt;p&gt;select samples from the majority class for which the average distance of the N &lt;em&gt;closest&lt;/em&gt; samples of a minority class is smallest.&lt;/p&gt;
&lt;p&gt;&lt;div style="text-align:center" markdown="1"&gt;
&lt;img alt="eq" src="/images/ImbalancedData/sphx_glr_plot_illustration_nearmiss_0011_2.png"&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;h3&gt;NearMiss-2&lt;/h3&gt;
&lt;p&gt;select samples from the majority class for which the average distance of the N &lt;em&gt;farthest&lt;/em&gt; samples of a minority class is smallest.&lt;/p&gt;
&lt;p&gt;&lt;div style="text-align:center" markdown="1"&gt;
&lt;img alt="eq" src="/images/ImbalancedData/sphx_glr_plot_illustration_nearmiss_0021_3.png"&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;h2&gt;Tomeks links&lt;/h2&gt;
&lt;p&gt;A Tomek’s link is defined as two observations of different classes (x and y) such that there is no example z for which:&lt;/p&gt;
&lt;p&gt;&lt;div style="text-align:center" markdown="1"&gt;
&lt;img alt="eq" src="/images/ImbalancedData/M10.png"&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;where d() is the distance between the two samples. In other words, a Tomek’s link exists if two observations of different classes are the nearest neighbors of each other. In the figure below, a Tomek’s link is illustrated by highlighting the samples of interest in green.&lt;/p&gt;
&lt;p&gt;&lt;div style="text-align:center" markdown="1"&gt;
&lt;img alt="eq" src="/images/ImbalancedData/tomeks.png"&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;For this undersampling strategy, we'll remove any observations from the majority class for which a Tomek's link is identified. Depending on the dataset, this technique won't actually achieve a balance among the classes - it will simply "clean" the dataset by removing some noisy observations, which may result in an easier classification problem. As I discussed earlier, most classifiers will still perform adequately for imbalanced datasets as long as there's a clear separation between the classifiers. Thus, by focusing on removing noisy examples of the majority class, we can improve the performance of our classifier even if we don't necessarily balance the classes.&lt;/p&gt;
&lt;h2&gt;Edited nearest neighbors&lt;/h2&gt;
&lt;p&gt;EditedNearestNeighbours applies a nearest-neighbors algorithm and “edit” the dataset by removing samples which do not agree “enough” with their neighboorhood. For each sample in the class to be under-sampled, the nearest-neighbours are computed and if the selection criterion is not fulfilled, the sample is removed.&lt;/p&gt;
&lt;p&gt;This is a similar approach as Tomek's links in the respect that we're not necessarily focused on actually achieving a class balance, we're simply looking to remove noisy observations in an attempt to make for an easier classification problem.&lt;/p&gt;
&lt;h1&gt;HandsOn Notebook:&lt;/h1&gt;
&lt;p&gt;To demonstrate these various techniques, I've trained a number of models on the UCI Wine Quality dataset where I've generated my target by asserting that observations with a quality rating less than or equal to 4 are "low quality" wine and observations with a quality rating greater than or equal to 5 are "high quality" wine.
I provide the notebook I wrote to explore these techniques in a &lt;a href="https://github.com/mohcinemadkour/imbalanced-data"&gt;Github repo&lt;/a&gt; if you're interested in exploring this further. I highly encourage you to check out this notebook and perform the same experiment on a different dataset to see how it compares - let me know in the comment section!&lt;/p&gt;
&lt;h1&gt;Further reading&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;[Learning from Imbalanced Data - Literature Review] (http://ieeexplore.ieee.org/document/5128907/)&lt;/li&gt;
&lt;li&gt;[Learning from Imbalanced Classes] (https://svds.com/learning-imbalanced-classes/)&lt;/li&gt;
&lt;li&gt;[Learning from imbalanced data: open challenges and future directions] (https://rd.springer.com/article/10.1007/s13748-016-0094-0?utm_medium=affiliate&amp;amp;utm_source=commission_junction&amp;amp;utm_campaign=3_nsn6445_brand_PID4003003&amp;amp;utm_content=de_textlink)&lt;/li&gt;
&lt;li&gt;[Handling imbalanced datasets in machine learning] (https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28)&lt;/li&gt;
&lt;/ul&gt;</content><category term="Statistical Analysis"></category><category term="unbalanced data"></category><category term="ROC"></category><category term="AUROC"></category><category term="AUCPR"></category><category term="F1 Score"></category><category term="Recall"></category><category term="Precision"></category></entry><entry><title>The role of unit tests in test automation</title><link href="https://mmadkour.xyz%5Cposts/2017/08/The%20role%20of%20unit%20tests%20in%20test%20automation/" rel="alternate"></link><published>2017-08-03T16:00:00-04:00</published><updated>2017-08-03T16:00:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2017-08-03:/2017/08/The role of unit tests in test automation/</id><summary type="html">&lt;p&gt;Unit testing is a software development and testing approach in which the smallest testable parts of an application, called units, are individually and independently tested to see if they are operating properly. Unit testing can be done manually but is usually automated. Unit testing is a part of the test-driven …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Unit testing is a software development and testing approach in which the smallest testable parts of an application, called units, are individually and independently tested to see if they are operating properly. Unit testing can be done manually but is usually automated. Unit testing is a part of the test-driven development(TDD) methodology that requires developers to first write failing unit tests. Then they write code in order to change the application until the test passes. Writing the failing test is important because it forces the developer to take into account all possible inputs, errors and outputs. &lt;/p&gt;
&lt;p&gt;The result of using TDD is that an agile team can accumulate a comprehensive suite of unit tests that can be run at any time to provide feedback that their software is still working.  If the new code breaks something and causes a test to fail,  TDD also makes it easier to pinpoint the problem, refactor the application and fix the bug.&lt;/p&gt;
&lt;h1&gt;The AAA pattern&lt;/h1&gt;
&lt;p&gt;The goal of unit testing is to isolate each part of a program and show that the individual parts work correctly.  This is in line with the YAGNI ("You ain't gonna need it") principle at the heart of the agile development practice of doing the simplest thing that can possibly work.  Using the YAGNI principle to build units of software, together with other practices such as continuous refactoring and continuous integration, make it easier to automate groups or suites of unit tests.  Unit test automation is a key component of a Continuous Delivery DevTestOps solution, that is, a continuously tested, two-way DevOps software delivery pipeline between an organization and its customers.&lt;/p&gt;
&lt;p&gt;Unit tests are designed for code that has no external dependencies, such as calls to the database or web services.  Because they focus on a specific behavior in a small section of a system under test (SUT), they're also relatively straight-forward to automate, especially if they are written in a standard format such as the AAA pattern.&lt;/p&gt;
&lt;p&gt;The AAA unit test pattern&lt;/p&gt;
&lt;p&gt;Image Source: Code Project
&lt;img alt="Image Source: Code Project" src="images/AAA pattern."&gt;&lt;/p&gt;
&lt;p&gt;The AAA (Arrange, Act, Assert ) pattern helps organize and clarify test code by breaking down a test case into the following functional sections:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;Arrange&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;unit&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="n"&gt;initializes&lt;/span&gt; &lt;span class="n"&gt;objects&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="k"&gt;sets&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="k"&gt;data&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;passed&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;Act&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt; &lt;span class="n"&gt;invokes&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;arranged&lt;/span&gt; &lt;span class="k"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;Assert&lt;/span&gt; &lt;span class="n"&gt;section&lt;/span&gt; &lt;span class="n"&gt;verifies&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="n"&gt;behaves&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Consider the following example test scenario:&lt;/p&gt;
&lt;p&gt;A unit test in AAA format tests a software unit that increments the number of products in an e-commerce shopping cart:&lt;/p&gt;
&lt;p&gt;Arrange&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;Create&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;empty&lt;/span&gt; &lt;span class="n"&gt;shopping&lt;/span&gt; &lt;span class="n"&gt;cart&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Act&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;Add&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;product&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;cart&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Assert &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;Number&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;products&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;cart&lt;/span&gt; &lt;span class="n"&gt;increased&lt;/span&gt; &lt;span class="k"&gt;by&lt;/span&gt; &lt;span class="n"&gt;one&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here's more about  the AAA pattern:&lt;/p&gt;
&lt;h2&gt;Arrange Section&lt;/h2&gt;
&lt;p&gt;In order to put yourself in a position where you can call a software unit and check that the result was correct, you first need to "prime the pump," or put the unit into a known beginning state.  When setting up the module to be tested, it may be necessary sometimes to surround that module with other collaborator modules.  For testing purposes, those collaborators could be test modules with actual or made-up data (also known mock objects, fakes, etc.). &lt;/p&gt;
&lt;p&gt;Mock objects are simulated objects created by a developer that mimic the behavior of real objects in controlled ways, similar to how crash test dummies are expected to simulate the dynamic behavior of humans in vehicle impacts.  A mock object, in the case of a database or e-commerce application, might be created as part of a unit test with a variety of fake data because real customer records may not exist yet or it would slow down testing if a complete customer database had to be accessed or initialized before running the test.&lt;/p&gt;
&lt;p&gt;Test-specific mock objects can used to verify application behavior&lt;/p&gt;
&lt;p&gt;Image source:  hackerchick
&lt;img alt="Image source:  hackerchick" src="images/mockobjects.png"&gt;&lt;/p&gt;
&lt;p&gt;Mock objects are used for much more than creating made-up test data in unit testing.  For example, using mock objects in place of real objects can make it easier to test a complex algorithm based on multiple objects being in particular states.  The use of mock objects is extensive in the literature on automated testing using xUnit testing frameworks. You can find an example here. &lt;/p&gt;
&lt;p&gt;In the shopping cart example, the Arrange part of the pattern involves creating a empty shopping cart  by initially setting the number of products in the cart to zero.  As we'll see later, there's a way to adapt the AAA syntax to handle more complicated scenarios.&lt;/p&gt;
&lt;h2&gt;Act Section:&lt;/h2&gt;
&lt;p&gt;This is the part of the test that exercises the unit of code under test by making a function or method call that returns a result or causes a reaction that can be observed.&lt;/p&gt;
&lt;p&gt;In the shopping cart example, the Act section takes place when Buy Item button on the shopping cart is pushed. &lt;/p&gt;
&lt;h2&gt;Assert Section:&lt;/h2&gt;
&lt;p&gt;The assertion section were you check to see that you have a result or reaction (include calls to other units of code) that matches your expectations. &lt;/p&gt;
&lt;p&gt;In the shopping cart example, the Assert section occurs when the number property is checked against your expectation (i.e. the number of products in the cart is increased by one every time the Buy Item button is pushed.)&lt;/p&gt;
&lt;p&gt;Following the AAA pattern consistently makes test code easier to read by clearly separating what is being tested from the setup and verification steps.  This helps when you need to reexamine sections of test code to see if they're still doing what it should be doing, such as following a previous set of successful test steps.&lt;/p&gt;
&lt;p&gt;In the bottom-up testing style of test-driven development, unit tests written in the AAA syntax will help you know exactly where to search to find a bug when a unit test fails.  Kent Beck, who popularized the TDD concept in his book Test Driven Development: By Example, states that TDD has two basic rules:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Never&lt;/span&gt; &lt;span class="k"&gt;write&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;single&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="n"&gt;unless&lt;/span&gt; &lt;span class="n"&gt;you&lt;/span&gt; &lt;span class="n"&gt;have&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;failing&lt;/span&gt; &lt;span class="n"&gt;automated&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;Eliminate&lt;/span&gt; &lt;span class="n"&gt;duplication&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;  &lt;span class="k"&gt;In&lt;/span&gt; &lt;span class="n"&gt;software&lt;/span&gt; &lt;span class="n"&gt;engineering&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;don&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;repeat&lt;/span&gt; &lt;span class="n"&gt;yourself&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DRY&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;principle&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;agile&lt;/span&gt; &lt;span class="n"&gt;software&lt;/span&gt; &lt;span class="n"&gt;development&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aimed&lt;/span&gt; &lt;span class="k"&gt;at&lt;/span&gt; &lt;span class="n"&gt;reducing&lt;/span&gt; &lt;span class="n"&gt;repetition&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;information&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="k"&gt;all&lt;/span&gt; &lt;span class="n"&gt;kinds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;which&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;especially&lt;/span&gt; &lt;span class="n"&gt;useful&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;multi&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tier&lt;/span&gt; &lt;span class="n"&gt;architectures&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;According to Beck, a good unit test in TDD should be able to do all of the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;Run&lt;/span&gt; &lt;span class="nv"&gt;fast&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;they&lt;/span&gt; &lt;span class="nv"&gt;have&lt;/span&gt; &lt;span class="nv"&gt;short&lt;/span&gt; &lt;span class="nv"&gt;setups&lt;/span&gt;, &lt;span class="nv"&gt;run&lt;/span&gt; &lt;span class="nv"&gt;times&lt;/span&gt;, &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="k"&gt;break&lt;/span&gt; &lt;span class="nv"&gt;downs&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;.
&lt;span class="nv"&gt;Run&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;isolation&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;you&lt;/span&gt; &lt;span class="nv"&gt;should&lt;/span&gt; &lt;span class="nv"&gt;be&lt;/span&gt; &lt;span class="nv"&gt;able&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;reorder&lt;/span&gt; &lt;span class="nv"&gt;them&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;.
&lt;span class="nv"&gt;Use&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt; &lt;span class="nv"&gt;that&lt;/span&gt; &lt;span class="nv"&gt;makes&lt;/span&gt; &lt;span class="nv"&gt;them&lt;/span&gt; &lt;span class="nv"&gt;easy&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;read&lt;/span&gt; &lt;span class="nv"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;understand&lt;/span&gt;.
&lt;span class="nv"&gt;Use&lt;/span&gt; &lt;span class="nv"&gt;real&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;or&lt;/span&gt; &lt;span class="nv"&gt;copies&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="nv"&gt;production&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;when&lt;/span&gt; &lt;span class="nv"&gt;they&lt;/span&gt; &lt;span class="nv"&gt;need&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt;.
&lt;span class="nv"&gt;Represent&lt;/span&gt; &lt;span class="nv"&gt;one&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt; &lt;span class="nv"&gt;towards&lt;/span&gt; &lt;span class="nv"&gt;your&lt;/span&gt; &lt;span class="nv"&gt;overall&lt;/span&gt; &lt;span class="nv"&gt;goal&lt;/span&gt;.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This means unit tests need to be narrowly focused and shouldn't try to test too many different things at once.  An example of a unit test that tries to do too many things is shown in a test scenario involving a sweater purchase in an e-commerce shopping cart application.  The Arrange section in this example assumes that the pipe has been primed and you have sweaters in your inventory database, that another unit is able to show the inventory to your customer and still other units are be able to process the customer payment and remove items from inventory.&lt;/p&gt;
&lt;p&gt;Here's some pseudo code for a unit test in the AAA format for this kind of functionality:&lt;/p&gt;
&lt;p&gt;Arrange&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;setup&lt;/span&gt; &lt;span class="nv"&gt;Sweater&lt;/span&gt; &lt;span class="nv"&gt;Inventory&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;mostly&lt;/span&gt; &lt;span class="nv"&gt;likely&lt;/span&gt; &lt;span class="nv"&gt;with&lt;/span&gt; &lt;span class="nv"&gt;mock&lt;/span&gt; &lt;span class="nv"&gt;database&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;set&lt;/span&gt; &lt;span class="nv"&gt;Sweater&lt;/span&gt; &lt;span class="nv"&gt;Inventory&lt;/span&gt; &lt;span class="nv"&gt;Count&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;      
&lt;span class="nv"&gt;when&lt;/span&gt; &lt;span class="nv"&gt;Sweater&lt;/span&gt; &lt;span class="nv"&gt;Inventory&lt;/span&gt; &lt;span class="nv"&gt;is&lt;/span&gt; &lt;span class="nv"&gt;requested&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;remove&lt;/span&gt; &lt;span class="nv"&gt;N&lt;/span&gt; &lt;span class="nv"&gt;items&lt;/span&gt;, &lt;span class="k"&gt;then&lt;/span&gt; &lt;span class="nv"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;count&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nv"&gt;N&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Act&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Unit&lt;/span&gt; &lt;span class="k"&gt;Under&lt;/span&gt; &lt;span class="n"&gt;Test&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;remove&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;inventory&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Assert&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="nb"&gt;number&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;sweaters&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Sweater&lt;/span&gt; &lt;span class="n"&gt;Inventory&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, writing large unit tests in this way can quickly become complex and convoluted,  especially when you need to test end-to-end functionality for a complete 6-step e-commerce shopping-cart application, i.e.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;Access&lt;/span&gt; &lt;span class="n"&gt;Homepage&lt;/span&gt; &lt;span class="err"&gt;–&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; 
&lt;span class="n"&gt;Customer&lt;/span&gt; &lt;span class="k"&gt;Search&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="err"&gt;–&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="n"&gt;Product&lt;/span&gt; &lt;span class="n"&gt;details&lt;/span&gt;  &lt;span class="err"&gt;–&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="n"&gt;Customer&lt;/span&gt; &lt;span class="n"&gt;login&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;or&lt;/span&gt; &lt;span class="n"&gt;Register&lt;/span&gt; &lt;span class="k"&gt;New&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="err"&gt;–&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="n"&gt;Payment&lt;/span&gt; &lt;span class="n"&gt;details&lt;/span&gt; &lt;span class="err"&gt;–&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="k"&gt;Order&lt;/span&gt; &lt;span class="n"&gt;confirmation&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A simpler and better to way to use the AAA unit test scaffolding, both for unit and higher-level tests, is by using Behavior-Driven Development (BDD), which BDD pioneer Dan North defines this way:&lt;/p&gt;
&lt;p&gt;"BDD is a second-generation, outside–in, pull-based, multiple-stakeholder, multiple-scale, high-automation, agile methodology. It describes a cycle of interactions with well-defined outputs, resulting in the delivery of working, tested software that matters."
&lt;img alt="andolasoft" src="images/bdd n tdd.jpg"&gt;
BDD is an enhancement of TDD&lt;/p&gt;
&lt;p&gt;Image Source:  andolasoft&lt;/p&gt;
&lt;p&gt;The main advantage of BDD is that it encourages collaboration between developers, QA and non-technical or business participants on a software project.  It extends TDD by writing test cases in a natural language that non-programmers and domain experts can read. BDD features are usually defined in a GIVEN WHEN and THEN (GWT) format, which is a semi-structured way of writing down test cases.  A BDD feature  or user story needs to follow the following structure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;Describe&lt;/span&gt; &lt;span class="n"&gt;who&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="k"&gt;primary&lt;/span&gt; &lt;span class="n"&gt;stakeholder&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;
&lt;span class="n"&gt;What&lt;/span&gt; &lt;span class="n"&gt;effect&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;stakeholder&lt;/span&gt; &lt;span class="n"&gt;wants&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;have&lt;/span&gt;
&lt;span class="n"&gt;What&lt;/span&gt; &lt;span class="n"&gt;business&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;stakeholder&lt;/span&gt; &lt;span class="n"&gt;will&lt;/span&gt; &lt;span class="n"&gt;derive&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;this&lt;/span&gt; &lt;span class="n"&gt;effect&lt;/span&gt;
&lt;span class="n"&gt;Acceptance&lt;/span&gt; &lt;span class="n"&gt;criteria&lt;/span&gt; &lt;span class="k"&gt;or&lt;/span&gt; &lt;span class="n"&gt;scenarios&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A brief example of a BDD feature in this format looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Feature&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="n"&gt;Items&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;abandoned&lt;/span&gt; &lt;span class="n"&gt;shopping&lt;/span&gt; &lt;span class="n"&gt;carts&lt;/span&gt; &lt;span class="n"&gt;should&lt;/span&gt; &lt;span class="n"&gt;be&lt;/span&gt; &lt;span class="n"&gt;returned&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;inventory&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="n"&gt;order&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;keep&lt;/span&gt; &lt;span class="n"&gt;track&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;inventory&lt;/span&gt;
&lt;span class="n"&gt;As&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="n"&gt;store&lt;/span&gt; &lt;span class="n"&gt;owner&lt;/span&gt;
&lt;span class="n"&gt;I&lt;/span&gt; &lt;span class="n"&gt;want&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="n"&gt;back&lt;/span&gt; &lt;span class="n"&gt;into&lt;/span&gt; &lt;span class="n"&gt;inventory&lt;/span&gt; &lt;span class="n"&gt;when&lt;/span&gt; &lt;span class="n"&gt;an&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="n"&gt;shopping&lt;/span&gt; &lt;span class="n"&gt;cart&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;abandoned&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Scenario 1: On-line shopping cart items not purchased within 30 minutes go back into inventory&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;Given&lt;/span&gt; &lt;span class="nv"&gt;that&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;customer&lt;/span&gt; &lt;span class="nv"&gt;puts&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;black&lt;/span&gt; &lt;span class="nv"&gt;sweater&lt;/span&gt; &lt;span class="nv"&gt;into&lt;/span&gt; &lt;span class="nv"&gt;his&lt;/span&gt; &lt;span class="nv"&gt;shopping&lt;/span&gt; &lt;span class="nv"&gt;cart&lt;/span&gt;
&lt;span class="nv"&gt;And&lt;/span&gt; &lt;span class="nv"&gt;I&lt;/span&gt; &lt;span class="nv"&gt;have&lt;/span&gt; &lt;span class="nv"&gt;three&lt;/span&gt; &lt;span class="nv"&gt;black&lt;/span&gt; &lt;span class="nv"&gt;sweaters&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;inventory&lt;/span&gt;.
&lt;span class="nv"&gt;When&lt;/span&gt; &lt;span class="nv"&gt;he&lt;/span&gt; &lt;span class="nv"&gt;does&lt;/span&gt; &lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="nv"&gt;complete&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;purchase&lt;/span&gt; &lt;span class="nv"&gt;with&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt; &lt;span class="nv"&gt;minutes&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt;.&lt;span class="nv"&gt;e&lt;/span&gt;. &lt;span class="nv"&gt;abandons&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;shopping&lt;/span&gt; &lt;span class="nv"&gt;cart&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;Then&lt;/span&gt; &lt;span class="nv"&gt;I&lt;/span&gt; &lt;span class="nv"&gt;should&lt;/span&gt; &lt;span class="nv"&gt;have&lt;/span&gt; &lt;span class="nv"&gt;four&lt;/span&gt; &lt;span class="nv"&gt;black&lt;/span&gt; &lt;span class="nv"&gt;sweaters&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;inventory&lt;/span&gt;.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In TDD, the developers write the tests while in BDD the automated specifications are created by users or testers (with developers writing the underlying code that implements the test.) 
&lt;img alt="Test Automation Pyramid" src="/images/automation pyramid.png"&gt;
Test Automation Pyramid&lt;/p&gt;
&lt;p&gt;Image Source:  Effective Testing Practices in an Agile Environment&lt;/p&gt;
&lt;h1&gt;Outside-in vs. Inside-out Testing&lt;/h1&gt;
&lt;p&gt;Agile teams generally follow one of two approaches when it comes to testing their applications, either outside-In  or inside-out.  In the outside-in approach, teams start by focusing on the end user's perspective and attempt to describe high-level desired functionality and goals for the software under test in the form of user stories.  In every iteration or Sprint, user stories are refined until the agile team and the Product Owner/Customer Representative can agree on the acceptance criteria, which determine that a User Story works as planned.  Testing then goes 'inward' and code is written to test smaller and small components until you reach the unit-test level.&lt;/p&gt;
&lt;p&gt;In the inside-out or bottom-up approach, agile teams start with unit tests at the lowest level of the Test Automation Pyramid (see Figure 5 above).  As the code evolves due to refactoring, testing efforts evolve as well as the team moves upward to acceptance level testing, which tests business logic at the API or service level.  The top of the pyramid and the last thing tested is the user interface (UI).&lt;/p&gt;
&lt;p&gt;Inside-out and outside-in are different but complementary approaches to testing.  Software quality control relies on the related notions of verification and validation (V&amp;amp;V) that check to see that a software system meets specifications and that it fulfills its intended purpose.  The terms verification and validation are often used interchangeably but have different meanings: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Verification&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Checks&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;software&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;respect&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;specifications&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Is our team building the code right?&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Validation&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Checks&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;software&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;respect&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;expectations&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Are we building the right code?&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;On modern agile DevOps projects, validation and verification steps overlap and take place continuously since agile team members must engage with customers and other stakeholders throughout the project-- to do things like prioritizing bug fixes and enhancements on the team's project backlog --  and not just after a separate test phase at the end of the project.  This requires effective communication at all levels of the business since team members need to be understand what features need to be built and who needs each feature.&lt;/p&gt;
&lt;p&gt;BDD and TDD use syntax to describe three test states that are roughly equivalent:&lt;/p&gt;
&lt;p&gt;Given = Arrange 
When = Act,
Then   = Assert&lt;/p&gt;
&lt;p&gt;In  TDD, "inside-out" development starts with the innermost components and proceeds towards the user interface building on the previously constructed components.  BDD makes it easier to for agile teams to design outside-in but then code inside-out.  Because of the increased communication and collaboration among developers, QA and non-technical or business participants on a software project that the BDD/GWT syntax promotes,  developers and testers are able to anticipate how to test the outer software when writing tests for the inner software.  This means that tests at the Acceptance and GUI level can better take advantage of already-built tests, reducing the need for the Mock Objects mentioned earlier. &lt;/p&gt;
&lt;p&gt;Using TDD and the AAA syntax encourages developers to write small, independent tests and to continually refactor their code.  BDD supports TDD by helping bridge the gap between unit tests and higher-level acceptance and integration tests.  BDD and the GWT syntax are useful in business environments, where work done by developers needs to be mapped to business value. Because the two approaches complement each other so well, you should combine them with test management tools to get the best results on your DevOps test automation projects.&lt;/p&gt;</content><category term="Software"></category><category term="Unit Test"></category><category term="Software"></category></entry><entry><title>A Practical Introduction to Deep Learning with Caffe and Python</title><link href="https://mmadkour.xyz%5Cposts/2016/06/introduction-deep-learning-python-caffe/" rel="alternate"></link><published>2016-06-26T00:00:00-04:00</published><updated>2016-06-26T00:00:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2016-06-26:/2016/06/introduction-deep-learning-python-caffe/</id><summary type="html">&lt;p&gt;The goal of this blog post is to give you a hands-on introduction to deep learning. To do this, we will build a Cat/Dog image classifier using a deep learning algorithm called convolutional neural network. This post is divided into 2 main parts. The first part covers some core concepts behind deep learning, while the second part is structured in a hands-on tutorial format. We will use some Python code and a popular open source deep learning framework called Caffe to build the classifier.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Deep learning is the new big trend in machine learning. It had many recent successes in computer vision, automatic speech recognition and natural language processing.&lt;/p&gt;
&lt;p&gt;The goal of this blog post is to give you a hands-on introduction to deep learning. To do this, we will build a Cat/Dog image classifier using a deep learning algorithm called convolutional neural network (CNN) and a &lt;a href="https://www.kaggle.com/c/dogs-vs-cats"&gt;Kaggle dataset&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This post is divided into 2 main parts. The first part covers some core concepts behind deep learning, while the second part is structured in a hands-on tutorial format.&lt;/p&gt;
&lt;p&gt;In the first part of the hands-on tutorial (section 4), we will build a Cat/Dog image classifier using a convolutional neural network from scratch. In the second part of the tutorial (section 5), we will cover an advanced technique for training convolutional neural networks called transfer learning. We will use some Python code and a popular open source deep learning framework called Caffe to build the classifier. Our classifier will be able to achieve a classification accuracy of 97%.&lt;/p&gt;
&lt;p&gt;By the end of this post, you will understand how convolutional neural networks work, and you will get familiar with the steps and the code for building these networks.&lt;/p&gt;
&lt;p&gt;The source code for this tutorial can be found in this &lt;a href="https://github.com/mohcinemadkour/deeplearning-cats-dogs-tutorial"&gt;github repository&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;1. Problem Definition&lt;/h1&gt;
&lt;p&gt;In this tutorial, we will be using a dataset from &lt;a href="https://www.kaggle.com/c/dogs-vs-cats"&gt;Kaggle&lt;/a&gt;. The dataset is comprised of 25,000 images of dogs and cats. &lt;/p&gt;
&lt;p&gt;Our goal is to build a machine learning algorithm capable of detecting the correct animal (cat or dog) in new unseen images. &lt;/p&gt;
&lt;p&gt;In Machine learning, this type of problems is called classification. &lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/cats-dogs.jpg"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;2. Classification using Traditional Machine Learning vs. Deep Learning&lt;/h1&gt;
&lt;p&gt;Classification using a machine learning algorithm has 2 phases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Training phase: In this phase, we train a machine learning algorithm using a dataset comprised of the images and their corresponding labels.&lt;/li&gt;
&lt;li&gt;Prediction phase: In this phase, we utilize the trained model to predict labels of unseen images.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The training phase for an image classification problem has 2 main steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Feature Extraction: In this phase, we utilize domain knowledge to extract new features that will be used by the machine learning algorithm. &lt;a href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients"&gt;HoG&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform"&gt;SIFT&lt;/a&gt; are examples of features used in image classification.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Model Training: In this phase, we utilize a clean dataset composed of the images' features and the corresponding labels to train the machine learning model.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the predicition phase, we apply the same feature extraction process to the new images and we pass the features to the trained machine learning algorithm to predict the label.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/machine-learning-training-prediction-2.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The main difference between traditional machine learning and deep learning algorithms is in the feature engineering. In traditional machine learning algorithms, we need to hand-craft the features. By contrast, in deep learning algorithms feature engineering is done automatically by the algorithm. 
Feature engineering is difficult, time-consuming and requires domain expertise. The promise of deep learning is more accurate machine learning algorithms compared to traditional machine learning with less or no feature engineering.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/traditional-ml-deep-learning-2.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;3. A Crash Course in Deep Learning&lt;/h1&gt;
&lt;p&gt;Deep learning refers to a class of artificial neural networks (ANNs) composed of many processing layers. ANNs existed for many decades, but attempts at training deep architectures of ANNs failed until Geoffrey Hinton's breakthrough work of the mid-2000s. In addition to algorithmic innovations, the increase in computing capabilities using GPUs and the collection of larger datasets are all factors that helped in the recent surge of deep learning.&lt;/p&gt;
&lt;h2&gt;3.1. Artificial Neural Networks (ANNs)&lt;/h2&gt;
&lt;p&gt;Artificial neural networks (ANNs) are a family of machine learning models inspired by biological neural networks. &lt;/p&gt;
&lt;h3&gt;Artificial Neural Networks vs. Biological Neural Networks&lt;/h3&gt;
&lt;p&gt;Biological Neurons are the core components of the human brain. A neuron consists of a cell body, dendrites, and an axon. It processes and transmit information to other neurons by emitting electrical signals. Each neuron receives input signals from its dendrites and produces output signals along its axon. The axon branches out and connects via synapses to dendrites of other neurons. &lt;/p&gt;
&lt;p&gt;A basic model for how the neurons work goes as follows: Each synapse has a strength that is learnable and control the strength of influence of one neuron on another. The dendrites carry the signals to the target neuron's body where they get summed. If the final sum is above a certain threshold, the neuron get fired, sending a spike along its axon.[1]&lt;/p&gt;
&lt;p&gt;Artificial neurons are inspired by biological neurons, and try to formulate the model explained above in a computational form. An artificial neuron has a finite number of inputs with weights associated to them, and an activation function (also called transfer function). The output of the neuron is the result of the activation function applied to the weighted sum of inputs. Artificial neurons are connected with each others to form artificial neural networks.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/neurons.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h3&gt;Feedforward Neural Networks&lt;/h3&gt;
&lt;p&gt;Feedforward Neural Networks are the simplest form of Artificial Neural Networks. &lt;/p&gt;
&lt;p&gt;These networks have 3 types of layers: Input layer, hidden layer and output layer. In these networks, data moves from the input layer through the hidden nodes (if any) and to the output nodes. &lt;/p&gt;
&lt;p&gt;Below is an example of a fully-connected feedforward neural network with 2 hidden layers. "Fully-connected" means that each node is connected to all the nodes in the next layer. &lt;/p&gt;
&lt;p&gt;Note that, the number of hidden layers and their size are the only free parameters. The larger and deeper the hidden layers, the more complex patterns we can model in theory.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/feedforward-nn.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h3&gt;Activation Functions&lt;/h3&gt;
&lt;p&gt;Activation functions transform the weighted sum of inputs that goes into the artificial neurons. These functions should be non-linear to encode complex patterns of the data. The most popular activation functions are Sigmoid, Tanh and ReLU. ReLU is the most popular activation function in deep neural networks.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/activation.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h3&gt;Training Artificial Neural Networks&lt;/h3&gt;
&lt;p&gt;The goal of the training phase is to learn the network's weights.  We need 2 elements to train an artificial neural network:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Training data: In the case of image classification, the training data is composed of images and the corresponding labels.&lt;/li&gt;
&lt;li&gt;Loss function: A function that measures the inaccuracy of predictions. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once we have the 2 elements above, we train the ANN using an algorithm called backpropagation together with gradient descent (or one of its derivatives). For a detailed explanation of backpropagation, I recommend this &lt;a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/"&gt;article&lt;/a&gt;. &lt;/p&gt;
&lt;h2&gt;3.2. Convolutional Neural Networks (CNNs or ConvNets)&lt;/h2&gt;
&lt;p&gt;Convolutional neural networks are a special type of feed-forward networks. These models are designed to emulate the behaviour of a visual cortex. CNNs perform very well on visual recognition tasks. 
CNNs have special layers called convolutional layers and pooling layers that allow the network to encode certain images properties. &lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/lenet.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Convolution Layer&lt;/h2&gt;
&lt;p&gt;This layer consists of a set of learnable filters that we slide over the image spatially, computing dot products between the entries of the filter and the input image. The filters should extend to the full depth of the input image. For example, if we want to apply a filter of size 5x5 to a colored image of size 32x32, then the filter should have depth 3 (5x5x3) to cover all 3 color channels (Red, Green, Blue) of the image. These filters will activate when they see same specific structure in the images. &lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/conv-layer.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Pooling Layer&lt;/h2&gt;
&lt;p&gt;Pooling is a form of non-linear down-sampling. The goal of the pooling layer is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. There are several functions to implement pooling among which max pooling is the most common one. Pooling is often applied with filters of size 2x2 applied with a stride of 2 at every depth slice. A pooling layer of size 2x2 with stride of 2 shrinks the input image to a 1/4 of its original size. [2]&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/max-pooling.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Convolutional Neural Networks Architecture&lt;/h2&gt;
&lt;p&gt;The simplest architecture of a convolutional neural networks starts with an input layer (images) followed by a sequence of convolutional layers and pooling layers, and ends with fully-connected layers. The convolutional layers are usually followed by one layer of ReLU activation functions. &lt;/p&gt;
&lt;p&gt;The convolutional, pooling and ReLU layers act as learnable features extractors, while the fully connected layers acts as a machine learning classifier. Furthermore, the early layers of the network encode generic patterns of the images, while later layers encode the details patterns of the images.&lt;/p&gt;
&lt;p&gt;Note that only the convolutional layers and fully-connected layers have weights. These weights are learned in the training phase. &lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/cnn-architecture.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;4. Building a Cat/Dog Classifier using a Convolutional Neural Network&lt;/h1&gt;
&lt;p&gt;In this section, we will implement a cat/dog classifier using a convolutional neural network. We will use a dataset from Kaggle's &lt;a href="https://www.kaggle.com/c/dogs-vs-cats"&gt;Dogs vs. Cats competition&lt;/a&gt;. To implement the convolutional neural network, we will use a deep learning framework called Caffe and some Python code.&lt;/p&gt;
&lt;h2&gt;4.1 Getting Dogs &amp;amp; Cats Data&lt;/h2&gt;
&lt;p&gt;First, we need to download 2 datasets from the &lt;a href="https://www.kaggle.com/c/dogs-vs-cats/data"&gt;competition page&lt;/a&gt;: train.zip and test1.zip. The train.zip file contains labeled cats and dogs images that we will use to train the network. The test1.zip file contains unlabeled images that we will classify to either dog or cat using the trained model. We will upload our predictions to Kaggle to get the score of our prediction model.&lt;/p&gt;
&lt;h2&gt;4.2 Machine Setup&lt;/h2&gt;
&lt;p&gt;To train convolutional neural networks, we need a machine with a powerful GPU. &lt;/p&gt;
&lt;p&gt;In this tutorial, I used one &lt;a href="https://aws.amazon.com/"&gt;AWS&lt;/a&gt; EC2 instance of type g2.2xlarge. This instance has a high-performance NVIDIA GPU with 1,536 CUDA cores and 4GB of video memory, 15GB of RAM and 8 vCPUs. The machine costs $0.65/hour.&lt;/p&gt;
&lt;p&gt;If you're not familiar with AWS, this &lt;a href="http://cs231n.github.io/aws-tutorial/"&gt;guide&lt;/a&gt; will help you set up an AWS EC2 instance. &lt;/p&gt;
&lt;p&gt;Please note, that the AMI recommended in the guide is no longer available. I prepared a new AMI (ami-64d31209) with all the necessary software installed. I also created a &lt;a href="https://github.com/mohcinemadkour/deeplearning-cats-dogs-tutorial/blob/master/aws-ec2-setup.md"&gt;guide&lt;/a&gt; for installing Caffe and Anaconda on an AWS EC2 instance or an Ubuntu machine with GPU.&lt;/p&gt;
&lt;p&gt;After setting up an AWS instance, we connect to it and clone the github repository that contains the necessary Python code and Caffe configuration files for the tutorial. From your terminal, execute the following command.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;clone&lt;/span&gt; &lt;span class="n"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;mohcinemadkour&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;git&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we create an &lt;code&gt;input&lt;/code&gt; folder for storing the training and test images.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cd&lt;/span&gt; &lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;
&lt;span class="n"&gt;mkdir&lt;/span&gt; &lt;span class="k"&gt;input&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;4.3 Caffe Overview&lt;/h2&gt;
&lt;p&gt;Caffe is a deep learning framework developed by the Berkeley Vision and Learning Center (&lt;a href="http://bvlc.eecs.berkeley.edu/"&gt;BVLC&lt;/a&gt;). It is written in C++ and has Python and Matlab bindings. &lt;/p&gt;
&lt;p&gt;There are 4 steps in training a CNN using Caffe:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1 - Data preparation: In this step, we clean the images and store them in a format that can be used by Caffe. We will write a Python script that will handle both image pre-processing and storage.&lt;/li&gt;
&lt;li&gt;Step 2 - Model definition: In this step, we choose a CNN architecture and we define its parameters in a configuration file with extension &lt;code&gt;.prototxt&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Step 3 - Solver definition:  The solver is responsible for model optimization. We define the solver parameters in a configuration file with extension &lt;code&gt;.prototxt&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;Step 4 - Model training: We train the model by executing one Caffe command from the terminal. After training the model, we will get the trained model in a file with extension &lt;code&gt;.caffemodel&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After the training phase, we will use the &lt;code&gt;.caffemodel&lt;/code&gt; trained model to make predictions of new unseen data. We will write a Python script to this.&lt;/p&gt;
&lt;h2&gt;4.4 Data Preparation&lt;/h2&gt;
&lt;p&gt;We start by copying the train.zip and test1.zip (that we downloaded to our local machine) to the &lt;code&gt;input&lt;/code&gt; folder in the AWS instance. We can do this using the &lt;code&gt;scp&lt;/code&gt; command from a MAC or linux machine. If you're running Windows, you can use a program such as &lt;a href="https://winscp.net/eng/download.php"&gt;Winscp&lt;/a&gt;. After copying the data, we unzip the files by executing the following commands:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;unzip&lt;/span&gt; &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zip&lt;/span&gt;
&lt;span class="n"&gt;unzip&lt;/span&gt; &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;test1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zip&lt;/span&gt;
&lt;span class="n"&gt;rm&lt;/span&gt; &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="cm"&gt;/*.zip&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we run &lt;code&gt;create_lmdb.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cd&lt;/span&gt; &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;create_lmdb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;create_lmdb.py&lt;/code&gt; script does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run histogram equalization on all training images. Histogram equalization is a technique for adjusting the contrast of images. &lt;/li&gt;
&lt;li&gt;Resize all training images to a 227x227 format.&lt;/li&gt;
&lt;li&gt;Divide the training data into 2 sets: One for training (5/6 of images) and the other for validation (1/6 of images). The training set is used to train the model, and the validation set is used to calculate the accuracy of the model. &lt;/li&gt;
&lt;li&gt;Store the training and validation in 2 LMDB databases. train_lmdb for training the model and validation_lmbd for model evaluation. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below is the explanation of the most important parts of the code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;transform_img&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;IMAGE_WIDTH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;IMAGE_HEIGHT&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="c1"&gt;#Histogram Equalization&lt;/span&gt;
    &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equalizeHist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equalizeHist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equalizeHist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="c1"&gt;#Image Resizing&lt;/span&gt;
    &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_height&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;interpolation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INTER_CUBIC&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;transform_img&lt;/code&gt; takes a colored images as input, does the histogram equalization of the 3 color channels and resize the image.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/image-transform.jpg"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;make_datum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;caffe_pb2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Datum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;IMAGE_WIDTH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;IMAGE_HEIGHT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rollaxis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tostring&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;make_datum&lt;/code&gt; takes an image and its label and return a &lt;a href="https://github.com/BVLC/caffe/wiki/The-Datum-Object"&gt;Datum object&lt;/a&gt; that contains the image and its label. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;in_db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lmdb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_lmdb&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;map_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1e12&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;in_db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;begin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;in_txn&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;in_idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_path&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;in_idx&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;  &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;
        &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IMREAD_COLOR&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transform_img&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;IMAGE_WIDTH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;IMAGE_HEIGHT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;cat&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;img_path&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;datum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_datum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;in_txn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{:0&amp;gt;5d}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;in_idx&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;datum&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SerializeToString&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{:0&amp;gt;5d}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;in_idx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;:&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;img_path&lt;/span&gt;
&lt;span class="n"&gt;in_db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code above takes 5/6 of the training images, transforms and stores them in train_lmdb. The code for storing validation data follows the same structure.&lt;/p&gt;
&lt;h3&gt;Generating the mean image of training data&lt;/h3&gt;
&lt;p&gt;We execute the command below to generate the mean image of training data. We will substract the mean image from each input image to ensure every feature pixel has zero mean. This is a common preprocessing step in supervised machine learning.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tools&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;compute_image_mean&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;backend&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;lmdb&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;train_lmdb&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binaryproto&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;4.4 Model Definition&lt;/h2&gt;
&lt;p&gt;After deciding on the CNN architecture, we need to define its parameters in a &lt;code&gt;.prototxt&lt;/code&gt; train_val file. Caffe comes with a few popular CNN &lt;a href="https://github.com/BVLC/caffe/tree/master/models"&gt;models&lt;/a&gt; such as Alexnet and GoogleNet. In this tutorial, we will use the &lt;a href="https://github.com/BVLC/caffe/tree/master/models/bvlc_reference_caffenet"&gt;bvlc_reference_caffenet&lt;/a&gt; model which is a replication of AlexNet with a few modifications. Below is a copy of the train_val file that we call &lt;code&gt;caffenet_train_val_1.prototxt&lt;/code&gt;. If you clone the tutorial git repository as explained above, you should have the same file under &lt;code&gt;deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We need to make the modifications below to the original bvlc_reference_caffenet prototxt file:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Change the path for input data and mean image: Lines 24, 40 and 51.&lt;/li&gt;
&lt;li&gt;Change the number of outputs from 1000 to 2: Line 373. The original bvlc_reference_caffenet was designed for a classification problem with 1000 classes. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[gist:id=3f71cf43ad04c2f04b9af45841e4fed3,file=caffenet_train_val_1.prototxt]&lt;/p&gt;
&lt;p&gt;We can print the model architecture by executing the command below. The model architecture image will be stored under &lt;code&gt;deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/caffe_model_1.png&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;draw_net&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_model_1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffenet_train_val_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prototxt&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_model_1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_model_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/caffe_model_1.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;4.5 Solver Definition&lt;/h2&gt;
&lt;p&gt;The solver is responsible for model optimization. We define the solver's parameters in a &lt;code&gt;.prototxt&lt;/code&gt; file. You can find our solver under &lt;code&gt;deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/&lt;/code&gt; with name &lt;code&gt;solver_1.prototxt&lt;/code&gt;. Below is a copy of the same.&lt;/p&gt;
&lt;p&gt;This solver computes the accuracy of the model using the validation set every 1000 iterations. The optimization process will run for a maximum of 40000 iterations and will take a snapshot of the trained model every 5000 iterations.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;base_lr&lt;/code&gt;, &lt;code&gt;lr_policy&lt;/code&gt;, &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;momentum&lt;/code&gt; and &lt;code&gt;weight_decay&lt;/code&gt; are hyperparameters that we need to tune to get a good convergence of the model.&lt;/p&gt;
&lt;p&gt;I chose &lt;code&gt;lr_policy: "step"&lt;/code&gt; with &lt;code&gt;stepsize: 2500&lt;/code&gt;, &lt;code&gt;base_lr: 0.001&lt;/code&gt; and &lt;code&gt;gamma: 0.1&lt;/code&gt;. In this configuration, we will start with a learning rate of 0.001, and we will drop the learning rate by a factor of ten every 2500 iterations.&lt;/p&gt;
&lt;p&gt;There are different strategies for the optimization process. For a detailed explanation, I recommend Caffe's &lt;a href="http://caffe.berkeleyvision.org/tutorial/solver.html"&gt;solver documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;[gist:id=3f71cf43ad04c2f04b9af45841e4fed3,file=solver_1.prototxt]&lt;/p&gt;
&lt;h2&gt;4.6 Model Training&lt;/h2&gt;
&lt;p&gt;After defining the model and the solver, we can start training the model by executing the command below: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tools&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt; &lt;span class="c1"&gt;--solver /home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/solver_1.prototxt 2&amp;gt;&amp;amp;1 | tee /home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/model_1_train.log&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The training logs will be stored under &lt;code&gt;deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/model_1_train.log&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;During the training process, we need to monitor the loss and the model accuracy. We can stop the process at anytime by pressing Ctrl+c. Caffe will take a snapshot of the trained model every 5000 iterations, and store them under &lt;code&gt;caffe_model_1&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;The snapshots have &lt;code&gt;.caffemodel&lt;/code&gt; extension. For example, 10000 iterations snapshot will be called: &lt;code&gt;caffe_model_1_iter_10000.caffemodel&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Plotting the learning curve&lt;/h3&gt;
&lt;p&gt;A learning curve is a plot of the training and test losses as a function of the number of iterations. These plots are very useful to visualize the train/validation losses and validation accuracy. &lt;/p&gt;
&lt;p&gt;We can see from the learning curve that the model achieved a validation accuracy of 90%, and it stopped improving after 3000 iterations. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;plot_learning_curve&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_model_1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;model_1_train&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_model_1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_model_1_learning_curve&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/caffe_model_1_learning_curve.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;4.7 Prediction on New Data&lt;/h2&gt;
&lt;p&gt;Now that we have a trained model, we can use it to make predictions on new unseen data (images from test1). The Python code for making the predictions is &lt;code&gt;make_predictions_1.py&lt;/code&gt; and it's stored under &lt;code&gt;deeplearning-cats-dogs-tutorial/code&lt;/code&gt;. The code needs 4 files to run:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Test images: We will use test1 images.&lt;/li&gt;
&lt;li&gt;Mean image: The mean image that we computed in section 4.4.&lt;/li&gt;
&lt;li&gt;Model architecture file: We'll call this file &lt;code&gt;caffenet_deploy_1.prototxt&lt;/code&gt;. It's stored under &lt;code&gt;deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1&lt;/code&gt;. It's structured in a similar way to &lt;code&gt;caffenet_train_val_1.prototxt&lt;/code&gt;, but with a few modifications. We need to delete the data layers, add an input layer and change the last layer type from SoftmaxWithLoss to Softmax.&lt;/li&gt;
&lt;li&gt;Trained model weights: This is the file that we computed in the training phase. We will use &lt;code&gt;caffe_model_1_iter_10000.caffemodel&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To run the Python code, we need to execute the command below. The predictions will be stored under &lt;code&gt;deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/submission_model_1.csv&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cd&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;make_predictions_1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Below is the explanation of the most important parts in the code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#Read mean image&lt;/span&gt;
&lt;span class="n"&gt;mean_blob&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;caffe_pb2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BlobProto&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/deeplearning-cats-dogs-tutorial/input/mean.binaryproto&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;mean_blob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ParseFromString&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;mean_array&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean_blob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean_blob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean_blob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean_blob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="c1"&gt;#Read model architecture and trained model&amp;#39;s weights&lt;/span&gt;
&lt;span class="n"&gt;net&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;caffe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Net&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/caffenet_deploy_1.prototxt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="s1"&gt;&amp;#39;/home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/caffe_model_1_iter_10000.caffemodel&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="n"&gt;caffe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TEST&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;#Define image transformers&lt;/span&gt;
&lt;span class="n"&gt;transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;caffe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;blobs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean_array&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code above stores the mean image under &lt;code&gt;mean_array&lt;/code&gt;, defines a model called &lt;code&gt;net&lt;/code&gt; by reading the deploy file and the trained model, and defines the transformations that we need to apply to the test images.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IMREAD_COLOR&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transform_img&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;IMAGE_WIDTH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;IMAGE_HEIGHT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;blobs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;pred_probas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;prob&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;pred_probas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code above read an image, apply similar image processing steps to training phase, calculates each class' probability and prints the class with the largest probability (0 for cats, and 1 for dogs). &lt;/p&gt;
&lt;p&gt;After submitting the predicitions to &lt;a href="https://www.kaggle.com/c/dogs-vs-cats/submissions/attach"&gt;Kaggle&lt;/a&gt;, it give an accuracy of 0.89691.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/kaggle-1.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;5. Building a Cat/Dog Classifier using Transfer Learning&lt;/h1&gt;
&lt;p&gt;In this section, we will use a very practical and powerful technique called transfer learning for building our cat/dog classifier.&lt;/p&gt;
&lt;h2&gt;5.1 What is Transfer Learning?&lt;/h2&gt;
&lt;p&gt;Convolutional neural networks require large datasets and a lot of computional time to train. Some networks could take up to 2-3 weeks across multiple GPUs to train. Transfer learning is a very useful technique that tries to address both problems. Instead of training the network from scratch, transfer learning utilizes a trained model on a different dataset, and adapts it to the problem that we're trying to solve. &lt;/p&gt;
&lt;p&gt;There are 2 strategies for transfer learning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Utilize the trained model as a fixed feature extractor: In this strategy, we remove the last fully connected layer from the trained model, we freeze the weights of the remaining layers, and we train a machine learning classifier on the output of the remaining layers. &lt;/li&gt;
&lt;li&gt;Fine-tune the trained model: In this strategy, we fine tune the trained model on the new dataset by continuing the backpropagation. We can either fine-tune the whole network or freeze some of its layers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a detailed explanation of transfer learning, I recommend reading these &lt;a href="http://cs231n.github.io/transfer-learning/"&gt;notes&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;5.2 Training the Cat/Dog Classifier using Transfer Learning&lt;/h2&gt;
&lt;p&gt;Caffe comes with a repository that is used by researchers and machine learning practitioners to share their trained models. This library is called &lt;a href="https://github.com/BVLC/caffe/wiki/Model-Zoo"&gt;Model Zoo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We will utilize the trained &lt;a href="https://github.com/BVLC/caffe/tree/master/models/bvlc_reference_caffenet"&gt;bvlc_reference_caffenet&lt;/a&gt; as a starting point of building our cat/dog classifier using transfer learning. This model was trained on the &lt;a href="http://www.image-net.org/"&gt;ImageNet dataset&lt;/a&gt; which contains millions of images across 1000 categories.&lt;/p&gt;
&lt;p&gt;We will use the fine-tuning strategy for training our model. &lt;/p&gt;
&lt;h3&gt;Download trained bvlc_reference_caffenet model&lt;/h3&gt;
&lt;p&gt;We can download the trained model by executing the command below.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cd&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;bvlc_reference_caffenet&lt;/span&gt;
&lt;span class="n"&gt;wget&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;dl&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;caffe&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;berkeleyvision&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;bvlc_reference_caffenet&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;caffemodel&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Model Definition&lt;/h3&gt;
&lt;p&gt;The model and solver configuration files are stored under &lt;code&gt;deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_2&lt;/code&gt;.
We need to make the following change to the original bvlc_reference_caffenet model configuration file.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Change the path for input data and mean image: Lines 24, 40 and 51.&lt;/li&gt;
&lt;li&gt;Change the name of the last fully connected layer from fc8 to fc8-cats-dogs. Lines 360, 363, 387 and 397.&lt;/li&gt;
&lt;li&gt;Change the number of outputs from 1000 to 2: Line 373. The original bvlc_reference_caffenet was designed for a classification problem with 1000 classes. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that if we keep a layer's name unchanged and we pass the trained model's weights to Caffe, it will pick its weights from the trained model. If we want to freeze a layer, we need to setup its &lt;code&gt;lr_mult&lt;/code&gt; parameter to 0.&lt;/p&gt;
&lt;p&gt;[gist:id=42696a9e64a08d7c1b1883d830857d48,file=caffenet_train_val_2.prototxt]&lt;/p&gt;
&lt;h3&gt;Solver Definition&lt;/h3&gt;
&lt;p&gt;We will use a similar solver to the one used in section 4.5.&lt;/p&gt;
&lt;p&gt;[gist:id=42696a9e64a08d7c1b1883d830857d48,file=solver_2.prototxt]&lt;/p&gt;
&lt;h3&gt;Model Training with Transfer Learning&lt;/h3&gt;
&lt;p&gt;After defining the model and the solver, we can start training the model by executing the command below. Note that we can pass the trained model's weights by using the argument &lt;code&gt;--weights&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tools&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt; &lt;span class="c1"&gt;--solver=/home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_2/solver_2.prototxt --weights /home/ubuntu/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel 2&amp;gt;&amp;amp;1 | tee /home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_2/model_2_train.log&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Plotting the Learning Curve&lt;/h3&gt;
&lt;p&gt;Similarly to the previous section, we can plot the learning curve by executing the command below. We can see from the learning curve that the model achieved an accuracy of ~97% after 1000 iterations only. This shows the power of transfer learning. We were able to get a higher accuracy with a smaller number of iterations.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;plot_learning_curve&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_model_2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;model_2_train&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;deeplearning&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dogs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tutorial&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_models&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_model_2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;caffe_model_2_learning_curve&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/caffe_model_2_learning_curve.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h3&gt;Prediction on New Data&lt;/h3&gt;
&lt;p&gt;Similary to section 4.7, we will generate predictions on the test data and upload the results to Kaggle to get the model accuracy. The code for making the predicitions is under &lt;code&gt;deeplearning-cats-dogs-tutorial/code/make_predictions_2.py&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;The model got an accuracy of 0.97154 which is better than the model that we trained from scratch. &lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/kaggle-2.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this blog post, we covered core concepts of deep learning and convolutional neural networks. We also learned how to build convolutional neural networks using Caffe and Python from scratch and using transfer learning. If you want to learn more about this topic, I highly recommend Stanford's &lt;a href="http://cs231n.github.io/"&gt;"Convolutional Neural Networks for Visual Recognition" course&lt;/a&gt;. &lt;/p&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://cs231n.github.io/neural-networks-1/"&gt;CS231n - Neural Networks Part 1: Setting up the Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Convolutional_neural_network"&gt;Wikipedia - Convolutional Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs231n.github.io/transfer-learning/"&gt;CS231n - Transfer Learning Notes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/"&gt;A Step by Step Backpropagation Example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs231n.github.io/"&gt;CS231n Convolutional Neural Networks for Visual Recognition&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="deep learning"></category><category term="deep learning"></category><category term="machine learning"></category><category term="python"></category><category term="caffe"></category></entry><entry><title>Clustering of vaccine temporal data in timeline</title><link href="https://mmadkour.xyz%5Cposts/2015/02/Temporal%20clinical%20events%20clustering/" rel="alternate"></link><published>2015-02-18T16:00:00-05:00</published><updated>2015-02-18T16:00:00-05:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2015-02-18:/2015/02/Temporal clinical events clustering/</id><summary type="html">&lt;p&gt;Events in clinical narratives are naturally associated with medical trials, including surgery, vaccination, lab test, medication, medical procedure, and diagnosis. They are interrelated with many temporal relations. The grouping of medical events onto temporal clusters is a key to applications such as longitudinal studies, clinical question answering, and information retrieval …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Events in clinical narratives are naturally associated with medical trials, including surgery, vaccination, lab test, medication, medical procedure, and diagnosis. They are interrelated with many temporal relations. The grouping of medical events onto temporal clusters is a key to applications such as longitudinal studies, clinical question answering, and information retrieval. However, it is difficult to define clinical event quantitatively or consistently in coarse time-bins (e.g. before vaccination or after admission). In this article, I developed the K-means classifier to enable labeling a sequence of medical events with predefined time-bins. The features set is based solely on temporal distance similarity between boundaries of events. The result of the solution is integrated with the &lt;a href="https://timeline.knightlab.com/"&gt;KnightLab timeline JS tool&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this article I investigate the task of tagging a sequence of events using a clustering algorithm. For this purpose I assume that each medical note can be associated with a predefined set of coarse of times that I refer to as time bins. For our example of VAERS note, the potential time-bins are: “before vaccination”, “soon after vaccination”, and “way after vaccination”. The time-bin “before vaccination” is intended to capture past medical history of the patient including the medical state of the patient on time of vaccination; “soon after vaccination” captures medical events that occurred immediately after the vaccination; and “way after vaccination” captures medical events that occurred after an extended duration from the vaccination. The issue in clustering events in predefined time-bins is that the time duration of each timebin varies based on the patient. For instance, the coarse of time “soon
after vaccination” could be the first few hours after or a few days
after depending on the general conditions. For that I consider that
related events happen in relatively close proximity of time. I use a
non-hierarchical clustering to classify the set of events. I consider
the temporal distance between events as the measure of similarity
between events of same clusters and dissimilarity between events of
different clusters.&lt;/p&gt;
&lt;h2&gt;K-Means Clustering&lt;/h2&gt;
&lt;p&gt;K-means is one of the simplest algorithms for solving the
clustering problem. Clustering is an unsupervised learning
problem whereby I aim to group subsets of entities with one
another based on a temporal distance similarity. The idea is to define
k centroids for the k assumed clusters and to associate each point
belonging to a given data set to the nearest center. A point represents
the time instant of the event or the center of interval if its time
interval event. When no point is pending, the first step is completed
and an early group age is done. At this point I re-calculate k new
centroids as barycenter of the clusters resulting from the previous
step. After I have these k new centroids, I re-bind the same data
set points to their nearest new center. A loop has been generated. As
a result of this loop the k centers change their location step by step
until no more changes are done or in other words centres do not
move any more.&lt;/p&gt;
&lt;h2&gt;Timeline View&lt;/h2&gt;
&lt;p&gt;For data that relates to temporal events, the Timeline Widget adds an interesting dimension to your exhibit.&lt;/p&gt;
&lt;p&gt;The nobelists.js data file lists the years when the Nobelists won their prizes, so I can plot each one on a time line. To display timelines in Exhibit you need to include a separate utility, the Timeline widget. The Timeline widget is a bit bulky, so Exhibit doesn't include it by default. You have to include the time extension to Exhibit. Open the file nobelists.html, find the reference to exhibit-api.js and add the following script element after it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nv"&gt;div&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;role&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;view&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;view&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;Timeline&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;  
    &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;.time&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; 
    &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;.time2&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; 
    &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;color&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;.cluster&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; 
    &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;top&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;band&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;unit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;month&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; 
    &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;bottom&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;band&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;unit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;year&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; 
    &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;top&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;band&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;pixels&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;per&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;unit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;90&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; 
    &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;bottom&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;band&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;pixels&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;per&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;unit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;400&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nv"&gt;div&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;role&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;lens&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nv"&gt;span&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;content&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;.hour&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nv"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;: 
                &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nv"&gt;span&lt;/span&gt; &lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;content&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;.label&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nv"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nv"&gt;div&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nv"&gt;div&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Visualization&lt;/h2&gt;
&lt;p&gt;I visualize the results using the Exhibit dashboard
solution. The timeline dashboard enables intuitive cluster analysis
by user interactions. Also our visualization allows summarizing by
the various types of events information. &lt;img alt="Here is a screeshot of the visualization" src="/images/timeline.png"&gt; Check out the &lt;a href="http://htmlpreview.github.io/?https://github.com/mohcinemadkour/Event-Timeline/blob/master/index.html"&gt;visualization of clustered events&lt;/a&gt;&lt;/p&gt;</content><category term="Clustering, K-Means"></category><category term="K-means"></category><category term="data visualization"></category><category term="VAERS Reports"></category></entry><entry><title>An Introduction to Agent-based Models: Simulating Segregation with Python</title><link href="https://mmadkour.xyz%5Cposts/2014/09/schelling-model/" rel="alternate"></link><published>2014-09-23T00:00:00-04:00</published><updated>2014-09-23T00:00:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2014-09-23:/2014/09/schelling-model/</id><summary type="html">&lt;p&gt;In this post, I will explain about Schelling's segregation model, implement the same in Python programming language, and explain the power of agent based simulations for understanding complex phenomenon.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;This article was originally published on &lt;a href="https://www.binpress.com/tutorial/introduction-to-agentbased-models-an-implementation-of-schelling-model-in-python/144"&gt;Binpress&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In computer science, agent-based models are used to assess the effects of autonomous agents (i.e. individuals, groups or objects) on an overall system. They're very powerful analytical tools that can be used in situations where experiments aren't feasible or are very expensive to conduct. These models have a wide range of applications in the social sciences, computer science, economics and business.&lt;/p&gt;
&lt;p&gt;In this piece, I'll introduce you to the power of agent-based models when used to understand complex phenomenons. To do this, we'll use some Python, a social science case study and the Schelling model.&lt;/p&gt;
&lt;h1&gt;1. The case study&lt;/h1&gt;
&lt;p&gt;If you look at the racial distribution of multi-ethnic cities, you'll be astonished by the incredible racial segregation. For example, the New York City map below represents data from the 2010 US Census color-coded by race. You can clearly see the racial segregation.&lt;/p&gt;
&lt;p&gt;Many would conclude from such phenomena that people are intolerant, and don't want to live next to people that are different from them. A deeper look, however, might provide some nuance. In the 70's, Thomas Schelling, the 2005 Economics Nobel Prize winner, was interested in this subject and built an agent-based model called the "Schelling segregation model" for explaining this phenomenon. With a very simple model, Schelling could show that what we see at the macro level may not in fact represent what's going down in the micro level.&lt;/p&gt;
&lt;p&gt;We'll run a few simulations using the Schelling model to get a deeper understanding of the segregation phenomena.&lt;/p&gt;
&lt;div style="text-align:left"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/NY_racial_map.jpg"&gt;
Source: &lt;a href="http://demographics.coopercenter.org/DotMap/index.html"&gt;http://demographics.coopercenter.org/DotMap/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;2. Schelling Segregation Model: Setting and Definitions&lt;/h1&gt;
&lt;p&gt;Agent-based models need three parameters: 1) Agents, 2) Behavior (rules) and 3) Metrics at the aggregated level. In the Schelling model, the agents are the people living in the city, the behavior is the house moving based on the similarity ratio and the metrics at the aggregated level is the similarity ratio.&lt;/p&gt;
&lt;p&gt;Let n be the number of races living in a city. We represent each race by a unique color and we represent the city by a grid where each cell represents a house. A house can be either empty or full. A full house can have have only one person living in it. If the house is empty, we color it in white. If the house is full, we color it by the color of the person living in it. We define the neighbors of a person to be the people living in the adjacent houses (Up, Bottom, Left, Right, Up-Left, Up-Right, Bottom-Left, Bottom-Right).&lt;/p&gt;
&lt;p&gt;Schelling's goal was to test what would happen if people had a small preference that their neighbors be of the same color (or even preference for some diversity). If the ratio of neighbors of the same race is above a certain threshold (that we call Similarity Threshold), we say that the person is satisfied. If not, we say that the person is unsatisfied.&lt;/p&gt;
&lt;p&gt;The Schelling simulation goes as follows. We start by randomly putting people in the city and we leave some houses empty. For each person living in the city, we check if he/she is satisfied. If satisfied, we don't do anything. If not, we move the person to an empty house. We run this simulation for a few iterations, and we check the final distribution of the people.&lt;/p&gt;
&lt;h1&gt;3. Python Implementation of Schelling Model&lt;/h1&gt;
&lt;p&gt;Back in the 70s, Schelling used pennies and nickels on a piece of paper for his simulation. We'll use Python for building the same simulation.&lt;/p&gt;
&lt;p&gt;We start by importing the necessary libraries for running the simulations. All libraries except &lt;code&gt;Matplotlib&lt;/code&gt; are installed by default in Python. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;itertools&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;copy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we define a class called &lt;code&gt;Schelling&lt;/code&gt;. This class takes 6 parameters: the width and height of the city, the ratio of empty houses in the city, the similarity threshold, the number of iterations and the number of races. We define 4 methods within the &lt;code&gt;Schelling&lt;/code&gt; class: &lt;code&gt;populate&lt;/code&gt;, &lt;code&gt;is_unsatisfied&lt;/code&gt;, &lt;code&gt;update&lt;/code&gt;, &lt;code&gt;move_to_empty&lt;/code&gt;, and &lt;code&gt;plot&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Schelling&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;empty_ratio&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;similarity_threshold&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;races&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; 
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt; 
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;races&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;races&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_ratio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;empty_ratio&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similarity_threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;similarity_threshold&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;populate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="o"&gt;....&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;is_unsatisfied&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="o"&gt;....&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;        
        &lt;span class="o"&gt;....&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;move_to_empty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="o"&gt;....&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="o"&gt;....&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;populate&lt;/code&gt; method is used at the beginning of the simulation. This method distributes randomly people in the grid. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;populate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all_houses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;itertools&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;product&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
    &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all_houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_empty&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_ratio&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all_houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all_houses&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_empty&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remaining_houses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all_houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_empty&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
    &lt;span class="n"&gt;houses_by_race&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remaining_houses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;races&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;races&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;races&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;#create agents for each race&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; 
                            &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses_by_race&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;houses_by_race&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                        &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;is_unsatisfied&lt;/code&gt; method takes as arguments the &lt;code&gt;(x, y)&lt;/code&gt; coordinates of a house, check the ratio of neighbors of similar color, and returns &lt;code&gt;True&lt;/code&gt; if the ratio is above the happiness threshold, otherwise it returns &lt;code&gt;False&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;is_unsatisfied&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="n"&gt;race&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;        
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;        
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;        
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count_similar&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;count_different&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count_similar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count_similar&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;count_different&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;happy_threshold&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;update&lt;/code&gt; method checks if each person in the grid is unsatisfied, if yes it assigns the person to a randomly chosen empty house. It runs this process &lt;code&gt;n_iterations&lt;/code&gt; times.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;old_agents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;deepcopy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;n_changes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;agent&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;old_agents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_unhappy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
                &lt;span class="n"&gt;agent_race&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;empty_house&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;empty_house&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;agent_race&lt;/span&gt;
                &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;empty_house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;n_changes&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;n_changes&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;n_changes&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;move_to_empty&lt;/code&gt; method takes as arguments the &lt;code&gt;(x, y)&lt;/code&gt; coordinates of a house, and moves the person living in the &lt;code&gt;(x, y)&lt;/code&gt; house to an empty house. This method is called within the &lt;code&gt;update&lt;/code&gt; method to move the unsatisfied people to empty houses.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;move_to_empty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;race&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;empty_house&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;updated_agents&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;empty_house&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;
    &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;updated_agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;empty_house&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;plot&lt;/code&gt; method is used to draw the whole city and people living in the city. We can call this method at anytime to check the distribution of people in the city. This method takes 2 arguments &lt;code&gt;title&lt;/code&gt;, and &lt;code&gt;file_name&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;#If you want to run the simulation with more than 7 colors, you should set agent_colors accordingly&lt;/span&gt;
    &lt;span class="n"&gt;agent_colors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;g&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;m&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;k&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;agent&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;agent_colors&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontweight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticks&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_yticks&lt;/span&gt;&lt;span class="p"&gt;([])&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;4. Simulations&lt;/h1&gt;
&lt;p&gt;Now that we have our implementation of the &lt;code&gt;Schelling&lt;/code&gt; class, we can run different simulations and plot the results.  we will build 3 simulations with the following characteristics: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;width = 50, and height = 50 (2500 houses)&lt;/li&gt;
&lt;li&gt;30% of empty houses&lt;/li&gt;
&lt;li&gt;Similarity Threshold = 30% (for Simulation 1), Similarity Threshold = 50% (for Simulation 2), and Similarity Threshold = 80% (for Simulation 3)&lt;/li&gt;
&lt;li&gt;Maximum number of iterations = 500&lt;/li&gt;
&lt;li&gt;Number of races = 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We start by creating and populating the cities.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;schelling_1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Schelling&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;schelling_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;populate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;schelling_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Schelling&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;schelling_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;populate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;schelling_3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Schelling&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;schelling_3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;populate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we plot the city at the initial phase. Note that the Similarity threshold has no effect on the initial state of the city.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;schelling_1_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Schelling Model with 2 colors: Initial State&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;schelling_2_initial.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we run the &lt;code&gt;update&lt;/code&gt; method, and we plot the final distribution for both Similarity thresholds.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;schelling_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;schelling_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;schelling_3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;schelling_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Schelling Model with 2 colors: Final State with Similarity Threshold 30%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;schelling_2_30_final.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;schelling_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Schelling Model with 2 colors: Final State with Similarity Threshold 50%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;schelling_2_50_final.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;schelling_3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Schelling Model with 2 colors: Final State with Similarity Threshold 80%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;schelling_2_80_final.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/schelling_2_initial.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/schelling_2_30_final.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/schelling_2_50_final.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/schelling_2_80_final.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Looking at the plots above, we can see that the higher the similarity threshold, the more segregated the city becomes. Furthermore, we can see that even with a small similarity threshold, we get segregated cities. In other words, even if the people are very tolerant (i.e. having a small Similarity threshold), we end up with segregation. We can conclude that what we see at the macro level may not in fact represent what's going down in the micro level.&lt;/p&gt;
&lt;h1&gt;5. Measuring Segregation&lt;/h1&gt;
&lt;p&gt;In the simulation above, we used visual representations to confirm the segregation. However, we don't have any quantitative measure for calculating segregation. We will define this measure in this section, and we will run a few simulations to check the relationship between the happiness threshold and the segregation level.&lt;/p&gt;
&lt;p&gt;First we will add a method to the &lt;code&gt;Schelling&lt;/code&gt; class called &lt;code&gt;calculate_similarity&lt;/code&gt;. This method returns the calculate the similarity ratio for each agent and returns the mean similarity ratio. We will use the mean similarity ratio as a measure of segregation.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;calculate_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;similarity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;agent&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;race&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;        
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;        
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;        
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_houses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agents&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;race&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_similar&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count_different&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count_similar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count_similar&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;count_different&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we will calculate the mean similarity ratio for different similarity thresholds, and we will plot the relationship between the similarity threshold and the similarity ratio.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;similarity_threshold_ratio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="n"&gt;schelling&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Schelling&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;schelling&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;populate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;schelling&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;similarity_threshold_ratio&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;schelling&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;calculate_similarity&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;similarity_threshold_ratio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;similarity_threshold_ratio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ro&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Similarity Threshold vs. Mean Similarity Ratio&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontweight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Similarity Threshold&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Mean Similarity Ratio&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;schelling_segregation_measure.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/schelling_segregation_measure.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can see from the plot above that for very small similarity thresholds, we get very high segregation (defined by the mean similarity ratio). For example, for a similarity threshold of 0.3, we got a mean similarity ratio of 0.75. We could confirm quantitatively that what we see at the macro level may not in fact represent what's going down in the micro level.&lt;/p&gt;
&lt;h1&gt;6. Wrap-up&lt;/h1&gt;
&lt;p&gt;In this article, we've introduced one example of agent-based models called, the Schelling segregation model, and we implemented it in Python. This very simple model helped us understand a very complex phenomena, namely segregation in multi-ethnics cities. We could show that a very high segregation level in these cities doesn't necessarily translate into intolerance at the individual level.&lt;/p&gt;
&lt;p&gt;All source code from this post can be found in this &lt;a href="https://gist.github.com/mohcinemadkour/87d3ac123d64e13e95e4a83fa3f5383e"&gt;github Gist file&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p&gt;https://www.coursera.org/course/modelthinking&lt;/p&gt;</content><category term="analytics"></category><category term="python"></category><category term="matplotlib"></category><category term="simulation"></category></entry><entry><title>An Introduction to Text Mining using Twitter Streaming API and Python</title><link href="https://mmadkour.xyz%5Cposts/2014/07/twitter-analytics/" rel="alternate"></link><published>2014-07-21T00:00:00-04:00</published><updated>2014-07-21T00:00:00-04:00</updated><author><name>Mohcine Madkour</name></author><id>tag:mmadkour.xyz\posts,2014-07-21:/2014/07/twitter-analytics/</id><summary type="html">&lt;p&gt;In this tutorial, I will use Twitter data to compare the popularity of 3 programming languages: Python, Javascript and Ruby, and to retrieve links to programming tutorials.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Text mining is the application of natural language processing techniques and analytical methods to text data in order to derive relevant information. Text mining is getting a lot attention these last years, due to an exponential increase in digital text data from web pages, google's projects such as &lt;a href="http://books.google.com/"&gt;google books&lt;/a&gt; and &lt;a href="https://books.google.com/ngrams"&gt;google ngram&lt;/a&gt;, and social media services such as Twitter. Twitter data constitutes a rich source that can be used for capturing information about any topic imaginable. This data can be used in different use cases such as finding trends related to a specific keyword, measuring brand sentiment, and gathering feedback about new products and services.&lt;/p&gt;
&lt;p&gt;In this tutorial, I will use Twitter data to compare the popularity of 3 programming languages: Python, Javascript and Ruby, and to retrieve links to programming tutorials. In the first paragraph, I will explaing how to connect to Twitter Streaming API and how to get the data. In the second paragraph, I will explain how to structure the data for analysis, and in the last paragraph, I will explain how to filter the data and extract links from tweets.&lt;/p&gt;
&lt;p&gt;Using only 2 days worth of Twitter data, I could retrieve 644 links to python tutorials, 413 to javascript tutorials and 136 to ruby tutorials. Furthermore, I could confirm that python is 1.5 times more popular than javascript and 4 times more popular than ruby.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/Twitter-analytics.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;1. Getting Data from Twitter Streaming API&lt;/h1&gt;
&lt;p&gt;API stands for Application Programming Interface. It is a tool that makes the interaction with computer programs and web services easy. Many web services provides APIs to developers to interact with their services and to access data in programmatic way. For this tutorial, we will use Twitter Streaming API to download tweets related to 3 keywords: "python", "javascript", and "ruby".&lt;/p&gt;
&lt;h2&gt;Step 1: Getting Twitter API keys&lt;/h2&gt;
&lt;p&gt;In order to access Twitter Streaming API, we need to get 4 pieces of information from Twitter: API key, API secret, Access token and Access token secret. Follow the steps below to get all 4 elements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a twitter account if you do not already have one.&lt;/li&gt;
&lt;li&gt;Go to https://apps.twitter.com/ and log in with your twitter credentials.&lt;/li&gt;
&lt;li&gt;Click "Create New App"&lt;/li&gt;
&lt;li&gt;Fill out the form, agree to the terms, and click "Create your Twitter application"&lt;/li&gt;
&lt;li&gt;In the next page, click on "API keys" tab, and copy your "API key" and "API secret".&lt;/li&gt;
&lt;li&gt;Scroll down and click "Create my access token", and copy your "Access token" and "Access token secret".&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Step 2: Connecting to Twitter Streaming API and downloading data&lt;/h2&gt;
&lt;p&gt;We will be using a Python library called &lt;code&gt;Tweepy&lt;/code&gt; to connect to Twitter Streaming API and downloading the data. If you don't have &lt;code&gt;Tweepy&lt;/code&gt; installed in your machine, go to this &lt;a href="https://github.com/tweepy/tweepy"&gt;link&lt;/a&gt;, and follow the installation instructions.&lt;/p&gt;
&lt;p&gt;Next create, a file called &lt;code&gt;twitter_streaming.py&lt;/code&gt;, and copy into it the code below. Make sure to enter your credentials into &lt;code&gt;access_token&lt;/code&gt;, &lt;code&gt;access_token_secret&lt;/code&gt;, &lt;code&gt;consumer_key&lt;/code&gt;, and &lt;code&gt;consumer_secret&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#Import the necessary methods from tweepy library&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tweepy.streaming&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StreamListener&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tweepy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;OAuthHandler&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tweepy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Stream&lt;/span&gt;

&lt;span class="c1"&gt;#Variables that contains the user credentials to access Twitter API &lt;/span&gt;
&lt;span class="n"&gt;access_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ENTER YOUR ACCESS TOKEN&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;access_token_secret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ENTER YOUR ACCESS TOKEN SECRET&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;consumer_key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ENTER YOUR API KEY&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;consumer_secret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ENTER YOUR API SECRET&amp;quot;&lt;/span&gt;


&lt;span class="c1"&gt;#This is a basic listener that just prints received tweets to stdout.&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;StdOutListener&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;StreamListener&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="c1"&gt;#This handles Twitter authetification and the connection to Twitter Streaming API&lt;/span&gt;
    &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StdOutListener&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;auth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;OAuthHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;consumer_key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;consumer_secret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;auth&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_access_token&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;access_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;access_token_secret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;stream&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;auth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;#This line filter Twitter Streams to capture data by the keywords: &amp;#39;python&amp;#39;, &amp;#39;javascript&amp;#39;, &amp;#39;ruby&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;track&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;javascript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you run the program from your terminal using the command: &lt;code&gt;python twitter_streaming.py&lt;/code&gt;, you will see data flowing like the picture below.&lt;/p&gt;
&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/twitter_streaming.jpg"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can stop the program by pressing Ctrl-C.&lt;/p&gt;
&lt;p&gt;We want to capture this data into a file that we will use later for the analysis. You can do so by piping the output to a file using the following command: &lt;code&gt;python twitter_streaming.py &amp;gt; twitter_data.txt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I run the program for 2 days (from 2014/07/15 till 2014/07/17) to get a meaningful data sample. This file size is 242 MB.&lt;/p&gt;
&lt;h1&gt;2. Reading and Understanding the data&lt;/h1&gt;
&lt;p&gt;The data that we stored &lt;code&gt;twitter_data.txt&lt;/code&gt; is in JSON format. JSON stands for JavaScript Object Notation. This format makes it easy to humans to read the data, and for machines to parse it. Below is an example for one tweet in JSON format. You can see that the tweet contains additional information in addition to the main text which in this example: &lt;code&gt;"Yaayyy I learned some JavaScript today! #thatwasntsohard #yesitwas #stoptalkingtoyourself #hashbrown #hashtag"&lt;/code&gt;. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;created_at&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Tue Jul 15 14:19:30 +0000 2014&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;489051636304990208&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id_str&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;489051636304990208&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Yaayyy I learned some JavaScript today! #thatwasntsohard #yesitwas #stoptalkingtoyourself #hashbrown #hashtag&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;source&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;\u003ca href=\&amp;quot;http:\/\/twitter.com\/download\/iphone\&amp;quot; rel=\&amp;quot;nofollow\&amp;quot;\u003eTwitter for iPhone\u003c\/a\u003e&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;truncated&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;in_reply_to_status_id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;in_reply_to_status_id_str&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;in_reply_to_user_id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;in_reply_to_user_id_str&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;in_reply_to_screen_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;user&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2301702187&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id_str&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;2301702187&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Toni Barlettano&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;screen_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;itsmetonib&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;location&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Greater NYC Area&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;url&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http:\/\/www.tonib.me&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;So Full of Art   |   \nToni Barlettano Creative Media + Design&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;protected&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;followers_count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;friends_count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;listed_count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;created_at&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Mon Jan 20 16:49:46 +0000 2014&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;favourites_count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;utc_offset&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;time_zone&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;geo_enabled&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;verified&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;statuses_count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;lang&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;contributors_enabled&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;is_translator&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;is_translation_enabled&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_background_color&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;C0DEED&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_background_image_url&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http:\/\/abs.twimg.com\/images\/themes\/theme1\/bg.png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_background_image_url_https&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;https:\/\/abs.twimg.com\/images\/themes\/theme1\/bg.png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_background_tile&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_image_url&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http:\/\/pbs.twimg.com\/profile_images\/425313048320958464\/Z2GcderW_normal.jpeg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_image_url_https&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;https:\/\/pbs.twimg.com\/profile_images\/425313048320958464\/Z2GcderW_normal.jpeg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_link_color&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;0084B4&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_sidebar_border_color&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;C0DEED&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_sidebar_fill_color&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;DDEEF6&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_text_color&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;333333&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;profile_use_background_image&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;default_profile&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;default_profile_image&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;following&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;follow_request_sent&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;notifications&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;geo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;coordinates&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;place&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;contributors&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;retweet_count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;favorite_count&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;entities&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;hashtags&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;thatwasntsohard&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;indices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;56&lt;/span&gt;&lt;span class="p"&gt;]},{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;yesitwas&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;indices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;57&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;66&lt;/span&gt;&lt;span class="p"&gt;]},{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;stoptalkingtoyourself&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;indices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;67&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;89&lt;/span&gt;&lt;span class="p"&gt;]},{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hashbrown&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;indices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;90&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;]},{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hashtag&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;indices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;101&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;109&lt;/span&gt;&lt;span class="p"&gt;]}],&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;symbols&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[],&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;urls&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[],&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;user_mentions&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[]},&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;favorited&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;retweeted&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;filter_level&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;medium&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;lang&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For the remaining of this tutorial, we will be using 4 Python libraries &lt;code&gt;json&lt;/code&gt; for parsing the data, &lt;code&gt;pandas&lt;/code&gt; for data manipulation, &lt;code&gt;matplotlib&lt;/code&gt; for creating charts, adn &lt;code&gt;re&lt;/code&gt; for regular expressions. The &lt;code&gt;json&lt;/code&gt; and &lt;code&gt;re&lt;/code&gt; libraries are installed by default in Python.  You should install &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;matplotlib&lt;/code&gt; if you don't have them in your machine.&lt;/p&gt;
&lt;p&gt;We will start first by uploading &lt;code&gt;json&lt;/code&gt; and &lt;code&gt;pandas&lt;/code&gt; using the commands below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next we will read the data in into an array that we call &lt;code&gt;tweets&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets_data_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;../data/twitter_data.txt&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;tweets_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;tweets_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tweets_data_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;r&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tweets_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;tweet&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;tweets_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;continue&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can print the number of tweets using the command below. For the dataset that I prepared, the number is 71238.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tweets_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we will structure the tweets data into a pandas DataFrame to simplify the data manipulation. We will start by creating an empty DataFrame called &lt;code&gt;tweets&lt;/code&gt; using the following command.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we will add 3 columns to the &lt;code&gt;tweets&lt;/code&gt; DataFrame called &lt;code&gt;text&lt;/code&gt;, &lt;code&gt;lang&lt;/code&gt;, and &lt;code&gt;country&lt;/code&gt;. &lt;code&gt;text&lt;/code&gt; column contains the tweet, &lt;code&gt;lang&lt;/code&gt; column contains the language in which the tweet was written, and &lt;code&gt;country&lt;/code&gt; the country from which the tweet was sent.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;tweets_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lang&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lang&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;tweets_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;country&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;place&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;country&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;place&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweets_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we will create 2 charts: The first one describing the Top 5 languages in which the tweets were written, and the second the Top 5 countries from which the tweets were sent.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets_by_lang&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lang&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tick_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labelsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tick_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labelsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Languages&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Number of tweets&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Top 5 languages&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontweight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tweets_by_lang&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;red&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/tweets_top_langs.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets_by_country&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;country&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tick_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labelsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tick_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labelsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Countries&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Number of tweets&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Top 5 countries&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontweight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tweets_by_country&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;blue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/tweets_top_countries.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h1&gt;3. Mining the tweets&lt;/h1&gt;
&lt;p&gt;Our main goals in these text mining tasks are: compare the popularity of Python, Ruby and Javascript programming languages and to retrieve programming tutorial links. We will do this in 3 steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We will add tags to our &lt;code&gt;tweets&lt;/code&gt; DataFrame in order to be able to manipualte the data easily.&lt;/li&gt;
&lt;li&gt;Target tweets that have "pogramming" or "tutorial" keywords.&lt;/li&gt;
&lt;li&gt;Extract links from the relevants tweets&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Adding Python, Ruby, and Javascript tags&lt;/h2&gt;
&lt;p&gt;First, we will create a function that checks if a specific keyword is present in a text. We will do this by using &lt;a href="http://en.wikipedia.org/wiki/Regular_expression"&gt;regular expressions&lt;/a&gt;. Python provides a library for regular expression called &lt;code&gt;re&lt;/code&gt;. We will start by importing this library&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next we will create a function called &lt;code&gt;word_in_text(word, text)&lt;/code&gt;. This function return &lt;code&gt;True&lt;/code&gt; if a &lt;code&gt;word&lt;/code&gt; is found in &lt;code&gt;text&lt;/code&gt;, otherwise it returns &lt;code&gt;False&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;word_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we will add 3 columns to our &lt;code&gt;tweets&lt;/code&gt; DataFrame. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;word_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;javascript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;word_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;javascript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;word_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can calculate the number of tweets for each programming language as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;javascript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This returns: 21839 for python, 16154 for javascript and 31410 for ruby. We can make a simple comparaison chart by executing the following: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;prg_langs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;javascript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tweets_by_prg_lang&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;javascript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;

&lt;span class="n"&gt;x_pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prg_langs&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_pos&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweets_by_prg_lang&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;g&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Setting axis labels and ticks&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Number of tweets&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Ranking: python vs. javascript vs. ruby (Raw data)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontweight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticks&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x_pos&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticklabels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prg_langs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/top_prg_lang_raw.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This shows, that the keyword &lt;code&gt;ruby&lt;/code&gt; is the most popular, followed by &lt;code&gt;python&lt;/code&gt; then &lt;code&gt;javascript&lt;/code&gt;. However, the &lt;code&gt;tweets&lt;/code&gt; DataFrame contains information about all tweets that contains one of the 3 keywords and doesn't restrict the information to the programming languages. For example, there are a lot tweets that contains the keyword &lt;code&gt;ruby&lt;/code&gt; and that are related to a political scandal called &lt;a href="http://en.wikipedia.org/wiki/Rubygate"&gt;Rubygate&lt;/a&gt;. In the next section, we will filter the tweets and re-run the analysis to make a more accurate comparison.&lt;/p&gt;
&lt;h2&gt;Targeting relevant tweets&lt;/h2&gt;
&lt;p&gt;We are intersted in targetting tweets that are related to programming languages. Such tweets often have one of the 2 keywords: "programming" or "tutorial". We will create 2 additional columns to our &lt;code&gt;tweets&lt;/code&gt; DataFrame where we will add this information.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;programming&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;word_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;programming&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tutorial&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;word_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tutorial&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We will add an additional column called &lt;code&gt;relevant&lt;/code&gt; that take value &lt;code&gt;True&lt;/code&gt; if the tweet has either "programming" or "tutorial" keyword, otherwise it takes value &lt;code&gt;False&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;relevant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;word_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;programming&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;word_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tutorial&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can print the counts of relevant tweet by executing the commands below.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;programming&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tutorial&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;relevant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This returns, 871 for &lt;code&gt;programming&lt;/code&gt; column, 511 for &lt;code&gt;tutorial&lt;/code&gt; column, and 1356 for &lt;code&gt;relevant&lt;/code&gt; column.&lt;/p&gt;
&lt;p&gt;We can compare now the popularity of the programming languages by executing the commands below. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;relevant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;relevant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;javascript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;relevant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Python is the most popular with a count of 732, followed by javascript by a count of 473, and ruby by a count of 185. We can make a comparaison graph by executing the commands below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets_by_prg_lang&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;relevant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                      &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;relevant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;javascript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                      &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;relevant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;x_pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prg_langs&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_pos&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tweets_by_prg_lang&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;g&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Number of tweets&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Ranking: python vs. javascript vs. ruby (Relevant data)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontweight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticks&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x_pos&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticklabels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prg_langs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div style="text-align:center"&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/images/top_prg_lang_relevant.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Extracting links from the relevants tweets&lt;/h2&gt;
&lt;p&gt;Now that we extracted the relevant tweets, we want to retrieve links to programming tutorials. We will start by creating a function that uses regular expressions for retrieving link that start with "http://" or "https://" from a text. This function will return the url if found, otherwise it returns an empty string.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;extract_link&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;regex&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;https?://[^\s&amp;lt;&amp;gt;&amp;quot;]+|www\.[^\s&amp;lt;&amp;gt;&amp;quot;]+&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;regex&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we will add a column called &lt;code&gt;link&lt;/code&gt; to our &lt;code&gt;tweets&lt;/code&gt; DataFrame. This column will contain the urls information.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;link&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;extract_link&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tweet&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next we will create a new DataFrame called &lt;code&gt;tweets_relevant_with_link&lt;/code&gt;. This DataFrame is a subset of &lt;code&gt;tweets&lt;/code&gt; DataFrame and contains all relevant tweets that have a link.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tweets_relevant&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;relevant&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tweets_relevant_with_link&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tweets_relevant&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets_relevant&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;link&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can now print out all links for &lt;code&gt;python&lt;/code&gt;, &lt;code&gt;javascript&lt;/code&gt;, and &lt;code&gt;ruby&lt;/code&gt; by executing the commands below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets_relevant_with_link&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets_relevant_with_link&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;link&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets_relevant_with_link&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets_relevant_with_link&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;javascript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;link&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;tweets_relevant_with_link&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tweets_relevant_with_link&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ruby&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;link&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This returns 644 links for python, 413 links for javascript, and 136 for ruby. Below are some python related links&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://t.co/WmTccp3rb1"&gt;http://t.co/WmTccp3rb1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/5qE3vPAy7N"&gt;http://t.co/5qE3vPAy7N&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/1rvmhqPsXD"&gt;http://t.co/1rvmhqPsXD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/S9aq2AahjH"&gt;http://t.co/S9aq2AahjH&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/ORg6IL8qXT"&gt;http://t.co/ORg6IL8qXT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/EnK2UlDcJ8"&gt;http://t.co/EnK2UlDcJ8&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/gtu9WVQCLK"&gt;http://t.co/gtu9WVQCLK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/xvMTzqLGg0"&gt;http://t.co/xvMTzqLGg0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/bgMZ0jIpA7"&gt;http://t.co/bgMZ0jIpA7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/O03VrRyEAb"&gt;http://t.co/O03VrRyEAb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/CfWYefZML7"&gt;http://t.co/CfWYefZML7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/N3iU2ZYa2z"&gt;http://t.co/N3iU2ZYa2z&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/S9aq2AahjH"&gt;http://t.co/S9aq2AahjH&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://t.co/ytms7bcsQV"&gt;http://t.co/ytms7bcsQV&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this tutorial, we covered many techniques used in text mining. The code provide in this post could be modified to create a deeper analysis or could be adapted to another use case. For those who want to go further in text mining, I recommend to follow up by studying regular expressions.&lt;/p&gt;
&lt;p&gt;You can find the source code from this tutorial in this github repository &lt;a href="https://github.com/mohcinemadkour/Twitter_Analytics"&gt;github link&lt;/a&gt;. &lt;/p&gt;
&lt;h1&gt;references&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;http://en.wikipedia.org/wiki/Text_mining&lt;/li&gt;
&lt;li&gt;http://en.wikipedia.org/wiki/Word-sense_disambiguation&lt;/li&gt;
&lt;li&gt;http://en.wikipedia.org/wiki/Regular_expression&lt;/li&gt;
&lt;/ul&gt;</content><category term="analytics"></category><category term="python"></category><category term="pandas"></category><category term="text mining"></category><category term="matplotlib"></category><category term="twitter"></category><category term="api"></category></entry></feed>