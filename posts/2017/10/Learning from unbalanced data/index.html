<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Mohcine Madkour, Big Data Architectures and more">


        <title>Building Machine Learning models with Imbalanced data // Mohcine Madkour // Big Data Architectures and more</title>


    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../../../../theme/css/pure.css">
    <link rel="stylesheet" href="../../../../theme/css/pygments.css">

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fitvids/1.0.1/jquery.fitvids.min.js"></script>
    <script>
        $(document).ready(function(){
            $(".content").fitVids();
        });
    </script>
</head>

<body>
<div class="pure-g-r" id="layout">
    <div class="sidebar sidebar-article pure-u">
        <header class="header-article">
            <hgroup>
                <a href="../../../../author/mohcine-madkour.html" title="See posts by Mohcine Madkour">
                        <img class="avatar" alt="Mohcine Madkour" src="http://www.gravatar.com/avatar/ae08847efc1a85b710f326eb8ee2e907">
                </a>
                <h2 class="article-info">Mohcine Madkour</h2>
                <small class="about-author"></small>
                <h5>Published</h5>
                <p>Mon 09 October 2017</p>
                <a href="/">&larr;Home</a>
            </hgroup>
        </header>
    </div>
    <div class="pure-u">
        <div class="content">
            <section class="post">
                <header class="post-header">
                    <h1>Building Machine Learning models with Imbalanced data</h1>
                        <p class="post-meta">
                            // under                                 <a class="post-category" href="../../../../tag/unbalanced-data/">unbalanced data</a>
                                <a class="post-category" href="../../../../tag/roc/">ROC</a>
                                <a class="post-category" href="../../../../tag/auroc/">AUROC</a>
                                <a class="post-category" href="../../../../tag/aucpr/">AUCPR</a>
                                <a class="post-category" href="../../../../tag/f1-score/">F1 Score</a>
                                <a class="post-category" href="../../../../tag/recall/">Recall</a>
                                <a class="post-category" href="../../../../tag/precision/">Precision</a>
                        </p>
                </header>
            </section>
            <p>In this blog post, I'll discuss a number of considerations and techniques for dealing with imbalanced data when training a machine learning model. The blog post will rely heavily on a sklearn contributor package called <a href="https://imbalanced-learn.org/en/stable/index.html">imbalanced-learn</a> to implement the discussed techniques.
Training a machine learning model on an imbalanced dataset can introduce unique challenges to the learning problem. Imbalanced data typically refers to a classification problem where the number of observations per class is not equally distributed; often you'll have a large amount of data/observations for one class (referred to as the majority class), and much fewer observations for one or more other classes (referred to as the minority classes). For example, suppose you're building a classifier to classify a credit card transaction a fraudulent or authentic - you'll likely have 10,000 authentic transactions for every 1 fraudulent transaction, that's quite an imbalance!
To understand the challenges that a class imbalance imposes, let's consider two common ways we'll train a model: tree-based logical rules developed according to some splitting criterion, and parameterized models updated by gradient descent.
When building a tree-based model (such as a decision tree), our objective is to find logical rules which are capable of taking the full dataset and separating out the observations into their different classes. In other words, we'd like each split in the tree to increase the purity of observations such that the data is filtered into homogeneous groups. If we have a majority class present, the top of the decision tree is likely to learn splits which separate out the majority class into pure groups at the expense of learning rules which separate the minority class.</p>
<p><img alt="majority minority class" src="/images/ImbalancedData/Screen-Shot-2018-02-12-at-10.06.36-PM.png"></p>
<p>For a more concrete example, here's a decision tree trained on the wine quality dataset used as an example later on in this post. The field value represents the number of observations for each class in a given node.</p>
<p><img alt="Tree" src="/images/ImbalancedData/download-1.png"></p>
<p>Similarly, if we're updating a parameterized model by gradient descent to minimize our loss function, we'll be spending most of our updates changing the parameter values in the direction which allow for correct classification of the majority class. In other words, many machine learning models are subject to a frequency bias in which they place more emphasis on learning from data observations which occur more commonly.</p>
<p>It's worth noting that not all datasets are affected equally by class imbalance. Generally, for easy classification problems in which there's a clear separation in the data, class imbalance doesn't impede on the model's ability to learn effectively. However, datasets that are inherently more difficult to learn from see an amplification in the learning challenge when a class imbalance is introduced.</p>
<h1>Metrics</h1>
<p>When dealing with imbalanced data, standard classification metrics do not adequately represent your models performance. For example, suppose you are building a model which will look at a person's medical records and classify whether or not they are likely to have a rare disease. An accuracy of 99.5% might look great until you realize that it is correctly classifying the 99.5% of healthy people as "disease-free" and incorrectly classifying the 0.5% of people which do have the disease as healthy. I discussed this in my post on evaluating a machine learning model, but I'll provide a discussion here as well regarding useful metrics when dealing with imbalanced data.</p>
<p><strong>Precision</strong> is defined as the fraction of relevant examples (true positives) among all of the examples which were predicted to belong in a certain class.
precision=truepositives/truepositives+falsepositives</p>
<p><strong>Recall</strong> is defined as the fraction of examples which were predicted to belong to a class with respect to all of the examples that truly belong in the class.</p>
<p>recall=truepositives/truepositives+falsenegatives</p>
<p>The following graphic does a phenomenal job visualizing the difference between precision and recall.
<img alt="the difference between precision and recall" src="/images/ImbalancedData/Precisionrecall.svg.png">
<a href="https://en.wikipedia.org/wiki/Precision_and_recall">Image credit</a></p>
<p>We can further combine these two metrics into a single value by calcuating the f-score as defined below.</p>
<p>$$Fβ=(1+β2)precision⋅recall/(β2⋅precision)+recall$$</p>
<p>The β parameter allows us to control the tradeoff of importance between precision and recall. β&lt;1 focuses more on precision while β&gt;1</p>
<p>focuses more on recall.</p>
<p>Another common tool used to understand a model's performance is a Receiver Operating Characteristics (ROC) curve. An ROC curve visualizes an algorithm's ability to discriminate the positive class from the rest of the data. We'll do this by plotting the True Positive Rate against the False Positive Rate for varying prediction thresholds.</p>
<p>TPR=truepositives/truepositives+falsenegatives</p>
<p>FPR=falsepositives/falsepositives+truenegatives</p>
<p>For classifiers which only produce factor outcomes (ie. directly output a class), there exists a fixed TPR and FPR for a trained model. However, other classifiers, such as logistic regression, are capable of giving a probabilistic output (ie. the chance that a given observation belongs to the positive class). For these classifiers, we can specify the probability threshold by which above that amount we'll predict the observation belongs to the positive class.</p>
<p>Screen-Shot-2018-02-15-at-12.41.38-PM</p>
<p><img alt="ROC" src="/images/ImbalancedData/Screen-Shot-2018-02-15-at-12.41.38-PM.png"></p>
<p>[Image credit] (https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and [Image credit] (https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py)</p>
<p>If we set a very low value for this probability threshold, we can increase our True Positive Rate as we'll be more likely to capture all of the positive observations. However, this can also introduce a number of false positive classifications, increasing our False Positive Rate. Intuitively, there exists a tradeoff between maximizing our True Positive Rate and minimizing our False Positive Rate. The ideal model would correctly identify all positive observations as belonging to the positive class (TPR=1) and would not incorrectly classify negative observations as belonging to the positive class (FPR=0).
<img alt="tradeoff between maximizing our True Positive Rate and minimizing our False Positive Rate" src="/images/ImbalancedData/roc_cutoff-1.gif">
This tradeoff can be visualized in this <a href="http://www.navan.name/roc/">demonstration</a> in which you can adjust the class distributions and classification threshold.</p>
<p>The <strong>area under the curve (AUC)</strong> is a single-value metric for which attempts to summarize an ROC curve to evaluate the quality of a classifier. As the name implies, this metric approximates the area under the ROC curve for a given classifier. Recall that the ideal curve hugs the upper lefthand corner as closely as possible, giving us the ability to identify all true positives while avoiding false positives; this ideal model would have an AUC of 1. On the flipside, if your model was no better than a random guess, your TPR and FPR would increase in parallel to one another, corresponding with an AUC of 0.5.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;AUC: {auc}&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;False positive rate&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;True positive rate&#39;</span><span class="p">)</span>
</pre></div>


<h1>Class weight</h1>
<p>One of the simplest ways to address the class imbalance is to simply provide a weight for each class which places more emphasis on the minority classes such that the end result is a classifier which can learn equally from all classes.
To calculate the proper weights for each class, you can use the sklearn utility function shown in the example below.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.utils.class_weight</span> <span class="kn">import</span> <span class="n">compute_class_weight</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">compute_class_weight</span><span class="p">(</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>


<p>In a tree-based model where you're determining the optimal split according to some measure such as decreased entropy, you can simply scale the entropy component of each class by the corresponding weight such that you place more emphasis on the minority classes. As a reminder, the entropy of a node can be calculated as</p>
<p>−∑ipilog(pi)</p>
<p>where pi is the fraction of data points within class i.</p>
<p>In a gradient-based model, you can scale the calculated loss for each observation by the appropriate class weight such that you place more significance on the losses associated with minority classes. As a reminder, a common loss function for classification is the categorical cross entropy (which is very similar to the above equation, albeit with slight differences). This may be calculated as</p>
<p>∑iyilogy^i</p>
<p>where yi represents the true class (typically a one-hot encoded vector) and y^i represents the predicted class distribution.</p>
<h1>Further reading</h1>
<div class="highlight"><pre><span></span><span class="cp">[</span><span class="nx">Learning</span> <span class="nx">from</span> <span class="nx">Imbalanced</span> <span class="kd">Data</span> <span class="o">-</span> <span class="nx">Literature</span> <span class="nx">Review</span><span class="cp">]</span> <span class="o">(</span><span class="nt">http</span><span class="o">://</span><span class="nt">ieeexplore</span><span class="p">.</span><span class="nc">ieee</span><span class="p">.</span><span class="nc">org</span><span class="o">/</span><span class="nt">document</span><span class="o">/</span><span class="nt">5128907</span><span class="o">/)</span>
<span class="cp">[</span><span class="nx">Learning</span> <span class="nx">from</span> <span class="nx">Imbalanced</span> <span class="nx">Classes</span><span class="cp">]</span> <span class="o">(</span><span class="nt">https</span><span class="o">://</span><span class="nt">svds</span><span class="p">.</span><span class="nc">com</span><span class="o">/</span><span class="nt">learning-imbalanced-classes</span><span class="o">/)</span>
<span class="cp">[</span><span class="nx">Learning</span> <span class="nx">from</span> <span class="nx">imbalanced</span> <span class="nx">data</span><span class="p">:</span> <span class="nx">open</span> <span class="nx">challenges</span> <span class="ow">and</span> <span class="nx">future</span> <span class="nx">directions</span><span class="cp">]</span> <span class="o">(</span><span class="nt">https</span><span class="o">://</span><span class="nt">rd</span><span class="p">.</span><span class="nc">springer</span><span class="p">.</span><span class="nc">com</span><span class="o">/</span><span class="nt">article</span><span class="o">/</span><span class="nt">10</span><span class="p">.</span><span class="nc">1007</span><span class="o">/</span><span class="nt">s13748-016-0094-0</span><span class="o">?</span><span class="nt">utm_medium</span><span class="o">=</span><span class="nt">affiliate</span><span class="o">&amp;</span><span class="nt">amp</span><span class="o">;</span><span class="nt">utm_source</span><span class="o">=</span><span class="nt">commission_junction</span><span class="o">&amp;</span><span class="nt">amp</span><span class="o">;</span><span class="nt">utm_campaign</span><span class="o">=</span><span class="nt">3_nsn6445_brand_PID4003003</span><span class="o">&amp;</span><span class="nt">amp</span><span class="o">;</span><span class="nt">utm_content</span><span class="o">=</span><span class="nt">de_textlink</span><span class="o">)</span>
<span class="cp">[</span><span class="nx">Handling</span> <span class="nx">imbalanced</span> <span class="n">datasets</span> <span class="k">in</span> <span class="nx">machine</span> <span class="nx">learning</span><span class="cp">]</span> <span class="o">(</span><span class="nt">https</span><span class="o">://</span><span class="nt">towardsdatascience</span><span class="p">.</span><span class="nc">com</span><span class="o">/</span><span class="nt">handling-imbalanced-datasets-in-machine-learning-7a0e84220f28</span><span class="o">)</span>
</pre></div>
            <div class="hr"></div>
            <a href="#" class="go-top">Go Top</a>
<div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = "leafyleap-2"; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div><footer class="footer">
    <p>&copy; Mohcine Madkour &ndash;
        Built with <a href="https://github.com/PurePelicanTheme/pure">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
    </p>
</footer>        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script>
</body>
</html>