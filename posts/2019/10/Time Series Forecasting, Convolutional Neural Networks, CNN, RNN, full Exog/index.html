<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Mohcine Madkour, Big Data Architectures and more">


        <title>High-Dimensional Time Series Forecasting with Convolutional Neural Networks: Adding Exogenous Features to WaveNet // Mohcine Madkour // Big Data Architectures and more</title>


    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../../../../theme/css/pure.css">
    <link rel="stylesheet" href="../../../../theme/css/pygments.css">

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fitvids/1.0.1/jquery.fitvids.min.js"></script>
    <script>
        $(document).ready(function(){
            $(".content").fitVids();
        });
    </script>
</head>

<body>
<div class="pure-g-r" id="layout">
    <div class="sidebar sidebar-article pure-u">
        <header class="header-article">
            <hgroup>
                <a href="../../../../author/mohcine-madkour.html" title="See posts by Mohcine Madkour">
                        <img class="avatar" alt="Mohcine Madkour" src="http://www.gravatar.com/avatar/ae08847efc1a85b710f326eb8ee2e907">
                </a>
                <h2 class="article-info">Mohcine Madkour</h2>
                <small class="about-author"></small>
                <h5>Published</h5>
                <p>Mon 14 October 2019</p>
                <a href="/">&larr;Home</a>
            </hgroup>
        </header>
    </div>
    <div class="pure-u">
        <div class="content">
            <section class="post">
                <header class="post-header">
                    <h1>High-Dimensional Time Series Forecasting with Convolutional Neural Networks: Adding Exogenous Features to WaveNet</h1>
                        <p class="post-meta">
                            // under                                 <a class="post-category" href="../../../../tag/time-series-forecasting/">Time Series Forecasting</a>
                                <a class="post-category" href="../../../../tag/convolutional-neural-networks/">Convolutional Neural Networks</a>
                                <a class="post-category" href="../../../../tag/cnn/">CNN</a>
                                <a class="post-category" href="../../../../tag/rnn/">RNN</a>
                        </p>
                </header>
            </section>
            <p>This notebook builds on the <a href="https://github.com/mohcinemadkour/TimeSeries_Seq2Seq/blob/master/notebooks/TS_Seq2Seq_Conv_Full.ipynb">previous notebook in this series</a>, where I demonstrated in python/keras code how a <strong>convolutional</strong> sequence-to-sequence neural network modeled after WaveNet can be built for the purpose of high-dimensional time series forecasting. I assume that you're comfortable with the core model and set out to improve it by adding <strong>exogenous features</strong> to the model's input on top of the raw time series signals. In forecasting, exogenous features are those external to the forecasted series that may have a causal influence on it (e.g. day of the week or language of a wikipedia page). They often provide predictive signal that's not fully captured by historical values of the target series alone. Here we'll see how these features can be derived and properly formatted in a keras setting along with how our network architecture can be modified to handle them.   </p>
<p>We'll be using the same daily wikipedia web page traffic dataset, available <a href="https://www.kaggle.com/c/web-traffic-time-series-forecasting/data">here on Kaggle</a>. And once again with our full-fledged model we'll forecast 60 days into the future, using all of the series history available in "train_1.csv" for the encoding stage of the model. </p>
<p>Our workflow's structure is mostly unchanged from the previous notebook, but adds a new section on exogenous feature extraction. The features we'll extract are day of the week and page-specific metadata (language, access type, and agent type). The model formatting and building sections are also modified to accomodate the inclusion of these features. Feel free to focus on those sections (2-6) if you're comfortable with the setup steps (as in the previous notebooks).     </p>
<p>Here's a section breakdown of this notebook -- enjoy!</p>
<p><strong>1. Loading and Previewing the Data</strong> <br>
<strong>2. Exogenous Feature Engineering</strong> <br>
<strong>3. Formatting the Data for Modeling</strong><br>
<strong>4. Building the Model - Training Architecture</strong><br>
<strong>5. Building the Model - Inference Loop</strong><br>
<strong>6. Generating and Plotting Predictions</strong></p>
<h2>1. Loading and Previewing the Data</h2>
<p>First thing's first, let's load up the data and get a quick feel for it (reminder that the dataset is available <a href="https://www.kaggle.com/c/web-traffic-time-series-forecasting/data">here</a>). </p>
<p>Note that there are a good number of NaN values in the data that don't disambiguate missing from zero. For the sake of simplicity in this tutorial, we'll naively fill these with 0 later on.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/train_1.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Page</th>
      <th>2015-07-01</th>
      <th>2015-07-02</th>
      <th>2015-07-03</th>
      <th>2015-07-04</th>
      <th>2015-07-05</th>
      <th>2015-07-06</th>
      <th>2015-07-07</th>
      <th>2015-07-08</th>
      <th>2015-07-09</th>
      <th>...</th>
      <th>2016-12-22</th>
      <th>2016-12-23</th>
      <th>2016-12-24</th>
      <th>2016-12-25</th>
      <th>2016-12-26</th>
      <th>2016-12-27</th>
      <th>2016-12-28</th>
      <th>2016-12-29</th>
      <th>2016-12-30</th>
      <th>2016-12-31</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2NE1_zh.wikipedia.org_all-access_spider</td>
      <td>18.0</td>
      <td>11.0</td>
      <td>5.0</td>
      <td>13.0</td>
      <td>14.0</td>
      <td>9.0</td>
      <td>9.0</td>
      <td>22.0</td>
      <td>26.0</td>
      <td>...</td>
      <td>32.0</td>
      <td>63.0</td>
      <td>15.0</td>
      <td>26.0</td>
      <td>14.0</td>
      <td>20.0</td>
      <td>22.0</td>
      <td>19.0</td>
      <td>18.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2PM_zh.wikipedia.org_all-access_spider</td>
      <td>11.0</td>
      <td>14.0</td>
      <td>15.0</td>
      <td>18.0</td>
      <td>11.0</td>
      <td>13.0</td>
      <td>22.0</td>
      <td>11.0</td>
      <td>10.0</td>
      <td>...</td>
      <td>17.0</td>
      <td>42.0</td>
      <td>28.0</td>
      <td>15.0</td>
      <td>9.0</td>
      <td>30.0</td>
      <td>52.0</td>
      <td>45.0</td>
      <td>26.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3C_zh.wikipedia.org_all-access_spider</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>...</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4minute_zh.wikipedia.org_all-access_spider</td>
      <td>35.0</td>
      <td>13.0</td>
      <td>10.0</td>
      <td>94.0</td>
      <td>4.0</td>
      <td>26.0</td>
      <td>14.0</td>
      <td>9.0</td>
      <td>11.0</td>
      <td>...</td>
      <td>32.0</td>
      <td>10.0</td>
      <td>26.0</td>
      <td>27.0</td>
      <td>16.0</td>
      <td>11.0</td>
      <td>17.0</td>
      <td>19.0</td>
      <td>10.0</td>
      <td>11.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>48.0</td>
      <td>9.0</td>
      <td>25.0</td>
      <td>13.0</td>
      <td>3.0</td>
      <td>11.0</td>
      <td>27.0</td>
      <td>13.0</td>
      <td>36.0</td>
      <td>10.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows Ã— 551 columns</p>
</div>

<div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre><span></span>&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 145063 entries, 0 to 145062
Columns: 551 entries, Page to 2016-12-31
dtypes: float64(550), object(1)
memory usage: 609.8+ MB
</pre></div>


<div class="highlight"><pre><span></span><span class="n">data_start_date</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">data_end_date</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Data ranges from </span><span class="si">%s</span><span class="s1"> to </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">data_start_date</span><span class="p">,</span> <span class="n">data_end_date</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span>Data ranges from 2015-07-01 to 2016-12-31
</pre></div>


<p>We can define a function that lets us visualize some random webpage series as below. For the sake of smoothing out the scale of traffic across different series, we apply a log1p transformation before plotting - i.e. take $\log(1+x)$ for each value $x$ in a series.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_random_series</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">n_series</span><span class="p">):</span>

    <span class="n">sample</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n_series</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">page_labels</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;Page&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">series_samples</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">data_start_date</span><span class="p">:</span><span class="n">data_end_date</span><span class="p">]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">series_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">series_samples</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Randomly Selected Wikipedia Page Daily Views Over Time (Log(views) + 1)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">page_labels</span><span class="p">)</span>

<span class="n">plot_random_series</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="/images/output_dup_6_0.png"></p>
<h2>2. Exogenous Feature Engineering</h2>
<p>Glancing back at our preview of the data above, we see that we have information that isn't directly captured by the raw traffic time series. The <strong>page column</strong> gives us metadata on each series that might guide our model in identifying shared patterns across related series. For example, pages written in the same language may exhibit similar seasonality patterns. Similarly, the <strong>date column headers</strong> let us explicitly encode day of the week information as a way of anchoring the model's understanding of weekly seasonality. In the code to follow, we'll extract numeric features from both of these sources and wrangle them into a format that keras will cleanly accept as input when combined with the raw series.</p>
<p><img alt="architecture" src="/images/Page_exog.png"></p>
<p>Let's start by converting dates to <strong>one-hot-encoded</strong> / <strong>dummy variable</strong> representations of day of the week, following the standard approach for handling categorical features. It's simple to do this using pandas:  </p>
<div class="highlight"><pre><span></span><span class="n">dow_ohe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">dayofweek</span><span class="p">)</span>
<span class="n">dow_ohe</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<p>Right now we have a dataframe of shape (n_timesteps, 7), with binary columns corresponding to each day of the week. We need to do a bit more for keras-friendly formatting: when processing a sequence of features, keras expects input arrays (tensors) of shape <strong>(n_samples, n_timesteps, n_features)</strong>. In this case, the day of week features are shared across all of the individual page series (our samples), so we want to just repeat the one-hot-encoded data n_samples (~145,000) times to get the 3-dimensional array we need. We can accomplish this using the handy numpy functions <strong>expand_dims</strong> and <strong>tile</strong> as below.</p>
<div class="highlight"><pre><span></span><span class="n">dow_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">dow_ohe</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># add sample dimension</span>
<span class="n">dow_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">dow_array</span><span class="p">,(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># repeat OHE array along sample dimension</span>
<span class="n">dow_array</span><span class="o">.</span><span class="n">shape</span>
</pre></div>


<div class="highlight"><pre><span></span>(145063, 550, 7)
</pre></div>


<p>Great, that's the exact format we need for an input array; now we'll just add the <strong>page metadata</strong> to this array. Let's take a quick look at the raw format of that metadata:</p>
<div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Page&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>0              2NE1_zh.wikipedia.org_all-access_spider
1               2PM_zh.wikipedia.org_all-access_spider
2                3C_zh.wikipedia.org_all-access_spider
3           4minute_zh.wikipedia.org_all-access_spider
4    52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...
5              5566_zh.wikipedia.org_all-access_spider
6            91Days_zh.wikipedia.org_all-access_spider
7             A&#39;N&#39;D_zh.wikipedia.org_all-access_spider
Name: Page, dtype: object
</pre></div>


<p>It turns out that this data is underscore delimited as <strong>name_project_access_agent</strong>. We should split that out into distinct columns, with the one tricky part being that underscores can occur in the <em>name</em> field that would throw off a simple split on underscore. A quick workaround is to use the <strong>rsplit</strong> function to work from right to left and limit the number of splits to 3. </p>
<div class="highlight"><pre><span></span><span class="n">page_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Page&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># split page string and expand to multiple columns </span>
<span class="n">page_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span><span class="s1">&#39;project&#39;</span><span class="p">,</span><span class="s1">&#39;access&#39;</span><span class="p">,</span><span class="s1">&#39;agent&#39;</span><span class="p">]</span>
<span class="n">page_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>project</th>
      <th>access</th>
      <th>agent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2NE1</td>
      <td>zh.wikipedia.org</td>
      <td>all-access</td>
      <td>spider</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2PM</td>
      <td>zh.wikipedia.org</td>
      <td>all-access</td>
      <td>spider</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3C</td>
      <td>zh.wikipedia.org</td>
      <td>all-access</td>
      <td>spider</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4minute</td>
      <td>zh.wikipedia.org</td>
      <td>all-access</td>
      <td>spider</td>
    </tr>
    <tr>
      <th>4</th>
      <td>52_Hz_I_Love_You</td>
      <td>zh.wikipedia.org</td>
      <td>all-access</td>
      <td>spider</td>
    </tr>
  </tbody>
</table>
</div>

<p>That looks great, so let's do a quick cardinality check on each of these categorical variables before we one-hot-encode them like we did for day of the week.</p>
<div class="highlight"><pre><span></span><span class="n">page_df</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre><span></span>name       49174
project        9
access         3
agent          2
dtype: int64
</pre></div>


<p>Since there are so many different names, it's likely more trouble than it's worth to include name in our feature set (it would mean an increase of ~50000 features in our input array!). So we'll drop name and one-hot-encode the low cardinality features to get a dataframe of shape (n_samples, n_features). Then we can repeat these features along the timesteps dimension to get the needed 3-dimensional array.      </p>
<div class="highlight"><pre><span></span><span class="n">page_df</span> <span class="o">=</span> <span class="n">page_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">page_array</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">page_df</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">page_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">page_array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># add timesteps dimension</span>
<span class="n">page_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">page_array</span><span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="n">dow_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># repeat OHE array along timesteps dimension </span>
<span class="n">page_array</span><span class="o">.</span><span class="n">shape</span>
</pre></div>


<div class="highlight"><pre><span></span>(145063, 550, 14)
</pre></div>


<p>The final step to complete our exogenous feature array is simply to concatenate the day of week information and page metadata into one shared array.</p>
<div class="highlight"><pre><span></span><span class="n">exog_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">dow_array</span><span class="p">,</span> <span class="n">page_array</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">exog_array</span><span class="o">.</span><span class="n">shape</span>
</pre></div>


<div class="highlight"><pre><span></span>(145063, 550, 21)
</pre></div>


<p>That's it, our exogenous feature extraction is all done! In the next section we'll write a function that lets us combine this exogenous feature array with the endogenous time series data in order to prepare for model training and prediction.   </p>
<h2>3. Formatting the Data for Modeling</h2>
<p>Sadly we can't just throw the time series dataframe and exogenous array we've created into keras and let it work its magic. Instead, we have to set up a few more data transformation steps to extract the exact numpy arrays that we'll later pass to keras. But even before doing that, we have to know how to appropriately partition the time series into encoding and prediction intervals for the purposes of training and validation. Note that for our simple convolutional model we won't use an encoder-decoder architecture like in the first notebook in this repo, but <strong>we'll keep the "encoding" and "decoding" (prediction) terminology to be consistent</strong> -- in this case, the encoding interval represents the entire series history that we will use for the network's feature learning, but not output any predictions on. </p>
<p>We'll use a style of <strong>walk-forward validation</strong>, where our validation set spans the same time-range as our training set, but shifted forward in time (in this case by 60 days). This way, we simulate how our model will perform on unseen data that comes in the future. </p>
<p><a href="https://github.com/Arturus/kaggle-web-traffic/blob/master/how_it_works.md">Artur Suilin</a> has created a very nice image that visualizes this validation style and contrasts it with traditional validation. I highly recommend checking out his entire repo, as he's implemented a truly state of the art (and competition winning) seq2seq model on this data set. </p>
<p><img alt="architecture" src="/images/ArturSuilin_validation.png"></p>
<h3>Train and Validation Series Partioning</h3>
<p>We need to create 4 sub-segments of the data:</p>
<div class="highlight"><pre><span></span>1. Train encoding period
2. Train decoding period (train targets, 60 days)
3. Validation encoding period
4. Validation decoding period (validation targets, 60 days)
</pre></div>


<p>We'll do this by finding the appropriate start and end dates for each segment. Starting from the end of the data we've loaded, we'll work backwards to get validation and training prediction intervals. Then we'll work forward from the start to get training and validation encoding intervals. </p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span>

<span class="n">pred_steps</span> <span class="o">=</span> <span class="mi">60</span> 
<span class="n">pred_length</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">pred_steps</span><span class="p">)</span>

<span class="n">first_day</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">data_start_date</span><span class="p">)</span> 
<span class="n">last_day</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">data_end_date</span><span class="p">)</span>

<span class="n">val_pred_start</span> <span class="o">=</span> <span class="n">last_day</span> <span class="o">-</span> <span class="n">pred_length</span> <span class="o">+</span> <span class="n">timedelta</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">val_pred_end</span> <span class="o">=</span> <span class="n">last_day</span>

<span class="n">train_pred_start</span> <span class="o">=</span> <span class="n">val_pred_start</span> <span class="o">-</span> <span class="n">pred_length</span>
<span class="n">train_pred_end</span> <span class="o">=</span> <span class="n">val_pred_start</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
</pre></div>


<div class="highlight"><pre><span></span><span class="n">enc_length</span> <span class="o">=</span> <span class="n">train_pred_start</span> <span class="o">-</span> <span class="n">first_day</span>

<span class="n">train_enc_start</span> <span class="o">=</span> <span class="n">first_day</span>
<span class="n">train_enc_end</span> <span class="o">=</span> <span class="n">train_enc_start</span> <span class="o">+</span> <span class="n">enc_length</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">val_enc_start</span> <span class="o">=</span> <span class="n">train_enc_start</span> <span class="o">+</span> <span class="n">pred_length</span>
<span class="n">val_enc_end</span> <span class="o">=</span> <span class="n">val_enc_start</span> <span class="o">+</span> <span class="n">enc_length</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> 
</pre></div>


<div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Train encoding:&#39;</span><span class="p">,</span> <span class="n">train_enc_start</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">train_enc_end</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Train prediction:&#39;</span><span class="p">,</span> <span class="n">train_pred_start</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">train_pred_end</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Val encoding:&#39;</span><span class="p">,</span> <span class="n">val_enc_start</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">val_enc_end</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Val prediction:&#39;</span><span class="p">,</span> <span class="n">val_pred_start</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">val_pred_end</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Encoding interval:&#39;</span><span class="p">,</span> <span class="n">enc_length</span><span class="o">.</span><span class="n">days</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Prediction interval:&#39;</span><span class="p">,</span> <span class="n">pred_length</span><span class="o">.</span><span class="n">days</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Train encoding: 2015-07-01 00:00:00 - 2016-09-02 00:00:00
Train prediction: 2016-09-03 00:00:00 - 2016-11-01 00:00:00

Val encoding: 2015-08-30 00:00:00 - 2016-11-01 00:00:00
Val prediction: 2016-11-02 00:00:00 - 2016-12-31 00:00:00

Encoding interval: 430
Prediction interval: 60
</pre></div>


<h3>Keras Data Formatting</h3>
<p>Now that we have the time segment dates, we'll define the functions we need to extract the data in keras friendly format. Here are the steps:</p>
<ul>
<li>Pull the time series into an array, save a date_to_index mapping as a utility for referencing into the array </li>
<li>Create function to extract specified time interval from all the series </li>
<li>Create functions to transform all the series. <ul>
<li>Here we smooth out the scale by taking log1p and de-meaning each series using the encoder series mean, then reshape to the <strong>(n_series, n_timesteps, n_features) tensor format</strong> that keras will expect. </li>
<li>Note that if we want to generate true predictions instead of log scale ones, we can easily apply a reverse transformation at prediction time. </li>
</ul>
</li>
<li>Create final function to extract complete encoding and target arrays, leveraging prior functions <ul>
<li>This will act as a one-shot function that grabs what we need to train or predict</li>
<li>It will extract (transformed) endogenous series data and combine it with our exogenous features</li>
</ul>
</li>
</ul>
<p>The first code block below accomplishes the first 3 steps, unchanged from the earlier notebooks in this series.</p>
<div class="highlight"><pre><span></span><span class="n">date_to_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]),</span>
                          <span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))])</span>

<span class="n">series_array</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span><span class="o">.</span><span class="n">values</span>

<span class="k">def</span> <span class="nf">get_time_block_series</span><span class="p">(</span><span class="n">series_array</span><span class="p">,</span> <span class="n">date_to_index</span><span class="p">,</span> <span class="n">start_date</span><span class="p">,</span> <span class="n">end_date</span><span class="p">):</span>

    <span class="n">inds</span> <span class="o">=</span> <span class="n">date_to_index</span><span class="p">[</span><span class="n">start_date</span><span class="p">:</span><span class="n">end_date</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">series_array</span><span class="p">[:,</span><span class="n">inds</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">transform_series_encode</span><span class="p">(</span><span class="n">series_array</span><span class="p">):</span>

    <span class="n">series_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">series_array</span><span class="p">))</span> <span class="c1"># filling NaN with 0</span>
    <span class="n">series_mean</span> <span class="o">=</span> <span class="n">series_array</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">series_array</span> <span class="o">=</span> <span class="n">series_array</span> <span class="o">-</span> <span class="n">series_mean</span>
    <span class="n">series_array</span> <span class="o">=</span> <span class="n">series_array</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">series_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">series_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">series_array</span><span class="p">,</span> <span class="n">series_mean</span>

<span class="k">def</span> <span class="nf">transform_series_decode</span><span class="p">(</span><span class="n">series_array</span><span class="p">,</span> <span class="n">encode_series_mean</span><span class="p">):</span>

    <span class="n">series_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">series_array</span><span class="p">))</span> <span class="c1"># filling NaN with 0</span>
    <span class="n">series_array</span> <span class="o">=</span> <span class="n">series_array</span> <span class="o">-</span> <span class="n">encode_series_mean</span>
    <span class="n">series_array</span> <span class="o">=</span> <span class="n">series_array</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">series_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">series_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">series_array</span>
</pre></div>


<p>Now we can leverage the first 3 processing steps built out above in order to create a one-shot preprocessing function for extracting encoder/input data (with the correct exogenous features attached) and decoder/target data. We'll include arguments that let us choose the number of time series samples to extract and which periods to sample from. With this function written, we'll be ready to set up the model!      </p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_data_encode_decode</span><span class="p">(</span><span class="n">series_array</span><span class="p">,</span> <span class="n">exog_array</span><span class="p">,</span> <span class="n">first_n_samples</span><span class="p">,</span>
                           <span class="n">date_to_index</span><span class="p">,</span> <span class="n">enc_start</span><span class="p">,</span> <span class="n">enc_end</span><span class="p">,</span> <span class="n">pred_start</span><span class="p">,</span> <span class="n">pred_end</span><span class="p">):</span>

    <span class="n">exog_inds</span> <span class="o">=</span> <span class="n">date_to_index</span><span class="p">[</span><span class="n">enc_start</span><span class="p">:</span><span class="n">pred_end</span><span class="p">]</span>

    <span class="c1"># sample of series from enc_start to enc_end  </span>
    <span class="n">encoder_input_data</span> <span class="o">=</span> <span class="n">get_time_block_series</span><span class="p">(</span><span class="n">series_array</span><span class="p">,</span> <span class="n">date_to_index</span><span class="p">,</span> 
                                               <span class="n">enc_start</span><span class="p">,</span> <span class="n">enc_end</span><span class="p">)[:</span><span class="n">first_n_samples</span><span class="p">]</span>
    <span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">encode_series_mean</span> <span class="o">=</span> <span class="n">transform_series_encode</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">)</span>

    <span class="c1"># sample of series from pred_start to pred_end </span>
    <span class="n">decoder_target_data</span> <span class="o">=</span> <span class="n">get_time_block_series</span><span class="p">(</span><span class="n">series_array</span><span class="p">,</span> <span class="n">date_to_index</span><span class="p">,</span> 
                                                <span class="n">pred_start</span><span class="p">,</span> <span class="n">pred_end</span><span class="p">)[:</span><span class="n">first_n_samples</span><span class="p">]</span>
    <span class="n">decoder_target_data</span> <span class="o">=</span> <span class="n">transform_series_decode</span><span class="p">(</span><span class="n">decoder_target_data</span><span class="p">,</span> <span class="n">encode_series_mean</span><span class="p">)</span>

    <span class="c1"># we append a lagged history of the target series to the input data, </span>
    <span class="c1"># so that we can train with teacher forcing</span>
    <span class="n">lagged_target_history</span> <span class="o">=</span> <span class="n">decoder_target_data</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">encoder_input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">lagged_target_history</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># we add the exogenous features corresponding to day after input series</span>
    <span class="c1"># values to the input data (exog should match day we are predicting)</span>
    <span class="n">exog_input_data</span> <span class="o">=</span> <span class="n">exog_array</span><span class="p">[:</span><span class="n">first_n_samples</span><span class="p">,</span><span class="n">exog_inds</span><span class="p">,:][:,</span><span class="mi">1</span><span class="p">:,:]</span>
    <span class="n">encoder_input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">exog_input_data</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span>
</pre></div>


<h2>4. Building the Model - Architecture</h2>
<p>This convolutional architecture is a full-fledged version of the <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">WaveNet model</a>, designed as a generative model for audio (in particular, for text-to-speech applications). The wavenet model can be abstracted beyond audio to apply to any time series forecasting problem, providing a nice structure for capturing long-term dependencies without an excessive number of learned weights. Exogenous features can be integrated into WaveNet simply by extending the 3rd dimension (feature dimension) of the tensors that we feed to the model.</p>
<p>The core of the wavenet model can be described as a <strong>stack of residual blocks</strong> that utilize <strong>dilated causal convolutions</strong>, visualized by the two diagrams from the wavenet paper below. I've gone into detailed discussion of these model components in the two previous notebooks of this series (<a href="https://github.com/JEddy92/TimeSeries_Seq2Seq/blob/master/notebooks/TS_Seq2Seq_Conv_Intro.ipynb">part 1</a>, <a href="https://github.com/JEddy92/TimeSeries_Seq2Seq/blob/master/notebooks/TS_Seq2Seq_Conv_Full.ipynb">part 2</a>), so I'd recommend checking those out if you want to build familiarity.</p>
<p><img alt="dilatedconv" src="/images/WaveNet_dilatedconv.png">  </p>
<p><img alt="blocks" src="/images/WaveNet_residblock.png">        </p>
<h3><strong>Our Architecture</strong></h3>
<p>With all of our components now laid out, here's what we'll use:</p>
<ul>
<li>16 dilated causal convolutional blocks<ul>
<li>Preprocessing and postprocessing (time distributed) fully connected layers (convolutions with filter width 1): 32 output units</li>
<li>32 filters of width 2 per block</li>
<li>Exponentially increasing dilation rate with a reset (1, 2, 4, 8, ..., 128, 1, 2, ..., 128) </li>
<li>Gated activations</li>
<li>Residual and skip connections</li>
</ul>
</li>
<li>2 (time distributed) fully connected layers to map sum of skip outputs to final output </li>
</ul>
<p>Note that the only change in architecture from the previous notebook (without exogenous features) is an increase in units from 16 to 32 for the pre and postprocessing layers. This increase lets us better handle the larger number of input features (before we only used 1 feature!). </p>
<p>As in the previous notebook, we'll extract the last 60 steps from the output sequence as our predicted output for training. We'll also use teacher forcing again during training, and write a separate function for iterative inference (section 5). </p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">FATAL</span><span class="p">)</span> <span class="c1"># suppress unhelpful tf warnings</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Multiply</span><span class="p">,</span> <span class="n">Add</span><span class="p">,</span> <span class="n">Concatenate</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="c1"># convolutional operation parameters</span>
<span class="n">n_filters</span> <span class="o">=</span> <span class="mi">32</span> <span class="c1"># 32 </span>
<span class="n">filter_width</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dilation_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)]</span> <span class="o">*</span> <span class="mi">2</span> 

<span class="c1"># define an input history series and pass it through a stack of dilated causal convolution blocks. </span>
<span class="c1"># Note the feature input dimension corresponds to the raw series and all exogenous features  </span>
<span class="n">history_seq</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">exog_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">history_seq</span>

<span class="n">skips</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">dilation_rate</span> <span class="ow">in</span> <span class="n">dilation_rates</span><span class="p">:</span>

    <span class="c1"># preprocessing - equivalent to time-distributed dense</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span> 

    <span class="c1"># filter convolution</span>
    <span class="n">x_f</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="n">n_filters</span><span class="p">,</span>
                 <span class="n">kernel_size</span><span class="o">=</span><span class="n">filter_width</span><span class="p">,</span> 
                 <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;causal&#39;</span><span class="p">,</span>
                 <span class="n">dilation_rate</span><span class="o">=</span><span class="n">dilation_rate</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># gating convolution</span>
    <span class="n">x_g</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="n">n_filters</span><span class="p">,</span>
                 <span class="n">kernel_size</span><span class="o">=</span><span class="n">filter_width</span><span class="p">,</span> 
                 <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;causal&#39;</span><span class="p">,</span>
                 <span class="n">dilation_rate</span><span class="o">=</span><span class="n">dilation_rate</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># multiply filter and gating branches</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">Multiply</span><span class="p">()([</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;tanh&#39;</span><span class="p">)(</span><span class="n">x_f</span><span class="p">),</span>
                    <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">x_g</span><span class="p">)])</span>

    <span class="c1"># postprocessing - equivalent to time-distributed dense</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">z</span><span class="p">)</span>

    <span class="c1"># residual connection</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">])</span>    

    <span class="c1"># collect skip connections</span>
    <span class="n">skips</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

<span class="c1"># add all skip connection outputs </span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">Add</span><span class="p">()(</span><span class="n">skips</span><span class="p">))</span>

<span class="c1"># final time-distributed dense layers </span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">out</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">out</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="o">.</span><span class="mi">2</span><span class="p">)(</span><span class="n">out</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">out</span><span class="p">)</span>

<span class="c1"># extract the last 60 time steps as the training target</span>
<span class="k">def</span> <span class="nf">slice</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[:,</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:,:]</span>

<span class="n">pred_seq_train</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="nb">slice</span><span class="p">,</span> <span class="n">arguments</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;seq_length&#39;</span><span class="p">:</span><span class="mi">60</span><span class="p">})(</span><span class="n">out</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">history_seq</span><span class="p">,</span> <span class="n">pred_seq_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_absolute_error&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Using TensorFlow backend.
</pre></div>


<div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre><span></span>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, None, 22)     0                                            
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, None, 32)     736         input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, None, 32)     2080        conv1d_1[0][0]                   
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, None, 32)     2080        conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, None, 32)     0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, None, 32)     0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, None, 32)     0           activation_1[0][0]               
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, None, 32)     1056        multiply_1[0][0]                 
__________________________________________________________________________________________________
add_1 (Add)                     (None, None, 32)     0           conv1d_1[0][0]                   
                                                                 conv1d_4[0][0]                   
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, None, 32)     1056        add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, None, 32)     2080        conv1d_5[0][0]                   
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, None, 32)     2080        conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, None, 32)     0           conv1d_6[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, None, 32)     0           conv1d_7[0][0]                   
__________________________________________________________________________________________________
multiply_2 (Multiply)           (None, None, 32)     0           activation_3[0][0]               
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, None, 32)     1056        multiply_2[0][0]                 
__________________________________________________________________________________________________
add_2 (Add)                     (None, None, 32)     0           conv1d_5[0][0]                   
                                                                 conv1d_8[0][0]                   
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, None, 32)     1056        add_2[0][0]                      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, None, 32)     2080        conv1d_9[0][0]                   
__________________________________________________________________________________________________
conv1d_11 (Conv1D)              (None, None, 32)     2080        conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, None, 32)     0           conv1d_10[0][0]                  
__________________________________________________________________________________________________
activation_6 (Activation)       (None, None, 32)     0           conv1d_11[0][0]                  
__________________________________________________________________________________________________
multiply_3 (Multiply)           (None, None, 32)     0           activation_5[0][0]               
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv1d_12 (Conv1D)              (None, None, 32)     1056        multiply_3[0][0]                 
__________________________________________________________________________________________________
add_3 (Add)                     (None, None, 32)     0           conv1d_9[0][0]                   
                                                                 conv1d_12[0][0]                  
__________________________________________________________________________________________________
conv1d_13 (Conv1D)              (None, None, 32)     1056        add_3[0][0]                      
__________________________________________________________________________________________________
conv1d_14 (Conv1D)              (None, None, 32)     2080        conv1d_13[0][0]                  
__________________________________________________________________________________________________
conv1d_15 (Conv1D)              (None, None, 32)     2080        conv1d_13[0][0]                  
__________________________________________________________________________________________________
activation_7 (Activation)       (None, None, 32)     0           conv1d_14[0][0]                  
__________________________________________________________________________________________________
activation_8 (Activation)       (None, None, 32)     0           conv1d_15[0][0]                  
__________________________________________________________________________________________________
multiply_4 (Multiply)           (None, None, 32)     0           activation_7[0][0]               
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
conv1d_16 (Conv1D)              (None, None, 32)     1056        multiply_4[0][0]                 
__________________________________________________________________________________________________
add_4 (Add)                     (None, None, 32)     0           conv1d_13[0][0]                  
                                                                 conv1d_16[0][0]                  
__________________________________________________________________________________________________
conv1d_17 (Conv1D)              (None, None, 32)     1056        add_4[0][0]                      
__________________________________________________________________________________________________
conv1d_18 (Conv1D)              (None, None, 32)     2080        conv1d_17[0][0]                  
__________________________________________________________________________________________________
conv1d_19 (Conv1D)              (None, None, 32)     2080        conv1d_17[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, None, 32)     0           conv1d_18[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, None, 32)     0           conv1d_19[0][0]                  
__________________________________________________________________________________________________
multiply_5 (Multiply)           (None, None, 32)     0           activation_9[0][0]               
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
conv1d_20 (Conv1D)              (None, None, 32)     1056        multiply_5[0][0]                 
__________________________________________________________________________________________________
add_5 (Add)                     (None, None, 32)     0           conv1d_17[0][0]                  
                                                                 conv1d_20[0][0]                  
__________________________________________________________________________________________________
conv1d_21 (Conv1D)              (None, None, 32)     1056        add_5[0][0]                      
__________________________________________________________________________________________________
conv1d_22 (Conv1D)              (None, None, 32)     2080        conv1d_21[0][0]                  
__________________________________________________________________________________________________
conv1d_23 (Conv1D)              (None, None, 32)     2080        conv1d_21[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, None, 32)     0           conv1d_22[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, None, 32)     0           conv1d_23[0][0]                  
__________________________________________________________________________________________________
multiply_6 (Multiply)           (None, None, 32)     0           activation_11[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
conv1d_24 (Conv1D)              (None, None, 32)     1056        multiply_6[0][0]                 
__________________________________________________________________________________________________
add_6 (Add)                     (None, None, 32)     0           conv1d_21[0][0]                  
                                                                 conv1d_24[0][0]                  
__________________________________________________________________________________________________
conv1d_25 (Conv1D)              (None, None, 32)     1056        add_6[0][0]                      
__________________________________________________________________________________________________
conv1d_26 (Conv1D)              (None, None, 32)     2080        conv1d_25[0][0]                  
__________________________________________________________________________________________________
conv1d_27 (Conv1D)              (None, None, 32)     2080        conv1d_25[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, None, 32)     0           conv1d_26[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, None, 32)     0           conv1d_27[0][0]                  
__________________________________________________________________________________________________
multiply_7 (Multiply)           (None, None, 32)     0           activation_13[0][0]              
                                                                 activation_14[0][0]              
__________________________________________________________________________________________________
conv1d_28 (Conv1D)              (None, None, 32)     1056        multiply_7[0][0]                 
__________________________________________________________________________________________________
add_7 (Add)                     (None, None, 32)     0           conv1d_25[0][0]                  
                                                                 conv1d_28[0][0]                  
__________________________________________________________________________________________________
conv1d_29 (Conv1D)              (None, None, 32)     1056        add_7[0][0]                      
__________________________________________________________________________________________________
conv1d_30 (Conv1D)              (None, None, 32)     2080        conv1d_29[0][0]                  
__________________________________________________________________________________________________
conv1d_31 (Conv1D)              (None, None, 32)     2080        conv1d_29[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, None, 32)     0           conv1d_30[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, None, 32)     0           conv1d_31[0][0]                  
__________________________________________________________________________________________________
multiply_8 (Multiply)           (None, None, 32)     0           activation_15[0][0]              
                                                                 activation_16[0][0]              
__________________________________________________________________________________________________
conv1d_32 (Conv1D)              (None, None, 32)     1056        multiply_8[0][0]                 
__________________________________________________________________________________________________
add_8 (Add)                     (None, None, 32)     0           conv1d_29[0][0]                  
                                                                 conv1d_32[0][0]                  
__________________________________________________________________________________________________
conv1d_33 (Conv1D)              (None, None, 32)     1056        add_8[0][0]                      
__________________________________________________________________________________________________
conv1d_34 (Conv1D)              (None, None, 32)     2080        conv1d_33[0][0]                  
__________________________________________________________________________________________________
conv1d_35 (Conv1D)              (None, None, 32)     2080        conv1d_33[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, None, 32)     0           conv1d_34[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, None, 32)     0           conv1d_35[0][0]                  
__________________________________________________________________________________________________
multiply_9 (Multiply)           (None, None, 32)     0           activation_17[0][0]              
                                                                 activation_18[0][0]              
__________________________________________________________________________________________________
conv1d_36 (Conv1D)              (None, None, 32)     1056        multiply_9[0][0]                 
__________________________________________________________________________________________________
add_9 (Add)                     (None, None, 32)     0           conv1d_33[0][0]                  
                                                                 conv1d_36[0][0]                  
__________________________________________________________________________________________________
conv1d_37 (Conv1D)              (None, None, 32)     1056        add_9[0][0]                      
__________________________________________________________________________________________________
conv1d_38 (Conv1D)              (None, None, 32)     2080        conv1d_37[0][0]                  
__________________________________________________________________________________________________
conv1d_39 (Conv1D)              (None, None, 32)     2080        conv1d_37[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, None, 32)     0           conv1d_38[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, None, 32)     0           conv1d_39[0][0]                  
__________________________________________________________________________________________________
multiply_10 (Multiply)          (None, None, 32)     0           activation_19[0][0]              
                                                                 activation_20[0][0]              
__________________________________________________________________________________________________
conv1d_40 (Conv1D)              (None, None, 32)     1056        multiply_10[0][0]                
__________________________________________________________________________________________________
add_10 (Add)                    (None, None, 32)     0           conv1d_37[0][0]                  
                                                                 conv1d_40[0][0]                  
__________________________________________________________________________________________________
conv1d_41 (Conv1D)              (None, None, 32)     1056        add_10[0][0]                     
__________________________________________________________________________________________________
conv1d_42 (Conv1D)              (None, None, 32)     2080        conv1d_41[0][0]                  
__________________________________________________________________________________________________
conv1d_43 (Conv1D)              (None, None, 32)     2080        conv1d_41[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, None, 32)     0           conv1d_42[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, None, 32)     0           conv1d_43[0][0]                  
__________________________________________________________________________________________________
multiply_11 (Multiply)          (None, None, 32)     0           activation_21[0][0]              
                                                                 activation_22[0][0]              
__________________________________________________________________________________________________
conv1d_44 (Conv1D)              (None, None, 32)     1056        multiply_11[0][0]                
__________________________________________________________________________________________________
add_11 (Add)                    (None, None, 32)     0           conv1d_41[0][0]                  
                                                                 conv1d_44[0][0]                  
__________________________________________________________________________________________________
conv1d_45 (Conv1D)              (None, None, 32)     1056        add_11[0][0]                     
__________________________________________________________________________________________________
conv1d_46 (Conv1D)              (None, None, 32)     2080        conv1d_45[0][0]                  
__________________________________________________________________________________________________
conv1d_47 (Conv1D)              (None, None, 32)     2080        conv1d_45[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, None, 32)     0           conv1d_46[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, None, 32)     0           conv1d_47[0][0]                  
__________________________________________________________________________________________________
multiply_12 (Multiply)          (None, None, 32)     0           activation_23[0][0]              
                                                                 activation_24[0][0]              
__________________________________________________________________________________________________
conv1d_48 (Conv1D)              (None, None, 32)     1056        multiply_12[0][0]                
__________________________________________________________________________________________________
add_12 (Add)                    (None, None, 32)     0           conv1d_45[0][0]                  
                                                                 conv1d_48[0][0]                  
__________________________________________________________________________________________________
conv1d_49 (Conv1D)              (None, None, 32)     1056        add_12[0][0]                     
__________________________________________________________________________________________________
conv1d_50 (Conv1D)              (None, None, 32)     2080        conv1d_49[0][0]                  
__________________________________________________________________________________________________
conv1d_51 (Conv1D)              (None, None, 32)     2080        conv1d_49[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, None, 32)     0           conv1d_50[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, None, 32)     0           conv1d_51[0][0]                  
__________________________________________________________________________________________________
multiply_13 (Multiply)          (None, None, 32)     0           activation_25[0][0]              
                                                                 activation_26[0][0]              
__________________________________________________________________________________________________
conv1d_52 (Conv1D)              (None, None, 32)     1056        multiply_13[0][0]                
__________________________________________________________________________________________________
add_13 (Add)                    (None, None, 32)     0           conv1d_49[0][0]                  
                                                                 conv1d_52[0][0]                  
__________________________________________________________________________________________________
conv1d_53 (Conv1D)              (None, None, 32)     1056        add_13[0][0]                     
__________________________________________________________________________________________________
conv1d_54 (Conv1D)              (None, None, 32)     2080        conv1d_53[0][0]                  
__________________________________________________________________________________________________
conv1d_55 (Conv1D)              (None, None, 32)     2080        conv1d_53[0][0]                  
__________________________________________________________________________________________________
activation_27 (Activation)      (None, None, 32)     0           conv1d_54[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, None, 32)     0           conv1d_55[0][0]                  
__________________________________________________________________________________________________
multiply_14 (Multiply)          (None, None, 32)     0           activation_27[0][0]              
                                                                 activation_28[0][0]              
__________________________________________________________________________________________________
conv1d_56 (Conv1D)              (None, None, 32)     1056        multiply_14[0][0]                
__________________________________________________________________________________________________
add_14 (Add)                    (None, None, 32)     0           conv1d_53[0][0]                  
                                                                 conv1d_56[0][0]                  
__________________________________________________________________________________________________
conv1d_57 (Conv1D)              (None, None, 32)     1056        add_14[0][0]                     
__________________________________________________________________________________________________
conv1d_58 (Conv1D)              (None, None, 32)     2080        conv1d_57[0][0]                  
__________________________________________________________________________________________________
conv1d_59 (Conv1D)              (None, None, 32)     2080        conv1d_57[0][0]                  
__________________________________________________________________________________________________
activation_29 (Activation)      (None, None, 32)     0           conv1d_58[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, None, 32)     0           conv1d_59[0][0]                  
__________________________________________________________________________________________________
multiply_15 (Multiply)          (None, None, 32)     0           activation_29[0][0]              
                                                                 activation_30[0][0]              
__________________________________________________________________________________________________
conv1d_60 (Conv1D)              (None, None, 32)     1056        multiply_15[0][0]                
__________________________________________________________________________________________________
add_15 (Add)                    (None, None, 32)     0           conv1d_57[0][0]                  
                                                                 conv1d_60[0][0]                  
__________________________________________________________________________________________________
conv1d_61 (Conv1D)              (None, None, 32)     1056        add_15[0][0]                     
__________________________________________________________________________________________________
conv1d_62 (Conv1D)              (None, None, 32)     2080        conv1d_61[0][0]                  
__________________________________________________________________________________________________
conv1d_63 (Conv1D)              (None, None, 32)     2080        conv1d_61[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, None, 32)     0           conv1d_62[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, None, 32)     0           conv1d_63[0][0]                  
__________________________________________________________________________________________________
multiply_16 (Multiply)          (None, None, 32)     0           activation_31[0][0]              
                                                                 activation_32[0][0]              
__________________________________________________________________________________________________
conv1d_64 (Conv1D)              (None, None, 32)     1056        multiply_16[0][0]                
__________________________________________________________________________________________________
add_17 (Add)                    (None, None, 32)     0           conv1d_4[0][0]                   
                                                                 conv1d_8[0][0]                   
                                                                 conv1d_12[0][0]                  
                                                                 conv1d_16[0][0]                  
                                                                 conv1d_20[0][0]                  
                                                                 conv1d_24[0][0]                  
                                                                 conv1d_28[0][0]                  
                                                                 conv1d_32[0][0]                  
                                                                 conv1d_36[0][0]                  
                                                                 conv1d_40[0][0]                  
                                                                 conv1d_44[0][0]                  
                                                                 conv1d_48[0][0]                  
                                                                 conv1d_52[0][0]                  
                                                                 conv1d_56[0][0]                  
                                                                 conv1d_60[0][0]                  
                                                                 conv1d_64[0][0]                  
__________________________________________________________________________________________________
activation_33 (Activation)      (None, None, 32)     0           add_17[0][0]                     
__________________________________________________________________________________________________
conv1d_65 (Conv1D)              (None, None, 128)    4224        activation_33[0][0]              
__________________________________________________________________________________________________
activation_34 (Activation)      (None, None, 128)    0           conv1d_65[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, None, 128)    0           activation_34[0][0]              
__________________________________________________________________________________________________
conv1d_66 (Conv1D)              (None, None, 1)      129         dropout_1[0][0]                  
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, None, 1)      0           conv1d_66[0][0]                  
==================================================================================================
Total params: 104,385
Trainable params: 104,385
Non-trainable params: 0
__________________________________________________________________________________________________
</pre></div>


<p>With our training architecture defined, we're ready to train the model! We'll leverage the transformer utility functions we defined earlier, and train using mean absolute error loss.</p>
<p>For this expansion of the full-fledged model, once again we end up more than doubling the total number of trainable parameters and incur the cost of slower training time. These additional parameters are due to the increase in filters for the pre/postprocessing layers. Training a model at this scale will take quite a while if you're not running fancy hardware - I'd recommend using a GPU. When constructing this notebook, I used an AWS EC2 instance with a GPU (p2.xlarge) and the Amazon Deep Learning AMI, and training took about an hour. </p>
<p>This time around, we'll go ahead and use all of the series in the dataset for training, and train for 15 epochs to give this more complex model more time to try to reach its full potential. </p>
<p>This is only a starting point, and I would encourage you to play around with this pipeline to see if you can get even better results! You could try selecting/engineering different exogenous features, adjusting the model architecture/hyperparameters, tuning the learning rate and number of epochs, etc.</p>
<div class="highlight"><pre><span></span><span class="n">first_n_samples</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">10</span> 
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span> <span class="o">=</span> \
    <span class="n">get_data_encode_decode</span><span class="p">(</span><span class="n">series_array</span><span class="p">,</span> <span class="n">exog_array</span><span class="p">,</span> <span class="n">first_n_samples</span><span class="p">,</span> <span class="n">date_to_index</span><span class="p">,</span> 
                           <span class="n">train_enc_start</span><span class="p">,</span> <span class="n">train_enc_end</span><span class="p">,</span> <span class="n">train_pred_start</span><span class="p">,</span> <span class="n">train_pred_end</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(),</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_absolute_error&#39;</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>  
</pre></div>


<div class="highlight"><pre><span></span>Epoch 1/15
145063/145063 [==============================] - 250s 2ms/step - loss: 0.3701
Epoch 2/15
145063/145063 [==============================] - 239s 2ms/step - loss: 0.2860
Epoch 3/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2790
Epoch 4/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2752
Epoch 5/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2729
Epoch 6/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2712
Epoch 7/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2700
Epoch 8/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2692
Epoch 9/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2684
Epoch 10/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2677
Epoch 11/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2672
Epoch 12/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2666
Epoch 13/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2661
Epoch 14/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2657
Epoch 15/15
145063/145063 [==============================] - 240s 2ms/step - loss: 0.2653
</pre></div>


<h2>5. Building the Model - Inference Loop</h2>
<p>Like in the previous notebook, we'll generate predictions by running our model from section 3 in a loop, using each iteration to extract the prediction for the time step one beyond our current history then append it to our history sequence. In each iteration we'll also update the exogenous features to include values corresponding to the next time step we'll predict. With 60 iterations, this lets us generate predictions for the full interval we've chosen. </p>
<p>Recall that we designed our model to output predictions for 60 time steps at once in order to use teacher forcing for training. So if we start from a history sequence and want to predict the first future time step, we can run the model on the history sequence and take the last time step of the output, which corresponds to one time step beyond the history sequence. </p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_sequence</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">):</span>

    <span class="n">history_tensor</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="p">[:,:(</span><span class="o">-</span><span class="n">pred_steps</span><span class="o">+</span><span class="mi">1</span><span class="p">),:]</span>
    <span class="n">pred_sequence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">pred_steps</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># initialize output (pred_steps time steps)  </span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pred_steps</span><span class="p">):</span>

        <span class="c1"># record next time step prediction (last time step of model output) </span>
        <span class="n">last_step_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">history_tensor</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pred_sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">last_step_pred</span>

        <span class="c1"># add the next time step prediction along with corresponding exogenous features</span>
        <span class="c1"># to the history tensor</span>
        <span class="n">last_step_exog</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="p">[:,[(</span><span class="o">-</span><span class="n">pred_steps</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="n">i</span><span class="p">],</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">last_step_tensor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">last_step_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> 
                                           <span class="n">last_step_exog</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">history_tensor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">history_tensor</span><span class="p">,</span> <span class="n">last_step_tensor</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pred_sequence</span>
</pre></div>


<h2>6. Generating and Plotting Predictions</h2>
<p>Now we have everything we need to generate predictions for encoder (history) /target series pairs that we didn't train on (note again we're using "encoder"/"decoder" terminology to stay consistent with notebook 1 -- here it's more like history/target). We'll pull out our set of validation encoder/target series (recall that these are shifted forward in time). Then using a plotting utility function which is updated to handle the addition of exogenous features in the input data, we can look at the tail end of the encoder series, the true target series, and the predicted target series. This gives us a feel for how our predictions are doing.  </p>
<div class="highlight"><pre><span></span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span> <span class="o">=</span> \
    <span class="n">get_data_encode_decode</span><span class="p">(</span><span class="n">series_array</span><span class="p">,</span> <span class="n">exog_array</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">date_to_index</span><span class="p">,</span> 
                           <span class="n">val_enc_start</span><span class="p">,</span> <span class="n">val_enc_end</span><span class="p">,</span> <span class="n">val_pred_start</span><span class="p">,</span> <span class="n">val_pred_end</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_and_plot</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span><span class="p">,</span> <span class="n">sample_ind</span><span class="p">,</span> <span class="n">enc_tail_len</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>

    <span class="n">encode_tensor</span> <span class="o">=</span> <span class="n">encoder_input_data</span><span class="p">[[</span><span class="n">sample_ind</span><span class="p">],:,:]</span> 
    <span class="n">pred_series</span> <span class="o">=</span> <span class="n">predict_sequence</span><span class="p">(</span><span class="n">encode_tensor</span><span class="p">)</span>

    <span class="n">encode_series</span> <span class="o">=</span> <span class="n">encode_tensor</span><span class="p">[:,:(</span><span class="o">-</span><span class="n">pred_steps</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pred_series</span> <span class="o">=</span> <span class="n">pred_series</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>   
    <span class="n">target_series</span> <span class="o">=</span> <span class="n">decoder_target_data</span><span class="p">[</span><span class="n">sample_ind</span><span class="p">,:,:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 

    <span class="n">encode_series_tail</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">encode_series</span><span class="p">[</span><span class="o">-</span><span class="n">enc_tail_len</span><span class="p">:],</span><span class="n">target_series</span><span class="p">[:</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">x_encode</span> <span class="o">=</span> <span class="n">encode_series_tail</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>   

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">x_encode</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">encode_series_tail</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">x_encode</span><span class="p">,</span><span class="n">x_encode</span><span class="o">+</span><span class="n">pred_steps</span><span class="p">),</span><span class="n">target_series</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">x_encode</span><span class="p">,</span><span class="n">x_encode</span><span class="o">+</span><span class="n">pred_steps</span><span class="p">),</span><span class="n">pred_series</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;teal&#39;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Encoder Series Tail of Length </span><span class="si">%d</span><span class="s1">, Target Series, and Predictions&#39;</span> <span class="o">%</span> <span class="n">enc_tail_len</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Encoding Series&#39;</span><span class="p">,</span><span class="s1">&#39;Target Series&#39;</span><span class="p">,</span><span class="s1">&#39;Predictions&#39;</span><span class="p">])</span>
</pre></div>


<p>Generating some plots as below, we can see that our predictions are often strong and expressive, with similar performance to those generated by the full-fledged model without exogenous features. This suggests that the exogenous features we've added may not contribute additional predictive signal and reinforces the effectiveness of a purely endogenous model. It's possible that we haven't fully tapped into the exogenous features' potential and likely that other feature engineering techniques could help as well, but for now this would argue in favor of choosing a simpler, more efficient model over this significantly more complex one. Set out on your own to try to prove this conclusion wrong!  </p>
<p>One feature engineering trick that seems particularly promising is to hard-code certain long term seasonalities (i.e. quarterly or yearly) as additional features in the input sequences. I'd call this type of feature a <strong>lagged endogenous feature</strong> since it's derived from the actual time series. You can check out <a href="https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/43795">Arthur Suilin's model description here</a> for his breakdown of this idea. I may explore this technique in a future notebook, so stay tuned!  </p>
<div class="highlight"><pre><span></span><span class="n">predict_and_plot</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span><span class="p">,</span> 
                 <span class="n">sample_ind</span><span class="o">=</span><span class="mi">16534</span><span class="p">,</span> <span class="n">enc_tail_len</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="/images/output_43_0.png"></p>
<div class="highlight"><pre><span></span><span class="n">predict_and_plot</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span><span class="p">,</span> 
                 <span class="n">sample_ind</span><span class="o">=</span><span class="mi">16555</span><span class="p">,</span> <span class="n">enc_tail_len</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="/images/output_dup_44_0.png"></p>
<div class="highlight"><pre><span></span><span class="n">predict_and_plot</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span><span class="p">,</span> 
                 <span class="n">sample_ind</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span> <span class="n">enc_tail_len</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="/images/output_dup_45_0.png"></p>
<div class="highlight"><pre><span></span><span class="n">predict_and_plot</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span><span class="p">,</span> 
                 <span class="n">sample_ind</span><span class="o">=</span><span class="mi">68000</span><span class="p">,</span> <span class="n">enc_tail_len</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="/images/output_46_0.png"></p>
<div class="highlight"><pre><span></span><span class="n">predict_and_plot</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span><span class="p">,</span> 
                 <span class="n">sample_ind</span><span class="o">=</span><span class="mi">6007</span><span class="p">,</span> <span class="n">enc_tail_len</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="/images/output_47_0.png"></p>
<div class="highlight"><pre><span></span><span class="n">predict_and_plot</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span><span class="p">,</span> 
                 <span class="n">sample_ind</span><span class="o">=</span><span class="mi">70450</span><span class="p">,</span> <span class="n">enc_tail_len</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="/images/output_48_0.png"></p>
<div class="highlight"><pre><span></span><span class="n">predict_and_plot</span><span class="p">(</span><span class="n">encoder_input_data</span><span class="p">,</span> <span class="n">decoder_target_data</span><span class="p">,</span> 
                 <span class="n">sample_ind</span><span class="o">=</span><span class="mi">16551</span><span class="p">,</span> <span class="n">enc_tail_len</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="/images/output_dup_49_0.png"></p>
            <div class="hr"></div>
            <a href="#" class="go-top">Go Top</a>
<div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = "leafyleap-2"; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div><footer class="footer">
    <p>&copy; Mohcine Madkour &ndash;
        Built with <a href="https://github.com/PurePelicanTheme/pure">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
    </p>
</footer>        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script>
</body>
</html>